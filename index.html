<html><head><script src="resources/jquery.min.js"></script><link href="resources/bootstrap.min.css" rel="stylesheet"></link><link href="resources/bootstrap-theme.min.css" rel="stylesheet"></link><script src="resources/bootstrap.min.js"></script><script src="helper.js">function hideAll(){console.log("hideAll")}function showme(e){console.log("showme");var l,n=e.substring(7),o=document.getElementsByName("data");for(l=0;l&lt;o.length;l++)o[l].style.display="none";var t=document.getElementsByName("summary");for(l=0;l&lt;t.length;l++)t[l].style.display="none";document.getElementById(n).style.display="block"}</script><style>table, th, td { vertical-align:top; padding: 3px} table {table-layout:fixed} td {word-wrap:break-word} .bs-callout { padding: 5px; margin: 5px 0; border: 1px solid #eee; border-left-width: 5px; border-radius: 3px; font-weight:normal; }.bs-callout-info {border-left-color: #5bc0de;}</style></head><body><nav class="navbar navbar-light"><div style="background-color: #F0F8FF;" class="container-fluid"><ul class="nav nav-pills"><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ppcx86" onclick="showme(this.id);">FULL SUMMARY</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu16" onclick="showme(this.id);">UBUNTU16</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu18" onclick="showme(this.id);">UBUNTU18</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel72" onclick="showme(this.id);">RHEL72</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel75" onclick="showme(this.id);">RHEL75</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_developers" onclick="showme(this.id);">DEVELOPERS</a></li><p style="float:right;color:grey;font-size:13;padding-top:5px" role="presentation">11-01-2019 12:30 UTC</p></ul><div style="float:right;color:grey;font-size:12">Notations:<img src="resources/red.png" style="width: 16px; height: 16px;">Build failed </img><img src="resources/blue.png" style="width: 16px; height: 16px;">Build success with no failure </img><img src="resources/yellow.png" style="width: 16px; height: 16px;">N (M) Build success with N test failures &amp; M unique failures </img></div></div></nav><div style="table-cell" class="col-sm-2 col-md-2 sidebar"><div class="list-group"><a href="#" class="list-group-item list-group-item-action active" onclick="showme(this.id);" id="anchor_ppcx86">Packages</a><a class="list-group-item list-group-item-action" href="#" id="anchor_accumulo" onclick="showme(this.id);" title="Owned by Prajyot">ACCUMULO</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ambari" onclick="showme(this.id);" title="Owned by Prajyot">AMBARI</a><a class="list-group-item list-group-item-action" href="#" id="anchor_atlas" onclick="showme(this.id);" title="Owned by Yussuf">ATLAS</a><a class="list-group-item list-group-item-action" href="#" id="anchor_calcite" onclick="showme(this.id);" title="Owned by Pravin">CALCITE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_datafu" onclick="showme(this.id);" title="Owned by N/A">DATAFU</a><a class="list-group-item list-group-item-action" href="#" id="anchor_druid" onclick="showme(this.id);" title="Owned by N/A">DRUID</a><a class="list-group-item list-group-item-action" href="#" id="anchor_falcon" onclick="showme(this.id);" title="Owned by Yussuf">FALCON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_flume" onclick="showme(this.id);" title="Owned by Pravin">FLUME</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hadoop" onclick="showme(this.id);" title="Owned by Pravin">HADOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hbase" onclick="showme(this.id);" title="Owned by Prajyot">HBASE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hive" onclick="showme(this.id);" title="Owned by Alisha">HIVE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_kafka" onclick="showme(this.id);" title="Owned by Prajyot">KAFKA</a><a class="list-group-item list-group-item-action" href="#" id="anchor_knox" onclick="showme(this.id);" title="Owned by Yussuf">KNOX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_metron" onclick="showme(this.id);" title="Owned by Pravin">METRON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_oozie" onclick="showme(this.id);" title="Owned by Alisha">OOZIE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_phoenix" onclick="showme(this.id);" title="Owned by Prajyot">PHOENIX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_pig" onclick="showme(this.id);" title="Owned by Yussuf">PIG</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ranger" onclick="showme(this.id);" title="Owned by Yussuf">RANGER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_slider" onclick="showme(this.id);" title="Owned by Yussuf">SLIDER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_spark" onclick="showme(this.id);" title="Owned by Prajyot">SPARK</a><a class="list-group-item list-group-item-action" href="#" id="anchor_sqoop" onclick="showme(this.id);" title="Owned by Yussuf">SQOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_storm" onclick="showme(this.id);" title="Owned by Alisha">STORM</a><a class="list-group-item list-group-item-action" href="#" id="anchor_tez" onclick="showme(this.id);" title="Owned by Prajyot">TEZ</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zeppelin" onclick="showme(this.id);" title="Owned by Alisha">ZEPPELIN</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zookeeper" onclick="showme(this.id);" title="Owned by Pravin">ZOOKEEPER</a></div></div><div style="display: table-cell"><div id="developers" style="display:block;font-weight:bold;display:none;" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">DEVELOPERS</div></div><div class="panel-body"><table style="font-size:15" id="summarytable" class="table table-striped"><tr><td style="width: 100px;font-weight:bold">ALISHA</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_storm">STORM </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zeppelin">ZEPPELIN </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_oozie">OOZIE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hive">HIVE </button></td></tr><tr><td style="width: 100px;font-weight:bold">PRAVIN</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_metron">METRON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zookeeper">ZOOKEEPER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hadoop">HADOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_calcite">CALCITE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_flume">FLUME </button></td></tr><tr><td style="width: 100px;font-weight:bold">PRAJYOT</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_kafka">KAFKA </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_tez">TEZ </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hbase">HBASE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_accumulo">ACCUMULO </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_phoenix">PHOENIX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_spark">SPARK </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ambari">AMBARI </button></td></tr><tr><td style="width: 100px;font-weight:bold">YUSSUF</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_knox">KNOX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_atlas">ATLAS </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_sqoop">SQOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_slider">SLIDER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_falcon">FALCON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_pig">PIG </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ranger">RANGER </button></td></tr></table></div></div></div><div style="display: table-cell"><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="accumulo"><div style="font-weight:bold;" class="panel-heading">ACCUMULO<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>42d82d9cdc0a401ff7e3dfc8c6e9b8659e5927d7</div><div><b>Last Run: </b>08-01-2019 20:26 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 2</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1726</div><div>Failed Count : 2</div><div>Skipped Count : 6</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 60000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 60000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ambari"><div style="font-weight:bold;" class="panel-heading">AMBARI<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> origin/trunk</div><div><b>Last Revision: </b>313178dc562cb8c2fc341b788a6da50b4274a869</div><div><b>Last Run: </b>09-01-2019 00:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5339</div><div>Failed Count : 1</div><div>Skipped Count : 72</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5339</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5339</div><div>Failed Count : 1</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5339</div><div>Failed Count : 1</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5339</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5339</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td></tr><tr><td>Result</td><td>N/A</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.ambari.server.orm.dao.AlertsDAOTest.testFindCurrentByDefinitionId</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>[Deadlocked Thread:
------------------
"Thread-22" Id=56 WAITING on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@1a78f688 owned by "Thread-26" Id=60
 at sun.misc.Unsafe.park(Native Method)
 -  waiting on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@1a78f688
 at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
 at java.util.concurrent.locks.Abstrac</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Host not found, hostname=c6401.ambari.apache.org</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>[Deadlocked Thread:
------------------
"Thread-22" Id=56 RUNNABLE
 at java.lang.Object.wait(Native Method)
 at java.lang.Object.wait(Object.java:502)
 at org.eclipse.persistence.internal.helper.ConcurrencyManager.acquireDeferredLock(ConcurrencyManager.java:184)
 at org.eclipse.persistence.internal.identitymaps.CacheKey.acquireDeferredLock(CacheKey.java:210)
 at org.eclipse.persistence.internal.ide</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.ambari.server.orm.dao.AlertsDAOTest.testFindCurrentByDefinitionId</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="atlas"><div style="font-weight:bold;" class="panel-heading">ATLAS<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>e05ed85fece9c6c3956a0e3f666f59e01a7b668c</div><div><b>Last Run: </b>09-01-2019 15:22 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 969</div><div>Failed Count : 1</div><div>Skipped Count : 30</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 969</div><div>Failed Count : 1</div><div>Skipped Count : 30</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>
Wanted but not invoked:
atlasEntityStore.createOrUpdate(
    &lt;any&gt;,
    &lt;any&gt;
);
-&gt; at org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled(NotificationHookConsumerKafkaTest.java:112)
Actually, there were zero interactions with this mock.
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>
Wanted but not invoked:
atlasEntityStore.createOrUpdate(
    &lt;any&gt;,
    &lt;any&gt;
);
-&gt; at org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled(NotificationHookConsumerKafkaTest.java:112)
Actually, there were zero interactions with this mock.
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="calcite"><div style="font-weight:bold;" class="panel-heading">CALCITE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>9667f8537010d21556a592bd0dfbf20f7d0a4411</div><div><b>Last Run: </b>07-01-2019 01:44 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="datafu"><div style="font-weight:bold;" class="panel-heading">DATAFU<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(N/A)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>857cf164c30883d739c4895c9a9c758880526435</div><div><b>Last Run: </b>07-01-2019 01:11 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="druid"><div style="font-weight:bold;" class="panel-heading">DRUID<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(N/A)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>c780aacc03e30b929ba14f70d7f278811fd8ba44</div><div><b>Last Run: </b>17-10-2018 06:25 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="falcon"><div style="font-weight:bold;" class="panel-heading">FALCON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>470e5e9f5de9ba1b6149dec60e87d3a04270eda3</div><div><b>Last Run: </b>09-01-2019 03:27 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 994</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 994</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1000</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1003</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 996</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 999</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="flume"><div style="font-weight:bold;" class="panel-heading">FLUME<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>5d29402f8def1fd3bb3f24c9d30bebb1e3806619</div><div><b>Last Run: </b>08-01-2019 01:48 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1325</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 15</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1324</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1324</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileWindows</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileNotOnWindows</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailure</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailureAndBufferSizeChanges</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndDifferentFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBehaviorWithEmptyFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsWithinAFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsAcrossFileBoundary</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testEmptyDirectoryAfterCommittingFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testLineExceedsMaxLineLength</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testNameCorrespondsToLatestRead</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicSpooling</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testInitiallyEmptyDirectory</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testFileChangesDuringRead</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div><div><li>Platform not recognized</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileWindows</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileNotOnWindows</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailure</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailureAndBufferSizeChanges</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndDifferentFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBehaviorWithEmptyFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsWithinAFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsAcrossFileBoundary</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testEmptyDirectoryAfterCommittingFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testLineExceedsMaxLineLength</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testNameCorrespondsToLatestRead</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicSpooling</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testInitiallyEmptyDirectory</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testFileChangesDuringRead</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hadoop"><div style="font-weight:bold;" class="panel-heading">HADOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>d66925a315644f3c3bcde589f365fc01f0033d32</div><div><b>Last Run: </b>07-01-2019 13:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 20436</div><div>Failed Count : 94</div><div>Skipped Count : 1193</div></td><td><div>Total Count : 20151</div><div>Failed Count : 68</div><div>Skipped Count : 1191</div></td><td><div>Total Count : 19583</div><div>Failed Count : 76</div><div>Skipped Count : 1143</div></td><td><div>Total Count : 19256</div><div>Failed Count : 70</div><div>Skipped Count : 1142</div></td><td><div>Total Count : 20094</div><div>Failed Count : 245</div><div>Skipped Count : 1190</div></td><td><div>Total Count : 20180</div><div>Failed Count : 85</div><div>Skipped Count : 1192</div></td><td><div>Total Count : 20507</div><div>Failed Count : 74</div><div>Skipped Count : 1192</div></td><td><div>Total Count : 20182</div><div>Failed Count : 85</div><div>Skipped Count : 1191</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState.testRegistrationMajorityQuorum</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</li></div><div><li>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerReadTimeout</li></div><div><li>org.apache.hadoop.hdfs.TestEncryptedTransfer.testLongLivedClientPipelineRecovery[0]</li></div><div><li>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testWaitForRegistrationOnRestart</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.mapred.TestJobConf.testJobConf</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.fs.azurebfs.services.TestAbfsClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.yarn.sls.TestReservationSystemInvariants.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</li></div><div><li>org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator.testAMSimulatorWithNodeLabels[0]</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetNewApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testSubmitApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testForceKillApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetApplicationsOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetContainerReportOnHA</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraintsByScheduler</li></div><div><li>org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory.testLogAggregationFileControllerFactory</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA.testGetApplicationReportIdempotent</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div><div><li>org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST.org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile src/test/resources/nodes.json)]</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf.perfZKRMStateStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler.testContainerReleaseWithAllocationTags[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemptionWithDRF]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodesWithStaleness[1]</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemption]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailover</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryOnDatanodeUpgrade</li></div><div><li>org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestMaintenanceState.testFileCloseAfterEnteringMaintenance</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork.testDatanodeReRegistration</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.writeRead</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateThreeBatches</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.multipleReads</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateSingleBatch</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testServerBindHost</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testNonExistentBlock</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testReadBack</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testIterate</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapAliasmap.testAliasmapBootstrap</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBDelimitedWriter</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBCorruptionDetector</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFileCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleFileCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFolderCorruption</li></div><div><li>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testTokenStore</li></div><div><li>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testCheckVersion</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength</li></div><div><li>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testGzipWithTwoInputs</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testNegativeRecordLength</li></div><div><li>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testGzipWithTwoInputs</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestUberAM.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapred.TestShuffleHandler.testRecoveryFromOtherVersions</li></div><div><li>org.apache.hadoop.mapred.TestShuffleHandler.testRecovery</li></div><div><li>org.apache.hadoop.tools.TestHadoopArchiveLogs.testFilterAppsByAggregatedStatus</li></div><div><li>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunchWithArguments</li></div><div><li>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunch</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntitiesPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntityTypes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testFromTsWithDeletion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testLevelDbRepair</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertForPreviousPeriodAfterRollPeriodRollsDB</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertAfterRollPeriodRollsDB</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntitiesWithOutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetEntitiesAclEnabled</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntityWithOutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testUpdatingOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testTokenStore</li></div><div><li>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testAMRMProxyStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyRestartTimes</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyState</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreNodeHealth</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testFinishResourceLocalization</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testNMTokenStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCompactionCycle</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLogDeleterStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testDeletionTaskStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerTokenStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLocalTrackerStateIterator</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreForResourceMapping</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStartResourceLocalization</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testApplicationStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testRemoveLocalizedResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testIsNewlyCreated</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testUnexpectedKeyDoesntThrowException</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingNoService</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingV2Enabled</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveAttempt</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testBadKeyIteration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testDeleteStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testEpoch</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testApps</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testProxyCA</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testClientTokens</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testVersion</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAMTokens</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAppDeletion</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveApplication</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testReservation</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testVersioning</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistConfiguration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testMaxLogs</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testRestartReadsFromUpdatedStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistUpdatedConfiguration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testConfigurationUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testNullConfigurationUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testSummaryRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testAppLogsScanLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testPluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testCleanLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testScanActiveLogsAndMoveToDonePluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient.testLifecycleAndOverride</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.tracing.TestTracing.testTracing</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.testAppFinishedFinished[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testSimpleDecreaseContainer</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExampleDotCom</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.test1OutOf2BlockpoolsWithBlockPoolPolicy</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.TestServiceAM.testContainersReleasedWhenPreLaunchFails</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>expected:&lt;router[0]&gt; but was:&lt;router[3]&gt;</li></div><div><li>expected:&lt;1546918553023&gt; but was:&lt;1546918554191&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>Self-suppression not permitted</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>10159 milliseconds passed.</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li> Expected to find 'localhost:44270: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:44270: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546939389129_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546939389129_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>The actual value 15 is not within the expected range: [5.60, 8.40].</li></div><div><li>The actual value 11 is not within the expected range: [5.60, 8.40].</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>src and dst file does not match at 0 between HdfsNamedFileStatus{path=hdfs://localhost:46069/testdir/srcdat/file0; isDirectory=false; length=102400; replication=2; blocksize=1024; modification_time=1546952141602; access_time=1546952135180; owner=u1; group=g1; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} and HdfsNamedFileStatus{path=hdfs://localhost:</li></div><div><li>File group ownership should match expected:&lt;[g0]&gt; but was:&lt;[supergroup]&gt;</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>java.io.IOException: Unable to delete directory /var/lib/jenkins/workspace/hadoop/hadoop-tools/hadoop-sls/target/test-dir/output5328169727264143972/metrics.</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 12:05:28 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>appattempt_1546932186738_0001_000001 not found in AMRMTokenSecretManager.</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>The Rolled-back process should be a different pid. Actual: 6858</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.doRestartTests(TestContainerManager.java:482)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuc</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>Error when transitioning to Active mode</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>Web app not running</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546903390477_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546903390477_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 01:16:04 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>Timed out attempt store notification</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 08:43:36,510

"Ping Checker" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.yarn.util.AbstractLivelinessMonitor$PingChecker.run(AbstractLivelinessMonitor.java:154)
        at java.lang.Thread.run(Thread.java:748)
"Timer-</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 02:24:06,714

"stripedRead-3" daemon prio=5 tid=14244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQue</li></div><div><li> Expected to find 'localhost:45047: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45047: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:40406: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:40406: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:45455: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45455: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:45135: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45135: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41967: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41967: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:38927: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:38927: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546910648076_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546910648076_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Mon Jan 07 20:12:10 CST 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>Incorrect # of containers on the greedy app expected:&lt;6&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodes(TestReplicationPolicy.java:525)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWi</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 09:30:44,749

"datanode DomainSocketWatcher" daemon prio=5 tid=153 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546899809978_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546899809978_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Mon Jan 07 18:53:38 CST 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Application attempt appattempt_1546895748910_0001_000001 doesn't exist in ApplicationMasterService cache.
 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:398)
 at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor$3.allocate(DefaultRequestInterceptor.java:224)
 at org.apache.hadoop.yarn.server.nodemanager.</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>Incorrect # of containers on the greedy app expected:&lt;6&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>test timed out after 180000 milliseconds</li></div><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>test timed out after 60000 milliseconds</li></div><div><li>DestHost:destPort localhost:11376 , LocalHost:localPort 40984ce6df2a/172.17.0.2:0. Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</li></div><div><li>expected:&lt;1546917924065&gt; but was:&lt;1546917925238&gt;</li></div><div><li>Unable to close file because the last blockBP-389427976-172.17.0.2-1546905112446:blk_1073741827_1003 does not have enough number of replicas.</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 12000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5498011387622669649.8: /tmp/libleveldbjni-64-1-5498011387622669649.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-6454562646584349185.8: /tmp/libleveldbjni-64-1-6454562646584349185.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Actual async detected volume failures should be greater or equal than [Ljava.lang.String;@11537d1e</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7784561517699997943.8: /tmp/libleveldbjni-64-1-7784561517699997943.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>inode should complete in ~60000 ms.
Expected: is &lt;true&gt;
     but: was &lt;false&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9116724356660138512.8: /tmp/libleveldbjni-64-1-9116724356660138512.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5836970591446903027.8: /tmp/libleveldbjni-64-1-5836970591446903027.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546938205011_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546938205011_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;DEFAULT&gt; but was:&lt;HIGH&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-2823841977520574558.8: /tmp/libleveldbjni-64-1-2823841977520574558.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>The actual value 14 is not within the expected range: [5.60, 8.40].</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 11:26:18 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5816037266765405976.8: /tmp/libleveldbjni-64-1-5816037266765405976.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-8739679424167203247.8: /tmp/libleveldbjni-64-1-8739679424167203247.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB$MyRollingLevelDB</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3847991619475157513.8: /tmp/libleveldbjni-64-1-3847991619475157513.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9006565544380648365.8: /tmp/libleveldbjni-64-1-9006565544380648365.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-4370864914664638310.8: /tmp/libleveldbjni-64-1-4370864914664638310.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5886235552469102165.8: /tmp/libleveldbjni-64-1-5886235552469102165.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:530)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.tearDown(TestNodeManagerShutdown.java:107)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeM</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.doRestartTests(TestContainerManager.java:482)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuc</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7421185355100852629.8: /tmp/libleveldbjni-64-1-7421185355100852629.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7801676120722955059.8: /tmp/libleveldbjni-64-1-7801676120722955059.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5204713396060524684.8: /tmp/libleveldbjni-64-1-5204713396060524684.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9103122012756037183.8: /tmp/libleveldbjni-64-1-9103122012756037183.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime(TestContinuousScheduling.java:387)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3329554230740595379.8: /tmp/libleveldbjni-64-1-3329554230740595379.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3058546666561165170.8: /tmp/libleveldbjni-64-1-3058546666561165170.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-966921701115744213.8: /tmp/libleveldbjni-64-1-966921701115744213.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 04:03:06,299

"IPC Server handler 7 on default port 39951" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer</li></div><div><li> Expected to find 'localhost:43714: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43714: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39334: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39334: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35021: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35021: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:42081: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:42081: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35506: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35506: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39931: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39931: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>expected:&lt;-6040926954844379003&gt; but was:&lt;3220549084575210641&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546900955447_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546900955447_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 00:57:38 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;8192&gt;</li></div><div><li>expected:&lt;1024&gt; but was:&lt;3072&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>Unexpected num under-replicated blocks expected:&lt;3&gt; but was:&lt;4&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546909492326_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546909492326_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 02:39:49 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>ProcessTree shouldn't be alive</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Process is still alive!</li></div><div><li>Process is still alive!</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>example.com exists:</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>test timed out after 600000 milliseconds</li></div><div><li> Expected to find 'localhost:36193: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:36193: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:34524: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34524: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:34645: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34645: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:43286: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43286: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41167: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41167: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41926: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41926: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546945709352_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546945709352_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 13:23:24 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
	at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters(TestFederationInterceptor.java:308)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMeth</li></div><div><li>java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
	at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt(TestFederationInterceptor.java:817)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAcce</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered(TestWorkPreservingRMRestart.java:1165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.Native</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState.testRegistrationMajorityQuorum</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</div></li><li><div>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerReadTimeout</div></li><li><div>org.apache.hadoop.hdfs.TestEncryptedTransfer.testLongLivedClientPipelineRecovery[0]</div></li><li><div>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testWaitForRegistrationOnRestart</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.mapred.TestJobConf.testJobConf</div></li><li><div>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.fs.azurebfs.services.TestAbfsClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</div></li><li><div>org.apache.hadoop.yarn.sls.TestReservationSystemInvariants.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</div></li><li><div>org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator.testAMSimulatorWithNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetNewApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testSubmitApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testForceKillApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetApplicationsOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetContainerReportOnHA</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraintsByScheduler</div></li><li><div>org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory.testLogAggregationFileControllerFactory</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA.testGetApplicationReportIdempotent</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</div></li><li><div>org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST.org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</div></li><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</div></li><li><div>org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile src/test/resources/nodes.json)]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf.perfZKRMStateStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler.testContainerReleaseWithAllocationTags[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemptionWithDRF]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</div></li><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodesWithStaleness[1]</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemption]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailover</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</div></li><li><div>org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryOnDatanodeUpgrade</div></li><li><div>org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestMaintenanceState.testFileCloseAfterEnteringMaintenance</div></li><li><div>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</div></li><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork.testDatanodeReRegistration</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.writeRead</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateThreeBatches</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.multipleReads</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateSingleBatch</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testServerBindHost</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testNonExistentBlock</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testReadBack</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testIterate</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapAliasmap.testAliasmapBootstrap</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBDelimitedWriter</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBCorruptionDetector</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFileCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleFileCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFolderCorruption</div></li><li><div>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testTokenStore</div></li><li><div>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testCheckVersion</div></li><li><div>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength</div></li><li><div>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testGzipWithTwoInputs</div></li><li><div>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testNegativeRecordLength</div></li><li><div>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testGzipWithTwoInputs</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestUberAM.testJobWithChangePriority</div></li><li><div>org.apache.hadoop.mapred.TestShuffleHandler.testRecoveryFromOtherVersions</div></li><li><div>org.apache.hadoop.mapred.TestShuffleHandler.testRecovery</div></li><li><div>org.apache.hadoop.tools.TestHadoopArchiveLogs.testFilterAppsByAggregatedStatus</div></li><li><div>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunchWithArguments</div></li><li><div>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunch</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntitiesPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntityTypes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testFromTsWithDeletion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testLevelDbRepair</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertForPreviousPeriodAfterRollPeriodRollsDB</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertAfterRollPeriodRollsDB</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntitiesWithOutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetEntitiesAclEnabled</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntityWithOutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testUpdatingOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testTokenStore</div></li><li><div>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testAMRMProxyStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyRestartTimes</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyState</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreNodeHealth</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testFinishResourceLocalization</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testNMTokenStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCompactionCycle</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLogDeleterStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testDeletionTaskStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerTokenStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLocalTrackerStateIterator</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreForResourceMapping</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStartResourceLocalization</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testApplicationStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testRemoveLocalizedResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testIsNewlyCreated</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testUnexpectedKeyDoesntThrowException</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingNoService</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingV2Enabled</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveAttempt</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testBadKeyIteration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testDeleteStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testEpoch</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testApps</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testProxyCA</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testClientTokens</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testVersion</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAMTokens</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAppDeletion</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveApplication</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testReservation</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testVersioning</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistConfiguration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testMaxLogs</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testRestartReadsFromUpdatedStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistUpdatedConfiguration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testConfigurationUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testNullConfigurationUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testSummaryRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testAppLogsScanLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testPluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testCleanLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testScanActiveLogsAndMoveToDonePluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient.testLifecycleAndOverride</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.tracing.TestTracing.testTracing</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.testAppFinishedFinished[1]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testSimpleDecreaseContainer</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</div></li><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</div></li><li><div>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExampleDotCom</div></li><li><div>org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.test1OutOf2BlockpoolsWithBlockPoolPolicy</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.yarn.service.TestServiceAM.testContainersReleasedWhenPreLaunchFails</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered[CAPACITY]</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hbase"><div style="font-weight:bold;" class="panel-heading">HBASE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>5d32e80f9ecd74c0a89c81b57f02e1ad400c2a2f</div><div><b>Last Run: </b>10-01-2019 14:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 4775</div><div>Failed Count : 6</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4787</div><div>Failed Count : 11</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4775</div><div>Failed Count : 6</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4788</div><div>Failed Count : 8</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4780</div><div>Failed Count : 20</div><div>Skipped Count : 41</div></td><td><div>Total Count : 2700</div><div>Failed Count : 2</div><div>Skipped Count : 20</div></td><td><div>Total Count : 4775</div><div>Failed Count : 0</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4787</div><div>Failed Count : 2</div><div>Skipped Count : 41</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div><div><li>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testRpcThrottleWhenStartup</li></div><div><li>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.org.apache.hadoop.hbase.quotas.TestQuotaAdmin</li></div><div><li>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.org.apache.hadoop.hbase.quotas.TestQuotaAdmin</li></div><div><li>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota</li></div><div><li>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div><div><li>org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.testRecoveryAndDoubleExecution</li></div><div><li>org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.testRecoveryAndDoubleExecution</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.coprocessor.example.TestWriteHeavyIncrementObserverWithMemStoreCompaction.test</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory</li></div><div><li>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS</li></div><div><li>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS</li></div><div><li>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.testKillRS</li></div><div><li>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.testKillRS</li></div><div><li>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.testRowsSeenMetricWithAsync</li></div><div><li>org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters.org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters</li></div><div><li>org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters.org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters</li></div><div><li>org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.testOfflineRegion</li></div><div><li>org.apache.hadoop.hbase.master.TestSplitWALManager.testCreateSplitWALProcedures</li></div><div><li>org.apache.hadoop.hbase.master.TestSplitWALManager.org.apache.hadoop.hbase.master.TestSplitWALManager</li></div><div><li>org.apache.hadoop.hbase.master.TestSplitWALManager.org.apache.hadoop.hbase.master.TestSplitWALManager</li></div><div><li>org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.testRegionMerge</li></div><div><li>org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.testFlushWithTableCompactionDisabled</li></div><div><li>org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.testHeartbeatWithSparseRowFilter</li></div><div><li>org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControlForStripedStore</li></div><div><li>org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControl</li></div><div><li>org.apache.hadoop.hbase.replication.multiwal.TestReplicationEndpointWithMultipleWAL.testMetricsSourceBaseSourcePassthrough</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.rsgroup.TestRSGroupsAdmin2.testMoveServersAndTables</li></div><div><li>org.apache.hadoop.hbase.master.TestCatalogJanitor.testLastParentCleanedEvenIfDaughterGoneFirst</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testAsyncSnapshotWillNotBlockSnapshotHFileCleaner</li></div><div><li>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>java.util.concurrent.TimeoutException: The procedure 47 is still running</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread RS-EventLoopGroup-7-2</li></div><div><li>java.io.InterruptedIOException
	at org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota(TestQuotaAdmin.java:495)
Caused by: java.lang.InterruptedException
	at org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota(TestQuotaAdmin.java:495)
</li></div><div><li>org.apache.hadoop.hbase.TableNotEnabledException: hbase:quota
 at org.apache.hadoop.hbase.master.procedure.AbstractStateMachineTableProcedure.preflightChecks(AbstractStateMachineTableProcedure.java:166)
 at org.apache.hadoop.hbase.master.procedure.DisableTableProcedure.&lt;init&gt;(DisableTableProcedure.java:80)
 at org.apache.hadoop.hbase.master.HMaster$11.run(HMaster.java:2639)
 at org.apache.hadoop.h</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>run queue not empty</li></div><div><li>expected executor to be running</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread RS-EventLoopGroup-5-3</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread Socket Reader #1 for port 33656</li></div><div><li>java.util.concurrent.TimeoutException: The procedure 12 is still running</li></div><div><li>Interrupt while waiting on Operation: DELETE, Table Name: Group_ns:testKillRS, procId: 26</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread Socket Reader #1 for port 36693</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread RS-EventLoopGroup-29-2</li></div><div><li>The procedure 305 is still running</li></div><div><li>java.lang.AssertionError
	at org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.testFlushWithTableCompactionDisabled(TestCompactSplitThread.java:171)
</li></div><div><li>Heartbeat messages are enabled, exceptions should NOT be thrown. Exception trace:org.apache.hadoop.hbase.client.RetriesExhaustedException: Failed after attempts=16, exceptions:
Thu Jan 10 16:24:52 UTC 2019, null, java.net.SocketTimeoutException: callTimeout=1000, callDuration=1007: Call to 371f24e5dd0e/172.17.0.2:36361 failed on local exception: org.apache.hadoop.hbase.ipc.CallTimeoutException: Ca</li></div><div><li>java.lang.AssertionError
	at org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushWithThroughputLimit(TestFlushWithThroughputController.java:154)
	at org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControlForStripedStore(TestFlushWithThroughputController.java:227)
</li></div><div><li>java.lang.AssertionError
	at org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushWithThroughputLimit(TestFlushWithThroughputController.java:154)
	at org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControl(TestFlushWithThroughputController.java:160)
</li></div><div><li>Waiting timed out after [3,000] msec Still waiting for log roll on regionservers: [371f24e5dd0e,32993,1547148562520]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;5&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.parentWithSpecifiedEndKeyCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:268)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testLastParentCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:167)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testAsyncSnapshotWillNotBlockSnapshotHFileCleaner(TestSnapshotFromMaster.java:445)
</li></div><div><li>Archived hfiles [] and table hfiles [f647b327639c4eb186372673db0f142d] is missing snapshot file:906c1e43edac463ebcdf98c1fe96fe72</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testRpcThrottleWhenStartup</div></li><li><div>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.org.apache.hadoop.hbase.quotas.TestQuotaAdmin</div></li><li><div>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.org.apache.hadoop.hbase.quotas.TestQuotaAdmin</div></li><li><div>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota</div></li><li><div>org.apache.hadoop.hbase.quotas.TestQuotaAdmin.testSetModifyRemoveRPCQuota</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.testRecoveryAndDoubleExecution</div></li><li><div>org.apache.hadoop.hbase.master.procedure.TestDisableTableProcedure.testRecoveryAndDoubleExecution</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.coprocessor.example.TestWriteHeavyIncrementObserverWithMemStoreCompaction.test</div></li><li><div>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory</div></li><li><div>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory</div></li><li><div>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS</div></li><li><div>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS</div></li><li><div>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.testKillRS</div></li><li><div>org.apache.hadoop.hbase.rsgroup.TestRSGroupsKillRS.testKillRS</div></li><li><div>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.testRowsSeenMetricWithAsync</div></li><li><div>org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters.org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters</div></li><li><div>org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters.org.apache.hadoop.hbase.client.replication.TestReplicationAdminWithClusters</div></li><li><div>org.apache.hadoop.hbase.master.TestMasterMetricsWrapper.testOfflineRegion</div></li><li><div>org.apache.hadoop.hbase.master.TestSplitWALManager.testCreateSplitWALProcedures</div></li><li><div>org.apache.hadoop.hbase.master.TestSplitWALManager.org.apache.hadoop.hbase.master.TestSplitWALManager</div></li><li><div>org.apache.hadoop.hbase.master.TestSplitWALManager.org.apache.hadoop.hbase.master.TestSplitWALManager</div></li><li><div>org.apache.hadoop.hbase.namespace.TestNamespaceAuditor.testRegionMerge</div></li><li><div>org.apache.hadoop.hbase.regionserver.TestCompactSplitThread.testFlushWithTableCompactionDisabled</div></li><li><div>org.apache.hadoop.hbase.regionserver.TestScannerHeartbeatMessages.testHeartbeatWithSparseRowFilter</div></li><li><div>org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControlForStripedStore</div></li><li><div>org.apache.hadoop.hbase.regionserver.throttle.TestFlushWithThroughputController.testFlushControl</div></li><li><div>org.apache.hadoop.hbase.replication.multiwal.TestReplicationEndpointWithMultipleWAL.testMetricsSourceBaseSourcePassthrough</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.rsgroup.TestRSGroupsAdmin2.testMoveServersAndTables</div></li><li><div>org.apache.hadoop.hbase.master.TestCatalogJanitor.testLastParentCleanedEvenIfDaughterGoneFirst</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testAsyncSnapshotWillNotBlockSnapshotHFileCleaner</div></li><li><div>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hive"><div style="font-weight:bold;" class="panel-heading">HIVE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>e92df8dd6aae2dffa24cabbfce343704a7fe9a04</div><div><b>Last Run: </b>08-01-2019 15:00 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 7723</div><div>Failed Count : 5</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7726</div><div>Failed Count : 4</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7723</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7723</div><div>Failed Count : 1</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7726</div><div>Failed Count : 1</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7726</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7696</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7726</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tez.TestConverters.testTaskSpecToFragmentSpec</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div><div><li>org.apache.hive.service.cli.session.TestSessionManagerMetrics.testAbandonedSessionMetrics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.kafka.TransactionalKafkaWriterTest.writerFencedOut</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div><div><li>expected:&lt;[1]&gt; but was:&lt;[]&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Expected exception: java.io.IOException</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hive.llap.tez.TestConverters.testTaskSpecToFragmentSpec</div></li><li><div>org.apache.hive.service.cli.session.TestSessionManagerMetrics.testAbandonedSessionMetrics</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hive.kafka.TransactionalKafkaWriterTest.writerFencedOut</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</div></li><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</div></li><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="kafka"><div style="font-weight:bold;" class="panel-heading">KAFKA<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>4616c0aaff5766b6305baeed521efdfaae0094e8</div><div><b>Last Run: </b>27-12-2018 19:00 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 2</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 5</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div><div><li>kafka.api.UserQuotaTest.testQuotaOverrideDelete</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.PlaintextConsumerTest.testLowMaxFetchSizeForRequestAndPartition</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testAdvertisedListenerUpdate</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testAddRemoveSaslListeners</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testKeyStoreAlter</li></div><div><li>org.apache.kafka.streams.integration.TableTableJoinIntegrationTest.testOuterOuter[caching enabled = true]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToZonedDateTime</li></div><div><li>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToEarliestOnTopicsAndPartitions</li></div><div><li>kafka.api.CustomQuotaCallbackTest.testCustomQuotaCallback</li></div><div><li>kafka.api.SaslOAuthBearerSslEndToEndAuthorizationTest.testProduceConsumeTopicAutoCreateTopicCreateAcl</li></div><div><li>kafka.api.SslEndToEndAuthorizationTest.testProduceConsumeWithPrefixedAcls</li></div><div><li>kafka.server.DeleteTopicsRequestTest.testValidDeleteTopicRequests</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div><div><li>java.lang.AssertionError: Client with id=QuotasTestProducer-1 should have been throttled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Timed out before consuming expected 2700 records. The number consumed was 1080.</li></div><div><li>org.scalatest.junit.JUnitTestFailedError: Expected exception java.util.concurrent.ExecutionException to be thrown, but java.util.concurrent.TimeoutException was thrown</li></div><div><li>java.lang.AssertionError: Partition [__consumer_offsets,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Partition [testtopic2,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Condition not met within timeout 15000. Never received expected final result.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Expected that consumer group has consumed all messages from topic/partition.</li></div><div><li>java.lang.AssertionError: Partition [topic1,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Too many quotaLimit calls Map(PRODUCE -&gt; 1, FETCH -&gt; 1, REQUEST -&gt; 3)</li></div><div><li>org.apache.kafka.common.errors.TopicExistsException: Topic 'e2etopic' already exists.</li></div><div><li>kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING</li></div><div><li>java.lang.AssertionError: There should be no errors, found Map(topic-3 -&gt; NONE, topic-4 -&gt; REQUEST_TIMED_OUT)</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li><li><div>kafka.api.UserQuotaTest.testQuotaOverrideDelete</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.PlaintextConsumerTest.testLowMaxFetchSizeForRequestAndPartition</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testAdvertisedListenerUpdate</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testAddRemoveSaslListeners</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testKeyStoreAlter</div></li><li><div>org.apache.kafka.streams.integration.TableTableJoinIntegrationTest.testOuterOuter[caching enabled = true]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToZonedDateTime</div></li><li><div>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToEarliestOnTopicsAndPartitions</div></li><li><div>kafka.api.CustomQuotaCallbackTest.testCustomQuotaCallback</div></li><li><div>kafka.api.SaslOAuthBearerSslEndToEndAuthorizationTest.testProduceConsumeTopicAutoCreateTopicCreateAcl</div></li><li><div>kafka.api.SslEndToEndAuthorizationTest.testProduceConsumeWithPrefixedAcls</div></li><li><div>kafka.server.DeleteTopicsRequestTest.testValidDeleteTopicRequests</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="knox"><div style="font-weight:bold;" class="panel-heading">KNOX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>fc1f085f30d9bdb9ba75d640c487e8bb1a8c0607</div><div><b>Last Run: </b>18-12-2018 01:04 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1102</div><div>Failed Count : 2</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 3</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1101</div><div>Failed Count : 9</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithServicesAndApplications</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithEmptyNamespace</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testServiceAnonAuth</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithApplication</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithLeadingSlashNamespace</li></div><div><li>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading</li></div><div><li>org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig</li></div><div><li>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</li></div><div><li>org.apache.knox.gateway.Knox242FuncTest.org.apache.knox.gateway.Knox242FuncTest</li></div><div><li>org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.testZooKeeperConfigMonitorSASLNodesExistWithAcceptableACL</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Timed out 10000 waiting for URL http://localhost:38127/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>test timed out after 5000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.setUp(AtlasZookeeperURLManagerTest.java:59)
</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.setUp(AtlasZookeeperURLManagerTest.java:59)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.createZNodes(HBaseZookeeperURLManagerTest.java:121)
	at org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading(HBaseZookeeperURLManagerTest.java:71)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.configureAndStartZKCluster(ZooKeeperConfigurationMonitorTest.java:113)
	at org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.setupSuite(ZooKeeperConfigurationMonitorTest.java:84)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig(RemoteConfigurationRegistryClientServiceTest.ja</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig(RemoteConfigurationRegistryClientServiceTest.java:152)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig(RemoteConfigurationRegistryClientServiceTest.jav</li></div><div><li>Timed out 10000 waiting for URL http://localhost:39710/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>Timed out 10000 waiting for URL http://localhost:45967/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.configureAndStartZKCluster(RemoteConfigurationMonitorTest.java:190)
	at org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.setupTest(RemoteConfigurationMonitorTest.java:112)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithServicesAndApplications</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithEmptyNamespace</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testServiceAnonAuth</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithApplication</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithLeadingSlashNamespace</div></li><li><div>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading</div></li><li><div>org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig</div></li><li><div>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</div></li><li><div>org.apache.knox.gateway.Knox242FuncTest.org.apache.knox.gateway.Knox242FuncTest</div></li><li><div>org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.testZooKeeperConfigMonitorSASLNodesExistWithAcceptableACL</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="metron"><div style="font-weight:bold;" class="panel-heading">METRON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>862244721fef7ba7389000cc2f3d0756bb07d69d</div><div><b>Last Run: </b>06-01-2019 12:39 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="oozie"><div style="font-weight:bold;" class="panel-heading">OOZIE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>8e8ebbbc7f12c144a3f26a838474d1ce3b801b1b</div><div><b>Last Run: </b>10-01-2019 21:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 3110</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 1</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 1</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 8</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3110</div><div>Failed Count : 852</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.test.TestWorkflowRetries.testWorkflowWithStartAndEndCompletesSuccessfully</li></div><div><li>org.apache.oozie.action.hadoop.TestIntegrationGitActionExecutor.testWhenRepoIsClonedThenGitIndexContentIsReadSuccessfully</li></div><div><li>org.apache.oozie.action.hadoop.TestHiveActionExecutor.testHiveAction</li></div><div><li>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</li></div><div><li>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2ActionFails</li></div><div><li>org.apache.oozie.action.hadoop.TestPyspark.testPyspark</li></div><div><li>org.apache.oozie.action.hadoop.TestSqoopActionExecutor.testSqoopActionWithArgsAndFreeFormQuery</li></div><div><li>org.apache.oozie.action.hadoop.TestSqoopActionExecutor.testSqoopActionWithRedundantPrefix</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.TestV1JobsServletBundleEngine.testGetBundleJobs</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowPurgeableSubSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededCoordinator</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowOverTheLimitRunningSubWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testRunningCoordinator</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testFailedBundle</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundlePurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowWithPurgeOldCoordActionTurnedOn</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleUnpurgeableCoordinatorUnpurgebleWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleUnpurgeableCoordinatorUnpurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testRunningWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundlePurgeableCoordinatorPurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowSucceededSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowOverTheLimitSucceededSubWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testKilledCoordinator</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorUnpurgeableWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleOverTheLimitPurgeableCoordinatorsOverTheLimitPurgeableWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorMultiplePurgeableWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededBundle</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowRunningSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowUnpurgeableSubSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testFailedCoordinator</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableBundlePurgeableCoordiatorPurgeableWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableBundlePurgeableCoordinatorPurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testComplexExample</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorOverTheLimitUnpurgeableWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleAndOverTheLimitUnpurgeableCoordinatorsAndWorkflows</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testKilledBundle</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflowWithNullEndTimeValidLastModifiedTime</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testRunningBundle</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testKilledWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testFailedWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testRunningWorkflowSucceededSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorUnpurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowWithNullEndTimeValidLastModifiedTime</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowUnpurgeableSubWorkflowPurgeableSubSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</li></div><div><li>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowWithPurgeOldCoordActionTurnedOff</li></div><div><li>org.apache.oozie.command.TestSLAAlertXCommand.testCoordSLAAlertCommands</li></div><div><li>org.apache.oozie.command.TestSLAAlertXCommand.testSLAChangeCommand</li></div><div><li>org.apache.oozie.command.TestSLAAlertXCommand.testBundleSLAAlertCommands</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleKillNoOp</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendNoOp</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleResumeNoOp</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleKillNegative</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendNegative</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendResumeKillSuccess</li></div><div><li>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleResumeNegative</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange3</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundlePauseExtendMaterializesCoordinator</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeReport</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testCheckBundleActionStatus</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeNegative1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeNegative2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend3</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendFailed</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfo1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfoFailed</li></div><div><li>org.apache.oozie.command.bundle.TestBundleJobsXCommand.testBundleJobsGet</li></div><div><li>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill3</li></div><div><li>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKillFailed</li></div><div><li>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause1</li></div><div><li>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause2</li></div><div><li>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause3</li></div><div><li>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpauseNeg1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPrep</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPausedWithError</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPaused</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspended</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspendedWithError</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunKilledCoordinator</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunWithError</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartDryrun</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartWithFailedCoordinator</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart1</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart2</li></div><div><li>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart3</li></div><div><li>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testJobXmlCommentRemoved</li></div><div><li>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testDuplicateCoordName</li></div><div><li>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testCoordJobNameParameterization</li></div><div><li>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testMultipleCoordSubmit</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testStartTime</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testCatchupJob</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testKill</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testNoAbandoned</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testMessage_withMixedStatus</li></div><div><li>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testMessage_withTimedout</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordKillNoOp</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendNoOp</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendNegative</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendResumeKillSuccess</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordResumeNoOp</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordResumeNegative</li></div><div><li>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordKillNegative</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNoDatasetDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeout</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTimeWithPushDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNone</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputMissingDependencies</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckFuture</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testLastOnly</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testCoordActionInputCheckXCommandUniqueness</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testRequeueInterval</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithUnResolved</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testResolveCoordConfiguration</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testHarFileInputCheck</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNonExistingNameNode</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testExceptionOnInvalidElFunction</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheck</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTimeWithPushDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithException</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNoDatasetDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeout</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestActionCreationTimeWithPushDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestActionCreationTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNone</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputMissingDependencies</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckFuture</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testLastOnly</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testCoordActionInputCheckXCommandUniqueness</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testRequeueInterval</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeoutWithUnResolved</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestCurrentTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testResolveCoordConfiguration</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testHarFileInputCheck</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNonExistingNameNode</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testExceptionOnInvalidElFunction</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheck</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestCurrentTimeWithPushDependency</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeoutWithException</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPullPushDependencyMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPushDependencyMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPullDependencyMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionInputLogicMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionReadyXCommand.testActionsInREADYNone</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionReadyXCommand.testActionsInREADYLastOnly</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testReadyToSkipped</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testVerifyPrecondition</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testWaitingToSkipped</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithErrorReported</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartCommand</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithError1003Reported</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithEscapeStrings</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableBasic</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableAdvanced</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionsIgnoreXCommand.testCoordActionsIgnore</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</li></div><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandDate</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangePauseTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoord_throwException</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Changefailed</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testChangeTimeDeleteRunning</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeConcurrency</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeXCommand</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime1</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime2</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime3</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime4</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Failed</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Killed</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Ignored</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeStatus</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testProcessLookaheadActions</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTimeDeleteAction</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTimeBeforeStart</li></div><div><li>org.apache.oozie.command.coord.TestCoordChangeXCommand.testRunningStatusWithNoAction</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnLatestAsEndInstance</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksParamerized</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnStartInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysParameterized</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksStartingFromPrevWeek</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testComputeNextNominalTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordAbsolute</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnStartInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsParamerized</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsStartingFromPrevMonth</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksInitialInstaceNotInPhase</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testGetNextValidActionTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnStartInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnInitialInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPushDependencies</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordOffset</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnLatestAsEndInstance</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsInitialInstaceNotInPhase</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysInitialInstaceNotInPhase</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullDeps</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnLatestAsEndInstance</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysStartingFromPrevDay</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullAndPushDeps</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnInitialInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnInitialInstanceIsLater</li></div><div><li>org.apache.oozie.command.coord.TestCoordELExtensions.testCoordELActionMater</li></div><div><li>org.apache.oozie.command.coord.TestCoordJobsXCommand.testCoordJobsGet</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillForBackwardSupport</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillRemovePushMissingDeps</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess1</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess2</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailed</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillWaiting</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillXCommandUniqueness</li></div><div><li>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailedOnAction</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays1</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays2</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays3</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterizationEndOfMonths</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleLessThanDuration</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency1</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency2</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency3</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency4</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency5</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency6</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency7</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testFailedJobNotMaterializeActions</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELMonthlyFrequenciesEqual</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTSEndsCronFrequencyEveryTwentiethHour</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testTimeout</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTELEveryTwentiethDay</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTELEveryTwentyFourthHour</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleEqualsDurationDSTChange</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTEndsELFrequencyEveryTwentiethHour</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogRelativePath</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalog</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupHours</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupDaysFixedDate</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleMoreThanDurationNoDSTChange</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELEveryThirdMonthFrequenciesEqual</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithDST1</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithDST2</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTStartsELFrequencyEveryTwentiethHour</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCurrentTimeCheck</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime1</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime2</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testSuccessedJobSlaParseElFunctionVariableInMaterializeActions</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogIncorrectURI</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMater</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testLastOnlyMaterialization</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testGetDryrun</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterwithCronFrequencyWithThrottle</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupStandardTimeStartDaylightMaterialization</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterEndOfWeeks</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTSwitchELAndCronFrequencyEveryThirtiethMinute</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatThrottle</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupMinute</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronEveryTwentiethDay</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenBeginningDSTCronAndELHourlyFrequenciesEqual</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenEndingDSTCronAndELHourlyFrequenciesEqual</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand1</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand2</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand3</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand4</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELDailyFrequenciesEqual</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupDaylightStartStandardMaterialization</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTStartsCronFrequencyEveryTwentiethHour</li></div><div><li>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommandWithRunningServices.testActionMaterWithPauseTimeAfterStartTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testLogMessagePrefix</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOut</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableSingleDep</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithUnresolvedMissingDependencies</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV1</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV2</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV3</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testResolveCoordConfiguration</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testExceptionOnInvalidElFunction</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException1</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException2</li></div><div><li>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testRequeueOnException</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInFailed</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate1</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate2</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate3</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate4</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithFailedOptionDirectoryPresent</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPaused</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupForHCat</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunFailedCoordAction</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupNoOutputEvents</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunKilledCoord</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg1</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg2</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithConfOption</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport1</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport2</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport3</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithFailedOption</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanup</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupOption</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunRefresh</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInDoneWithError</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDateNeg</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPausedWithError</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions1</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions2</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions3</li></div><div><li>org.apache.oozie.command.coord.TestCoordRerunXCommand.testActionStatusRunningWithWorkflow</li></div><div><li>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrepWithBackwardCompatibility</li></div><div><li>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendWithErrorAndResumeWithErrorForRunning</li></div><div><li>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrep</li></div><div><li>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForRunning</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testELdataIO_xsd_4</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithDryRun</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithWrongNamespace</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSchemaError</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmit</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesInputEvent</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithValidFrequency</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleEndInstancesInputEvent</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSLAAlertWithNewlyCreatedActions</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithSLAAlertsDisable</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testDuplicateDatasetNameInIncludeFile</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithVarAppName</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithBundleId</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitReservedVars</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesOutputEvent</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithCronFrequency</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithTimeout</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoDatasets</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithUnMaterializableFrequency</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithDoneFlag</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIdenticalStartAndEndTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleStartInstancesInputEvent</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testCheckMaximumFrequency</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDatasetInitialInstance</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testAvailConfigDefaults</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitFixedValues</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDateOffset</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithStartTimeAfterEndTime</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithSLA</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoControls</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testMissingConfigDefaults</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoUsername</li></div><div><li>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIncludeFile</li></div><div><li>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive2</li></div><div><li>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendPostive</li></div><div><li>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive</li></div><div><li>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendNegative</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordFromBundleJobChangeDefinition</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testReRunRefresh</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testConfChange</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordDefUnsupportedChange</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordDefinitionChangeError</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordFromBundleJobChangeConf</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testDefinitionChange</li></div><div><li>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testUpdateControl</li></div><div><li>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testNormalCase</li></div><div><li>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testWorkflowInstanceMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testActionMissing</li></div><div><li>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testOffsetOutOfRange</li></div><div><li>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testLenOutOfRange</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringLauncher</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckErrorUserRetry</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testCheckInterval</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheck</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckErrorNoUserRetry</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition1</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition2</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition3</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition4</li></div><div><li>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringMRAction</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndError</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testStartNonTransientWithCoordActionUpdate</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessageError</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndDataNotSet</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testStartErrorWithUserRetry</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessageError2</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testStartTransient</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessage</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testStartNonTransient</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndNonTransient</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testExecutionDataNotSet</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndErrorWithUserRetry</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndNonTransientWithCoordActionUpdate</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testEndTransient</li></div><div><li>org.apache.oozie.command.wf.TestActionErrors.testStartError</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionReuseWfJobAppPath</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartToCheckRetry</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition1</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition2</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition3</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStart</li></div><div><li>org.apache.oozie.command.wf.TestActionStartXCommand.testActionWithEscapedStringAndCDATA</li></div><div><li>org.apache.oozie.command.wf.TestActionUserRetry.testUserRetryPolicy</li></div><div><li>org.apache.oozie.command.wf.TestActionUserRetry.testUserRetry</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillNoOp</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillSuspendResumeSuccess</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillNegative</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkResumeNoOp</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkSuspendNoOp</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillSuccess</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkResumeNegative</li></div><div><li>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkSuspendNegative</li></div><div><li>org.apache.oozie.command.wf.TestCompletedActionXCommand.testEarlyCallbackTimeout</li></div><div><li>org.apache.oozie.command.wf.TestCompletedActionXCommand.testEarlyCallbackTransitionToRunning</li></div><div><li>org.apache.oozie.command.wf.TestForkedActionStartXCommand.testWfFailure</li></div><div><li>org.apache.oozie.command.wf.TestForkedActionStartXCommand.testWfSuccess</li></div><div><li>org.apache.oozie.command.wf.TestLastModified.testWorkflowRun</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunFork</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunWithExistingCoodConf</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerun</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRedeploy</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunWithExistingConf</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunFromFailNodes</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunVariableSub</li></div><div><li>org.apache.oozie.command.wf.TestReRunXCommand.testRerunDisableForChild</li></div><div><li>org.apache.oozie.command.wf.TestSignalXCommand.testJoinFail</li></div><div><li>org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPoints</li></div><div><li>org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPointsAll</li></div><div><li>org.apache.oozie.command.wf.TestSubmitHiveXCommand.testWFXmlGeneration</li></div><div><li>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGenerationNewConfigProps</li></div><div><li>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGeneration</li></div><div><li>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGenerationNegative1</li></div><div><li>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGeneration1</li></div><div><li>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGeneration2</li></div><div><li>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGenerationNegative1</li></div><div><li>org.apache.oozie.command.wf.TestSubmitSqoopXCommand.testWFXmlGeneration</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsDir</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testWFConfigDefaultVarResolve</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testProtoConfStorage</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitReservedVars</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testDryrunValidXml</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitAppName</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFileNegative</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFile1</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFile2</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testDryrunInvalidXml</li></div><div><li>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitLongXml</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillFailed</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillChildJob</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillSuccess</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowActionRetryInfoXCommand.testRetryConsoleUrlForked</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowActionRetryInfoXCommand.testRetryConsoleUrl</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailedToLoadJob</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testChildId</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailed</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess1</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess2</li></div><div><li>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccessAfterNodeDefUpgrade</li></div><div><li>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDate</li></div><div><li>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDateRange</li></div><div><li>org.apache.oozie.coord.TestCoordUtils.testGetWhereClause</li></div><div><li>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIds</li></div><div><li>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIdsRange</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionsPh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValuePh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMaxPh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMinPh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testHCatPartitionExists</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDatabase</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValue</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testTable</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testHCatTableExists</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitions</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionsPh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testTablePh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilterPh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDatabasePh1</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilter</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMax</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMin</li></div><div><li>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitions</li></div><div><li>org.apache.oozie.coord.input.dependency.TestCoordOldInputDependency.testNoMissingInputDependencies</li></div><div><li>org.apache.oozie.coord.input.dependency.TestCoordOldInputDependency.testOneMissingInputDependency</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testNestedConditionWithRange</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testCurrentLatest</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testLatestRange</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testNestedCondition3</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testExists</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testLatestRangeComplex</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testHcatHdfsLatest</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testHcatHdfs</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSimpleOr1</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testAnd</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testWait</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSingeSetWithMin</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCoordWithoutInputCheck</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombineNegative</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testLatestRange</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition1</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition2</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition3</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombine</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testMinWait</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testWaitFail</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testMultipleInstance</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testValidateRange</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSimpleOr</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testDryRun</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombineWithMin</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testLatest</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testAndWithMin</li></div><div><li>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testOrWithMin</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testInvalidXMLCoordinatorFailsForNoDuplicates</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEventDependencies</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testWorkflowJobEvent</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testWorkflowJobEventError</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testForNoDuplicatesWorkflowEvents</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testWorkflowActionEvent</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testForNoDuplicatesCoordinatorActionEvents</li></div><div><li>org.apache.oozie.event.TestEventQueue.testQueueOperations</li></div><div><li>org.apache.oozie.event.TestEventQueue.testMemoryEventQueueBasic</li></div><div><li>org.apache.oozie.service.TestActionCheckerService.testActionCheckerService</li></div><div><li>org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceCoord</li></div><div><li>org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceDelay</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForBundle</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAdminUsersWithAdminFile</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAdminUsersWithAdminGroup</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForCoord</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoSuccess</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceUseDefaultGroup</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testDefaultGroup</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoFailure</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testWhenDefinedInAdminFileAndConfigurationThenAllowBothAdmins</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoDefaultSuccess</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testWhenDefinedInConfigurationThenAdminPrivilegesAllowed</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testErrors</li></div><div><li>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceUseACLs</li></div><div><li>org.apache.oozie.service.TestCoordMaterializeTriggerService.testMaxMatThrottleNotPickedMultipleJobs</li></div><div><li>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService1</li></div><div><li>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService2</li></div><div><li>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService3</li></div><div><li>org.apache.oozie.service.TestCoordMaterializeTriggerService.testMaxMatThrottleNotPicked</li></div><div><li>org.apache.oozie.service.TestEventHandlerService.testEventLogging</li></div><div><li>org.apache.oozie.service.TestEventHandlerService.testEventListener</li></div><div><li>org.apache.oozie.service.TestEventHandlerService.testService</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testPurgeMissingDependencies</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testDependencyCacheWithHA</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testCheckAfterActionDelete</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testPurgeMissingDependencies</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testDependencyCacheWithHA</li></div><div><li>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testCheckAfterActionDelete</li></div><div><li>org.apache.oozie.service.TestHASLAService.testSLAUpdateWithHA</li></div><div><li>org.apache.oozie.service.TestHASLAService.testSLAAlertCommandWithHA</li></div><div><li>org.apache.oozie.service.TestHASLAService.testNoDuplicateEventsInHA</li></div><div><li>org.apache.oozie.service.TestHASLAService.testSLAFailOverWithHA</li></div><div><li>org.apache.oozie.service.TestHAShareLibService.testShareLibWithHA</li></div><div><li>org.apache.oozie.service.TestHCatAccessorService.testGetHCatConfLocal</li></div><div><li>org.apache.oozie.service.TestHCatAccessorService.testGetHCatConfHDFS</li></div><div><li>org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfoNoDefault</li></div><div><li>org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfo</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testCreateFileSystem</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testCheckSupportedFilesystem</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testCreateJobClient</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testValidateNameNode</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testCreateLocalResourceForConfigurationFile</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testActionConfigurations</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testCreateYarnClient</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testService</li></div><div><li>org.apache.oozie.service.TestHadoopAccessorService.testValidateJobTracker</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationDefault</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testTopicAsUser</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationJobType</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testMixedTopic1</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testMixedTopic2</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testTopicAsFixedString</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testTopicProperties1</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testTopicProperties2</li></div><div><li>org.apache.oozie.service.TestJMSTopicService.testTopicAsJobId</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testPartitionDependency</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMaxElementsInMemory</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToIdle</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToLive</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testHCatCanonicalHostName</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMemoryUsageAndSpeed</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerService.testPartitionDependency</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerService.testHCatCanonicalHostName</li></div><div><li>org.apache.oozie.service.TestPartitionDependencyManagerService.testMemoryUsageAndSpeed</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testPauseCoordinatorForBackwardSupport</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testUnpauseBundleAndCoordinator</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testPauseUnpause1</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testPauseUnpause2</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testPauseBundleAndCoordinator</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testStart1</li></div><div><li>org.apache.oozie.service.TestPauseTransitService.testStart2</li></div><div><li>org.apache.oozie.service.TestPurgeService.testPurgeServiceForBundle</li></div><div><li>org.apache.oozie.service.TestPurgeService.testPurgeServiceForCoordinator</li></div><div><li>org.apache.oozie.service.TestPurgeService.testPurgeServiceForWorkflow</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSuspended</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordCreateNotifyParentFailed</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryService</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaitingRegisterPartition</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testBundleRecoveryCoordCreate</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForKilled</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testBundleRecoveryCoordExists</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForResume</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSubmitted</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaiting</li></div><div><li>org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryUserRetry</li></div><div><li>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn10Threads</li></div><div><li>org.apache.oozie.service.TestShareLibService.testPurgeJar</li></div><div><li>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn5Threads</li></div><div><li>org.apache.oozie.service.TestShareLibService.testCreateLauncherLibPath</li></div><div><li>org.apache.oozie.service.TestShareLibService.testShareLibLoadFilesFromHDFS</li></div><div><li>org.apache.oozie.service.TestShareLibService.testDuplicateJarsInDistributedCache</li></div><div><li>org.apache.oozie.service.TestShareLibService.testLoadMappingFilesFromDFSandLocalFs</li></div><div><li>org.apache.oozie.service.TestShareLibService.testShareLib</li></div><div><li>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn1Thread</li></div><div><li>org.apache.oozie.service.TestShareLibService.testGetShareLibCompatible</li></div><div><li>org.apache.oozie.service.TestShareLibService.testRetentionOverflow</li></div><div><li>org.apache.oozie.service.TestShareLibService.testParsingALotOfShareLibsParallel</li></div><div><li>org.apache.oozie.service.TestShareLibService.testShareLibLoadFilesFromLocalFs</li></div><div><li>org.apache.oozie.service.TestShareLibService.testLoadfromDFS</li></div><div><li>org.apache.oozie.service.TestShareLibService.testPurgeShareLib</li></div><div><li>org.apache.oozie.service.TestShareLibService.testConfFileAddedToDistributedCache</li></div><div><li>org.apache.oozie.service.TestShareLibService.testGetShareLibPath</li></div><div><li>org.apache.oozie.service.TestShareLibService.testfailFast</li></div><div><li>org.apache.oozie.service.TestShareLibService.testShareLibLoadFileMultipleFile</li></div><div><li>org.apache.oozie.service.TestShareLibService.testMetafileSymlink</li></div><div><li>org.apache.oozie.service.TestShareLibService.testConfFileAddedToActionConf</li></div><div><li>org.apache.oozie.service.TestShareLibService.testMultipleLauncherCall</li></div><div><li>org.apache.oozie.service.TestShareLibService.testAddShareLib_pig</li></div><div><li>org.apache.oozie.service.TestShareLibService.testAddShareLibDistributedCache</li></div><div><li>org.apache.oozie.service.TestShareLibService.testPurgeLauncherJar</li></div><div><li>org.apache.oozie.service.TestShareLibService.testAddShareLib_pig_withVersion</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitRunningWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendAndResume</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSucceeded</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded1</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded2</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded3</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceStaleCoordActions</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testFoo</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitWithLock</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePaused</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleRunningAfterCoordResume</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspended</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceUpdateLastModifiedTime</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser1</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser2</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceRunningWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePaused</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceBackwardSupport</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceForTimeout</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitRunningFromKilled</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning1</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning2</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning3</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedByUser</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspendedWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusCoordSubmitFails</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceDoneWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePausedWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceNoDoneWithErrorForBackwardSupport</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceForTerminalStates</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitRunningFromKilled</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled2</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedBottomUp</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePausedWithError</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testBundleStatusNotTransitionFromKilled</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitWithLock</li></div><div><li>org.apache.oozie.service.TestStatusTransitService.testCoordNotTransitionfromKilled</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testGetJobIdsForThisServer</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testGetServerUrls</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testIsLeader</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testInstrumentation</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testRegisterUnregister</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testisAllServerRequest</li></div><div><li>org.apache.oozie.service.TestZKJobsConcurrencyService.testIsJobIdForThisServer</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReentrantMultipleThread</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testTimeoutWaitingWriteLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testWriteReadLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testTimeoutWaitingWriteLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testTimeoutTimingOutWriteLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testLocksAreReused</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testWaitWriteLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testWaitWriteLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReentrantMultipleCall</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testLocksAreGarbageCollected</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testLockRelease</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testLockReaper</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testRegisterUnregister</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReadLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReadWriteLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testWriteReadLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReadWriteLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testNoWaitWriteLockOozies</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testTimeoutTimingOutWriteLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testReadLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testNoWaitWriteLockThreads</li></div><div><li>org.apache.oozie.service.TestZKLocksService.testRetriableRelease</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testRegisterUnregister</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testBulkJobForZKUUIDService</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testFallback</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testResetSequence_withMultiThread</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testResetSequence</li></div><div><li>org.apache.oozie.service.TestZKUUIDService.testIDGeneration</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testDisableLogOverWS</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers_coordActionList</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testNoDashInConversionPattern</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testTuncateLog</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testRegisterUnregister</li></div><div><li>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers_errorLog</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testSafeMode</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testPurgeServiceV2</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testOsEnv</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testConfiguration</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testVersion</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testShareLib</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testJavaSysProps</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testShareLibUpdate</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testMetrics</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testPurgeServiceV2Negative</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testStatus</li></div><div><li>org.apache.oozie.servlet.TestAdminServlet.testShareLib_withKey</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleCoordinators</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testNoRecords</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testSingleRecord</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testDefaultStatus</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleRecords</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testBundleIdWithCoordId</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testBundleId</li></div><div><li>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleBundleIdsForName</li></div><div><li>org.apache.oozie.servlet.TestCallbackServlet.testCallbackPost</li></div><div><li>org.apache.oozie.servlet.TestCallbackServlet.testCallbackGet</li></div><div><li>org.apache.oozie.servlet.TestJobsServlet.testJobs</li></div><div><li>org.apache.oozie.servlet.TestJobsServlet.testDiffUser</li></div><div><li>org.apache.oozie.servlet.TestJobsServlet.testSubmit</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testJobInfo</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testGraph</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testReRun</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testStart</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testKill</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testJobDef</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testJobLog</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testResume</li></div><div><li>org.apache.oozie.servlet.TestV0JobServlet.testSuspend</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testSafeMode</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testPurgeServiceV1</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testOsEnv</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testAvailableTimeZones</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testConfiguration</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testVersion</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testInstrumentation</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testJavaSysProps</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testV1QueueDump</li></div><div><li>org.apache.oozie.servlet.TestV1AdminServlet.testStatus</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testCoordActionKill</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testJobInfo</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testStartForErrorCode</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testGraph</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testStart</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testKill</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testCoordChange</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testJobDef</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testJobLog</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testResume</li></div><div><li>org.apache.oozie.servlet.TestV1JobServlet.testSuspend</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineReRun</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStart</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetBundleJob</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStreamLog</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetDefinition</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineKill</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineChange</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineSuspend</li></div><div><li>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineResume</li></div><div><li>org.apache.oozie.servlet.TestV1JobsServlet.testJobs</li></div><div><li>org.apache.oozie.servlet.TestV1JobsServlet.testSubmit</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testCoordActionIgnore</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testJobInfo</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameNormal</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionFromV0JobServlet</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameLenOutOfRange</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetCoordActionReruns</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameActionNameMissing</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameUnparseableLen</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionFromV1JobServlet</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameUnparseableOffset</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameOffsetOutOfRange</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testCoordJobIgnore</li></div><div><li>org.apache.oozie.servlet.TestV2JobServlet.testJobStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatusSlaStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testIdBundleId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testNonExistentBundleId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testNonMatchingParentIdBundleId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventMultipleEventStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatusStartMet</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventSlaStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleName</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletIntegration.testEmptyQueryParams</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletIntegration.testFilterNameTypo</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletIntegration.testValidRequest</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusDescendingJobId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameNominalStart</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameNominalEnd</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameAppType</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameExpectedEndStart</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdExpectedEndInterval</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameActualStartStart</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameCreatedStart</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameExpectedStart</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLALikeAppNamePercentSign</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameCreatedEnd</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdActualEndInterval</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppName</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusAscendingJobId</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdActualStartInterval</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAscendingAppName</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAParentIdExpectedStartInterval</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatus</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameUserName</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLALikeAppNameLikeUnderscore1</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusDescendingDefaultField</li></div><div><li>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameActualEndStart</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundle</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateSla</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative2</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative3</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative4</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWF</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFonHDFSNegative</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateSlaNegative</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFonHDFS</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundleNegative1</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundleNegative2</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinator</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinatorNegative1</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinatorNegative2</li></div><div><li>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative</li></div><div><li>org.apache.oozie.servlet.TestVersionServlet.testVersion</li></div><div><li>org.apache.oozie.store.TestDBWorkflowStore.testDBWorkflowStore</li></div><div><li>org.apache.oozie.util.TestZKUtils.testGetZKId</li></div><div><li>org.apache.oozie.util.TestZKUtils.testMetaData</li></div><div><li>org.apache.oozie.util.TestZKUtils.testGetZKIdIndex</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Could not find own virtual machine</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>YARN App state for app application_1547194572497_0003 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;RUNNING&gt; but was:&lt;SUCCEEDED&gt;</li></div><div><li>YARN App state for app application_1547194489406_0002 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1547194671450_0002 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1547195282766_0003 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>Error applying authorization policy on hive configuration: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</li></div><div><li>YARN App state for app application_1547196461926_0004 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1547195599009_0003 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div><div><li>YARN App state for app application_1547195599009_0008 expected:&lt;FINISHED&gt; but was:&lt;RUNNING&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>E0712: Could not create lib paths list for application [testPath], Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div><div><li>Call From f0212e6d23a2/172.17.0.2 to localhost:37843 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.test.TestWorkflowRetries.testWorkflowWithStartAndEndCompletesSuccessfully</div></li><li><div>org.apache.oozie.action.hadoop.TestIntegrationGitActionExecutor.testWhenRepoIsClonedThenGitIndexContentIsReadSuccessfully</div></li><li><div>org.apache.oozie.action.hadoop.TestHiveActionExecutor.testHiveAction</div></li><li><div>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2Action</div></li><li><div>org.apache.oozie.action.hadoop.TestHive2ActionExecutor.testHive2ActionFails</div></li><li><div>org.apache.oozie.action.hadoop.TestPyspark.testPyspark</div></li><li><div>org.apache.oozie.action.hadoop.TestSqoopActionExecutor.testSqoopActionWithArgsAndFreeFormQuery</div></li><li><div>org.apache.oozie.action.hadoop.TestSqoopActionExecutor.testSqoopActionWithRedundantPrefix</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.TestV1JobsServletBundleEngine.testGetBundleJobs</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowPurgeableSubSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededCoordinator</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowOverTheLimitRunningSubWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testRunningCoordinator</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testFailedBundle</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundlePurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowWithPurgeOldCoordActionTurnedOn</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleUnpurgeableCoordinatorUnpurgebleWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleUnpurgeableCoordinatorUnpurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testRunningWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundlePurgeableCoordinatorPurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowSucceededSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowOverTheLimitSucceededSubWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testKilledCoordinator</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorUnpurgeableWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleOverTheLimitPurgeableCoordinatorsOverTheLimitPurgeableWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorMultiplePurgeableWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededBundle</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testSucceededWorkflowRunningSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowUnpurgeableSubSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testFailedCoordinator</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableBundlePurgeableCoordiatorPurgeableWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableBundlePurgeableCoordinatorPurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testComplexExample</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorOverTheLimitUnpurgeableWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableBundleAndOverTheLimitUnpurgeableCoordinatorsAndWorkflows</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testKilledBundle</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflowWithNullEndTimeValidLastModifiedTime</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testRunningBundle</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testKilledWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testFailedWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testRunningWorkflowSucceededSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorUnpurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowPurgeableSubWorkflowWithNullEndTimeValidLastModifiedTime</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableWorkflowUnpurgeableSubWorkflowPurgeableSubSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testPurgeableCoordinatorPurgeableWorkflowPurgeableSubWorkflow</div></li><li><div>org.apache.oozie.command.TestPurgeXCommand.testUnpurgeableCoordinatorPurgeableWorkflowWithPurgeOldCoordActionTurnedOff</div></li><li><div>org.apache.oozie.command.TestSLAAlertXCommand.testCoordSLAAlertCommands</div></li><li><div>org.apache.oozie.command.TestSLAAlertXCommand.testSLAChangeCommand</div></li><li><div>org.apache.oozie.command.TestSLAAlertXCommand.testBundleSLAAlertCommands</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleKillNoOp</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendNoOp</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleResumeNoOp</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleKillNegative</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendNegative</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleSuspendResumeKillSuccess</div></li><li><div>org.apache.oozie.command.bundle.TestBulkBundleXCommand.testBulkBundleResumeNegative</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChange3</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundlePauseExtendMaterializesCoordinator</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeReport</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testCheckBundleActionStatus</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeNegative1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleChangeXCommand.testBundleChangeNegative2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspend3</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendFailed</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobSuspendXCommand.testBundleSuspendWithError</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfo1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobXCommand.testBundleJobInfoFailed</div></li><li><div>org.apache.oozie.command.bundle.TestBundleJobsXCommand.testBundleJobsGet</div></li><li><div>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKill3</div></li><li><div>org.apache.oozie.command.bundle.TestBundleKillXCommand.testBundleKillFailed</div></li><li><div>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause1</div></li><li><div>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause2</div></li><li><div>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpause3</div></li><li><div>org.apache.oozie.command.bundle.TestBundlePauseUnpauseXCommand.testBundlePauseUnpauseNeg1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPrep</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPausedWithError</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInPaused</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspended</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunInSuspendedWithError</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunKilledCoordinator</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerun2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleRerunXCommand.testBundleRerunWithError</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartDryrun</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartWithFailedCoordinator</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStartNegative2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart1</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart2</div></li><li><div>org.apache.oozie.command.bundle.TestBundleStartXCommand.testBundleStart3</div></li><li><div>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testJobXmlCommentRemoved</div></li><li><div>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testDuplicateCoordName</div></li><li><div>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testCoordJobNameParameterization</div></li><li><div>org.apache.oozie.command.bundle.TestBundleSubmitXCommand.testMultipleCoordSubmit</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testStartTime</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testCatchupJob</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testKill</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testNoAbandoned</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testMessage_withMixedStatus</div></li><li><div>org.apache.oozie.command.coord.TestAbandonedCoordChecker.testMessage_withTimedout</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordKillNoOp</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendNoOp</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendNegative</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordSuspendResumeKillSuccess</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordResumeNoOp</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordResumeNegative</div></li><li><div>org.apache.oozie.command.coord.TestBulkCoordXCommand.testBulkCoordKillNegative</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNoDatasetDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeout</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTimeWithPushDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestActionCreationTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNone</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputMissingDependencies</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckFuture</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testLastOnly</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testCoordActionInputCheckXCommandUniqueness</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testRequeueInterval</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithUnResolved</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testResolveCoordConfiguration</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testHarFileInputCheck</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testNonExistingNameNode</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testExceptionOnInvalidElFunction</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheck</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testActionInputCheckLatestCurrentTimeWithPushDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommand.testTimeoutWithException</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNoDatasetDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeout</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestActionCreationTimeWithPushDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestActionCreationTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNone</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputMissingDependencies</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckFuture</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testLastOnly</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testCoordActionInputCheckXCommandUniqueness</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testRequeueInterval</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeoutWithUnResolved</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestCurrentTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testResolveCoordConfiguration</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testHarFileInputCheck</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testNonExistingNameNode</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testExceptionOnInvalidElFunction</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheck</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testActionInputCheckLatestCurrentTimeWithPushDependency</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionInputCheckXCommandNonUTC.testTimeoutWithException</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPullPushDependencyMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPushDependencyMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionPullDependencyMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionMissingDependenciesXCommand.testCoordActionInputLogicMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionReadyXCommand.testActionsInREADYNone</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionReadyXCommand.testActionsInREADYLastOnly</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testReadyToSkipped</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testVerifyPrecondition</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionSkipXCommand.testWaitingToSkipped</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithErrorReported</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartCommand</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithError1003Reported</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionStartXCommand.testActionStartWithEscapeStrings</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableBasic</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionUpdatePushMissingDependency.testUpdateCoordTableAdvanced</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionsIgnoreXCommand.testCoordActionsIgnore</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</div></li><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandDate</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangePauseTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoord_throwException</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Changefailed</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testChangeTimeDeleteRunning</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeConcurrency</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeXCommand</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime1</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime2</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime3</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime4</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Failed</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Killed</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordStatus_Ignored</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeStatus</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testProcessLookaheadActions</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTimeDeleteAction</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testCoordChangeEndTimeBeforeStart</div></li><li><div>org.apache.oozie.command.coord.TestCoordChangeXCommand.testRunningStatusWithNoAction</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnLatestAsEndInstance</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksParamerized</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnStartInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysParameterized</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksStartingFromPrevWeek</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testComputeNextNominalTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordAbsolute</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnStartInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsParamerized</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsStartingFromPrevMonth</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksInitialInstaceNotInPhase</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testGetNextValidActionTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnStartInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysFailOnInitialInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPushDependencies</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordOffset</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnLatestAsEndInstance</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsInitialInstaceNotInPhase</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysInitialInstaceNotInPhase</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullDeps</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnLatestAsEndInstance</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfDaysStartingFromPrevDay</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testDryRunPullAndPushDeps</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfWeeksFailOnInitialInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordCommandUtils.testCoordEndOfMonthsFailOnInitialInstanceIsLater</div></li><li><div>org.apache.oozie.command.coord.TestCoordELExtensions.testCoordELActionMater</div></li><li><div>org.apache.oozie.command.coord.TestCoordJobsXCommand.testCoordJobsGet</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillForBackwardSupport</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillRemovePushMissingDeps</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess1</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillSuccess2</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailed</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillWaiting</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillXCommandUniqueness</div></li><li><div>org.apache.oozie.command.coord.TestCoordKillXCommand.testCoordKillFailedOnAction</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays1</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays2</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupRelativeDays3</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterizationEndOfMonths</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleLessThanDuration</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency1</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency2</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency3</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency4</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency5</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency6</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithCronFrequency7</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testFailedJobNotMaterializeActions</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELMonthlyFrequenciesEqual</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTSEndsCronFrequencyEveryTwentiethHour</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testTimeout</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTELEveryTwentiethDay</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTELEveryTwentyFourthHour</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleEqualsDurationDSTChange</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTEndsELFrequencyEveryTwentiethHour</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogRelativePath</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalog</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupHours</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupDaysFixedDate</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCronFrequencyCatchupThrottleMoreThanDurationNoDSTChange</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELEveryThirdMonthFrequenciesEqual</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithDST1</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithDST2</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTStartsELFrequencyEveryTwentiethHour</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testCurrentTimeCheck</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime1</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterWithPauseTime2</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testSuccessedJobSlaParseElFunctionVariableInMaterializeActions</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterForHcatalogIncorrectURI</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMater</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testLastOnlyMaterialization</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testGetDryrun</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterwithCronFrequencyWithThrottle</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupStandardTimeStartDaylightMaterialization</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testActionMaterEndOfWeeks</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTSwitchELAndCronFrequencyEveryThirtiethMinute</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatThrottle</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupMinute</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronEveryTwentiethDay</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenBeginningDSTCronAndELHourlyFrequenciesEqual</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenEndingDSTCronAndELHourlyFrequenciesEqual</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand1</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand2</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand3</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMatLookupCommand4</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenChangingDSTCronAndELDailyFrequenciesEqual</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testMaterializationLookupDaylightStartStandardMaterialization</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommand.testWhenDSTStartsCronFrequencyEveryTwentiethHour</div></li><li><div>org.apache.oozie.command.coord.TestCoordMaterializeTransitionXCommandWithRunningServices.testActionMaterWithPauseTimeAfterStartTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testLogMessagePrefix</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOut</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableSingleDep</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithUnresolvedMissingDependencies</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV1</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV2</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testUpdateCoordTableMultipleDepsV3</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testResolveCoordConfiguration</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testExceptionOnInvalidElFunction</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException1</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testTimeOutWithException2</div></li><li><div>org.apache.oozie.command.coord.TestCoordPushDependencyCheckXCommand.testRequeueOnException</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInFailed</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate1</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate2</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate3</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDate4</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithFailedOptionDirectoryPresent</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPaused</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupForHCat</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunFailedCoordAction</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupNoOutputEvents</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunKilledCoord</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg1</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActionsNeg2</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithConfOption</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport1</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport2</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunForBackwardSupport3</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunWithFailedOption</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanup</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunCleanupOption</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunRefresh</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInDoneWithError</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunDateNeg</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunInPausedWithError</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions1</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions2</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testCoordRerunActions3</div></li><li><div>org.apache.oozie.command.coord.TestCoordRerunXCommand.testActionStatusRunningWithWorkflow</div></li><li><div>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrepWithBackwardCompatibility</div></li><li><div>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendWithErrorAndResumeWithErrorForRunning</div></li><li><div>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForPrep</div></li><li><div>org.apache.oozie.command.coord.TestCoordResumeXCommand.testCoordSuspendAndResumeForRunning</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testELdataIO_xsd_4</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithDryRun</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithWrongNamespace</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSchemaError</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmit</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesInputEvent</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithValidFrequency</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleEndInstancesInputEvent</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSLAAlertWithNewlyCreatedActions</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithSLAAlertsDisable</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testDuplicateDatasetNameInIncludeFile</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithVarAppName</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithBundleId</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitReservedVars</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleInstancesOutputEvent</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithCronFrequency</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithTimeout</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoDatasets</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithUnMaterializableFrequency</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitWithDoneFlag</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIdenticalStartAndEndTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithMultipleStartInstancesInputEvent</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testCheckMaximumFrequency</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDatasetInitialInstance</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testAvailConfigDefaults</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitFixedValues</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitDateOffset</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithStartTimeAfterEndTime</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithSLA</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoControls</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testMissingConfigDefaults</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testSubmitNoUsername</div></li><li><div>org.apache.oozie.command.coord.TestCoordSubmitXCommand.testBasicSubmitWithIncludeFile</div></li><li><div>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive2</div></li><li><div>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendPostive</div></li><li><div>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendWithErrorPostive</div></li><li><div>org.apache.oozie.command.coord.TestCoordSuspendXCommand.testCoordSuspendNegative</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordFromBundleJobChangeDefinition</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testReRunRefresh</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testConfChange</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordDefUnsupportedChange</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordDefinitionChangeError</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testCoordFromBundleJobChangeConf</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testDefinitionChange</div></li><li><div>org.apache.oozie.command.coord.TestCoordUpdateXCommand.testUpdateControl</div></li><li><div>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testNormalCase</div></li><li><div>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testWorkflowInstanceMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testActionMissing</div></li><li><div>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testOffsetOutOfRange</div></li><li><div>org.apache.oozie.command.coord.TestCoordWfActionInfoXCommand.testLenOutOfRange</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringLauncher</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckErrorUserRetry</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testCheckInterval</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheck</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckErrorNoUserRetry</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition1</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition2</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition3</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckPreCondition4</div></li><li><div>org.apache.oozie.command.wf.TestActionCheckXCommand.testActionCheckTransientDuringMRAction</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndError</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testStartNonTransientWithCoordActionUpdate</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessageError</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndDataNotSet</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testStartErrorWithUserRetry</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessageError2</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testStartTransient</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testKillNodeErrorMessage</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testStartNonTransient</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndNonTransient</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testExecutionDataNotSet</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndErrorWithUserRetry</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndNonTransientWithCoordActionUpdate</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testEndTransient</div></li><li><div>org.apache.oozie.command.wf.TestActionErrors.testStartError</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionReuseWfJobAppPath</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartToCheckRetry</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition1</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition2</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStartPreCondition3</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionStart</div></li><li><div>org.apache.oozie.command.wf.TestActionStartXCommand.testActionWithEscapedStringAndCDATA</div></li><li><div>org.apache.oozie.command.wf.TestActionUserRetry.testUserRetryPolicy</div></li><li><div>org.apache.oozie.command.wf.TestActionUserRetry.testUserRetry</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillNoOp</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillSuspendResumeSuccess</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillNegative</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkResumeNoOp</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkSuspendNoOp</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testbulkWfKillSuccess</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkResumeNegative</div></li><li><div>org.apache.oozie.command.wf.TestBulkWorkflowXCommand.testBulkSuspendNegative</div></li><li><div>org.apache.oozie.command.wf.TestCompletedActionXCommand.testEarlyCallbackTimeout</div></li><li><div>org.apache.oozie.command.wf.TestCompletedActionXCommand.testEarlyCallbackTransitionToRunning</div></li><li><div>org.apache.oozie.command.wf.TestForkedActionStartXCommand.testWfFailure</div></li><li><div>org.apache.oozie.command.wf.TestForkedActionStartXCommand.testWfSuccess</div></li><li><div>org.apache.oozie.command.wf.TestLastModified.testWorkflowRun</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunFork</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunWithExistingCoodConf</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerun</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRedeploy</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunWithExistingConf</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunFromFailNodes</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunVariableSub</div></li><li><div>org.apache.oozie.command.wf.TestReRunXCommand.testRerunDisableForChild</div></li><li><div>org.apache.oozie.command.wf.TestSignalXCommand.testJoinFail</div></li><li><div>org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPoints</div></li><li><div>org.apache.oozie.command.wf.TestSignalXCommand.testSuspendPointsAll</div></li><li><div>org.apache.oozie.command.wf.TestSubmitHiveXCommand.testWFXmlGeneration</div></li><li><div>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGenerationNewConfigProps</div></li><li><div>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGeneration</div></li><li><div>org.apache.oozie.command.wf.TestSubmitMRXCommand.testWFXmlGenerationNegative1</div></li><li><div>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGeneration1</div></li><li><div>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGeneration2</div></li><li><div>org.apache.oozie.command.wf.TestSubmitPigXCommand.testWFXmlGenerationNegative1</div></li><li><div>org.apache.oozie.command.wf.TestSubmitSqoopXCommand.testWFXmlGeneration</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsDir</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testWFConfigDefaultVarResolve</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testProtoConfStorage</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitReservedVars</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testDryrunValidXml</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitAppName</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFileNegative</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFile1</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testAppPathIsFile2</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testDryrunInvalidXml</div></li><li><div>org.apache.oozie.command.wf.TestSubmitXCommand.testSubmitLongXml</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillFailed</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillChildJob</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowActionKillXCommand.testWfActionKillSuccess</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowActionRetryInfoXCommand.testRetryConsoleUrlForked</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowActionRetryInfoXCommand.testRetryConsoleUrl</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailedToLoadJob</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testChildId</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillFailed</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess1</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccess2</div></li><li><div>org.apache.oozie.command.wf.TestWorkflowKillXCommand.testWfKillSuccessAfterNodeDefUpgrade</div></li><li><div>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDate</div></li><li><div>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromDateRange</div></li><li><div>org.apache.oozie.coord.TestCoordUtils.testGetWhereClause</div></li><li><div>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIds</div></li><li><div>org.apache.oozie.coord.TestCoordUtils.testGetCoordActionsFromIdsRange</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionsPh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValuePh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMaxPh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMinPh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testHCatPartitionExists</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDatabase</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitionValue</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testTable</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testHCatTableExists</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataOutPartitions</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionsPh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testTablePh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilterPh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDatabasePh1</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testdataInPartitionFilter</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMax</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitionMin</div></li><li><div>org.apache.oozie.coord.TestHCatELFunctions.testDataInPartitions</div></li><li><div>org.apache.oozie.coord.input.dependency.TestCoordOldInputDependency.testNoMissingInputDependencies</div></li><li><div>org.apache.oozie.coord.input.dependency.TestCoordOldInputDependency.testOneMissingInputDependency</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testNestedConditionWithRange</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testCurrentLatest</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testLatestRange</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testNestedCondition3</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testExists</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testLatestRangeComplex</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testHcatHdfsLatest</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordInputLogicPush.testHcatHdfs</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSimpleOr1</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testAnd</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testWait</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSingeSetWithMin</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCoordWithoutInputCheck</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombineNegative</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testLatestRange</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition1</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition2</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testNestedCondition3</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombine</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testMinWait</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testWaitFail</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testMultipleInstance</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testValidateRange</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testSimpleOr</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testDryRun</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testCombineWithMin</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testLatest</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testAndWithMin</div></li><li><div>org.apache.oozie.coord.input.logic.TestCoordinatorInputLogic.testOrWithMin</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testInvalidXMLCoordinatorFailsForNoDuplicates</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEventDependencies</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testWorkflowJobEvent</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testWorkflowJobEventError</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testForNoDuplicatesWorkflowEvents</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testWorkflowActionEvent</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testForNoDuplicatesCoordinatorActionEvents</div></li><li><div>org.apache.oozie.event.TestEventQueue.testQueueOperations</div></li><li><div>org.apache.oozie.event.TestEventQueue.testMemoryEventQueueBasic</div></li><li><div>org.apache.oozie.service.TestActionCheckerService.testActionCheckerService</div></li><li><div>org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceCoord</div></li><li><div>org.apache.oozie.service.TestActionCheckerService.testActionCheckerServiceDelay</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForBundle</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAdminUsersWithAdminFile</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAdminUsersWithAdminGroup</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceForCoord</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoSuccess</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceUseDefaultGroup</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testDefaultGroup</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoFailure</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testWhenDefinedInAdminFileAndConfigurationThenAllowBothAdmins</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizedSystemInfoDefaultSuccess</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testWhenDefinedInConfigurationThenAdminPrivilegesAllowed</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testErrors</div></li><li><div>org.apache.oozie.service.TestAuthorizationService.testAuthorizationServiceUseACLs</div></li><li><div>org.apache.oozie.service.TestCoordMaterializeTriggerService.testMaxMatThrottleNotPickedMultipleJobs</div></li><li><div>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService1</div></li><li><div>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService2</div></li><li><div>org.apache.oozie.service.TestCoordMaterializeTriggerService.testCoordMaterializeTriggerService3</div></li><li><div>org.apache.oozie.service.TestCoordMaterializeTriggerService.testMaxMatThrottleNotPicked</div></li><li><div>org.apache.oozie.service.TestEventHandlerService.testEventLogging</div></li><li><div>org.apache.oozie.service.TestEventHandlerService.testEventListener</div></li><li><div>org.apache.oozie.service.TestEventHandlerService.testService</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testPurgeMissingDependencies</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testDependencyCacheWithHA</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerEhCache.testCheckAfterActionDelete</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testPurgeMissingDependencies</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testDependencyCacheWithHA</div></li><li><div>org.apache.oozie.service.TestHAPartitionDependencyManagerService.testCheckAfterActionDelete</div></li><li><div>org.apache.oozie.service.TestHASLAService.testSLAUpdateWithHA</div></li><li><div>org.apache.oozie.service.TestHASLAService.testSLAAlertCommandWithHA</div></li><li><div>org.apache.oozie.service.TestHASLAService.testNoDuplicateEventsInHA</div></li><li><div>org.apache.oozie.service.TestHASLAService.testSLAFailOverWithHA</div></li><li><div>org.apache.oozie.service.TestHAShareLibService.testShareLibWithHA</div></li><li><div>org.apache.oozie.service.TestHCatAccessorService.testGetHCatConfLocal</div></li><li><div>org.apache.oozie.service.TestHCatAccessorService.testGetHCatConfHDFS</div></li><li><div>org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfoNoDefault</div></li><li><div>org.apache.oozie.service.TestHCatAccessorService.testGetJMSConnectionInfo</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testCreateFileSystem</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testCheckSupportedFilesystem</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testCreateJobClient</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testValidateNameNode</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testCreateLocalResourceForConfigurationFile</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testActionConfigurations</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testCreateYarnClient</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testService</div></li><li><div>org.apache.oozie.service.TestHadoopAccessorService.testValidateJobTracker</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationDefault</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testTopicAsUser</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testIncorrectConfigurationJobType</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testMixedTopic1</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testMixedTopic2</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testTopicAsFixedString</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testTopicProperties1</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testTopicProperties2</div></li><li><div>org.apache.oozie.service.TestJMSTopicService.testTopicAsJobId</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testPartitionDependency</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMaxElementsInMemory</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToIdle</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testEvictionOnTimeToLive</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testHCatCanonicalHostName</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerEhcache.testMemoryUsageAndSpeed</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerService.testPartitionDependency</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerService.testHCatCanonicalHostName</div></li><li><div>org.apache.oozie.service.TestPartitionDependencyManagerService.testMemoryUsageAndSpeed</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testPauseCoordinatorForBackwardSupport</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testUnpauseBundleAndCoordinator</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testPauseUnpause1</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testPauseUnpause2</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testPauseBundleAndCoordinator</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testStart1</div></li><li><div>org.apache.oozie.service.TestPauseTransitService.testStart2</div></li><li><div>org.apache.oozie.service.TestPurgeService.testPurgeServiceForBundle</div></li><li><div>org.apache.oozie.service.TestPurgeService.testPurgeServiceForCoordinator</div></li><li><div>org.apache.oozie.service.TestPurgeService.testPurgeServiceForWorkflow</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSuspended</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordCreateNotifyParentFailed</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryService</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaitingRegisterPartition</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testBundleRecoveryCoordCreate</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForKilled</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testBundleRecoveryCoordExists</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForResume</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForSubmitted</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testCoordActionRecoveryServiceForWaiting</div></li><li><div>org.apache.oozie.service.TestRecoveryService.testWorkflowActionRecoveryUserRetry</div></li><li><div>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn10Threads</div></li><li><div>org.apache.oozie.service.TestShareLibService.testPurgeJar</div></li><li><div>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn5Threads</div></li><li><div>org.apache.oozie.service.TestShareLibService.testCreateLauncherLibPath</div></li><li><div>org.apache.oozie.service.TestShareLibService.testShareLibLoadFilesFromHDFS</div></li><li><div>org.apache.oozie.service.TestShareLibService.testDuplicateJarsInDistributedCache</div></li><li><div>org.apache.oozie.service.TestShareLibService.testLoadMappingFilesFromDFSandLocalFs</div></li><li><div>org.apache.oozie.service.TestShareLibService.testShareLib</div></li><li><div>org.apache.oozie.service.TestShareLibService.testDeterminingLatestSharelibPathOn1Thread</div></li><li><div>org.apache.oozie.service.TestShareLibService.testGetShareLibCompatible</div></li><li><div>org.apache.oozie.service.TestShareLibService.testRetentionOverflow</div></li><li><div>org.apache.oozie.service.TestShareLibService.testParsingALotOfShareLibsParallel</div></li><li><div>org.apache.oozie.service.TestShareLibService.testShareLibLoadFilesFromLocalFs</div></li><li><div>org.apache.oozie.service.TestShareLibService.testLoadfromDFS</div></li><li><div>org.apache.oozie.service.TestShareLibService.testPurgeShareLib</div></li><li><div>org.apache.oozie.service.TestShareLibService.testConfFileAddedToDistributedCache</div></li><li><div>org.apache.oozie.service.TestShareLibService.testGetShareLibPath</div></li><li><div>org.apache.oozie.service.TestShareLibService.testfailFast</div></li><li><div>org.apache.oozie.service.TestShareLibService.testShareLibLoadFileMultipleFile</div></li><li><div>org.apache.oozie.service.TestShareLibService.testMetafileSymlink</div></li><li><div>org.apache.oozie.service.TestShareLibService.testConfFileAddedToActionConf</div></li><li><div>org.apache.oozie.service.TestShareLibService.testMultipleLauncherCall</div></li><li><div>org.apache.oozie.service.TestShareLibService.testAddShareLib_pig</div></li><li><div>org.apache.oozie.service.TestShareLibService.testAddShareLibDistributedCache</div></li><li><div>org.apache.oozie.service.TestShareLibService.testPurgeLauncherJar</div></li><li><div>org.apache.oozie.service.TestShareLibService.testAddShareLib_pig_withVersion</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitRunningWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendAndResume</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSucceeded</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded1</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded2</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSucceeded3</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceStaleCoordActions</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testFoo</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitWithLock</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePaused</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleRunningAfterCoordResume</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspended</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceUpdateLastModifiedTime</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser1</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceKilledByUser2</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceRunningWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePaused</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceBackwardSupport</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceForTimeout</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitRunningFromKilled</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning1</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning2</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceRunning3</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedByUser</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceSuspendedWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusCoordSubmitFails</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceDoneWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServicePausedWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceNoDoneWithErrorForBackwardSupport</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceForTerminalStates</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitRunningFromKilled</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusTransitServiceKilled2</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServiceSuspendedBottomUp</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitServicePausedWithError</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testBundleStatusNotTransitionFromKilled</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordStatusTransitWithLock</div></li><li><div>org.apache.oozie.service.TestStatusTransitService.testCoordNotTransitionfromKilled</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testGetJobIdsForThisServer</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testGetServerUrls</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testIsLeader</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testInstrumentation</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testRegisterUnregister</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testisAllServerRequest</div></li><li><div>org.apache.oozie.service.TestZKJobsConcurrencyService.testIsJobIdForThisServer</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReentrantMultipleThread</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testTimeoutWaitingWriteLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testWriteReadLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testTimeoutWaitingWriteLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testTimeoutTimingOutWriteLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testLocksAreReused</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testWaitWriteLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testWaitWriteLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReentrantMultipleCall</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testLocksAreGarbageCollected</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testLockRelease</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testLockReaper</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testRegisterUnregister</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReadLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReadWriteLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testWriteReadLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReadWriteLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testNoWaitWriteLockOozies</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testTimeoutTimingOutWriteLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testReadLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testNoWaitWriteLockThreads</div></li><li><div>org.apache.oozie.service.TestZKLocksService.testRetriableRelease</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testRegisterUnregister</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testBulkJobForZKUUIDService</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testFallback</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testResetSequence_withMultiThread</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testResetSequence</div></li><li><div>org.apache.oozie.service.TestZKUUIDService.testIDGeneration</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testDisableLogOverWS</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers_coordActionList</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testNoDashInConversionPattern</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testTuncateLog</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testRegisterUnregister</div></li><li><div>org.apache.oozie.service.TestZKXLogStreamingService.testStreamingWithMultipleOozieServers_errorLog</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testSafeMode</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testPurgeServiceV2</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testOsEnv</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testConfiguration</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testVersion</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testShareLib</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testJavaSysProps</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testShareLibUpdate</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testMetrics</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testPurgeServiceV2Negative</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testStatus</div></li><li><div>org.apache.oozie.servlet.TestAdminServlet.testShareLib_withKey</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleCoordinators</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testNoRecords</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testSingleRecord</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testDefaultStatus</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleRecords</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testBundleIdWithCoordId</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testBundleId</div></li><li><div>org.apache.oozie.servlet.TestBulkMonitorWebServiceAPI.testMultipleBundleIdsForName</div></li><li><div>org.apache.oozie.servlet.TestCallbackServlet.testCallbackPost</div></li><li><div>org.apache.oozie.servlet.TestCallbackServlet.testCallbackGet</div></li><li><div>org.apache.oozie.servlet.TestJobsServlet.testJobs</div></li><li><div>org.apache.oozie.servlet.TestJobsServlet.testDiffUser</div></li><li><div>org.apache.oozie.servlet.TestJobsServlet.testSubmit</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testJobInfo</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testGraph</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testReRun</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testStart</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testKill</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testJobDef</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testJobLog</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testResume</div></li><li><div>org.apache.oozie.servlet.TestV0JobServlet.testSuspend</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testSafeMode</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testPurgeServiceV1</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testOsEnv</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testAvailableTimeZones</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testConfiguration</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testVersion</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testInstrumentation</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testJavaSysProps</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testV1QueueDump</div></li><li><div>org.apache.oozie.servlet.TestV1AdminServlet.testStatus</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testCoordActionKill</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testJobInfo</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testStartForErrorCode</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testGraph</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testStart</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testKill</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testCoordChange</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testJobDef</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testJobLog</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testResume</div></li><li><div>org.apache.oozie.servlet.TestV1JobServlet.testSuspend</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineReRun</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStart</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetBundleJob</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineStreamLog</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineGetDefinition</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineKill</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineChange</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineSuspend</div></li><li><div>org.apache.oozie.servlet.TestV1JobServletBundleEngine.testBundleEngineResume</div></li><li><div>org.apache.oozie.servlet.TestV1JobsServlet.testJobs</div></li><li><div>org.apache.oozie.servlet.TestV1JobsServlet.testSubmit</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testCoordActionIgnore</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testJobInfo</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameNormal</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionFromV0JobServlet</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameLenOutOfRange</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetCoordActionReruns</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameActionNameMissing</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameUnparseableLen</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionFromV1JobServlet</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameUnparseableOffset</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testGetWfActionByJobIdAndNameOffsetOutOfRange</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testCoordJobIgnore</div></li><li><div>org.apache.oozie.servlet.TestV2JobServlet.testJobStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatusSlaStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testIdBundleId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testNonExistentBundleId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testNonMatchingParentIdBundleId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventMultipleEventStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventEventStatusStartMet</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleSLAEventSlaStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletBundle.testBundleName</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletIntegration.testEmptyQueryParams</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletIntegration.testFilterNameTypo</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletIntegration.testValidRequest</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusDescendingJobId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameNominalStart</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameNominalEnd</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameAppType</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameExpectedEndStart</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdExpectedEndInterval</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameActualStartStart</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameCreatedStart</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameExpectedStart</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLALikeAppNamePercentSign</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameCreatedEnd</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdActualEndInterval</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppName</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusAscendingJobId</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLASLAParentIdActualStartInterval</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAscendingAppName</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAParentIdExpectedStartInterval</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatus</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameUserName</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLALikeAppNameLikeUnderscore1</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameJobStatusDescendingDefaultField</div></li><li><div>org.apache.oozie.servlet.TestV2SLAServletSLAJSONResponse.testSLAAppNameActualEndStart</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundle</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateSla</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative2</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative3</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative4</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWF</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFonHDFSNegative</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateSlaNegative</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFonHDFS</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundleNegative1</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateBundleNegative2</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinator</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinatorNegative1</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateCoordinatorNegative2</div></li><li><div>org.apache.oozie.servlet.TestV2ValidateServlet.testValidateWFNegative</div></li><li><div>org.apache.oozie.servlet.TestVersionServlet.testVersion</div></li><li><div>org.apache.oozie.store.TestDBWorkflowStore.testDBWorkflowStore</div></li><li><div>org.apache.oozie.util.TestZKUtils.testGetZKId</div></li><li><div>org.apache.oozie.util.TestZKUtils.testMetaData</div></li><li><div>org.apache.oozie.util.TestZKUtils.testGetZKIdIndex</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="phoenix"><div style="font-weight:bold;" class="panel-heading">PHOENIX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>3bd426f10337b6e109ab7394bd4a4023039fd0e8</div><div><b>Last Run: </b>10-01-2019 23:45 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1737</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="pig"><div style="font-weight:bold;" class="panel-heading">PIG<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>8cecd74b7f64f7e964ea7164637da1011e1ab92f</div><div><b>Last Run: </b>10-01-2019 02:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ranger"><div style="font-weight:bold;" class="panel-heading">RANGER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>e1b0105eee67bb73c56b66b2dda1c3424555ab3e</div><div><b>Last Run: </b>10-01-2019 01:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="slider"><div style="font-weight:bold;" class="panel-heading">SLIDER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/develop</div><div><b>Last Revision: </b>1d4f519d763210f46e327338be72efa99e65cb5d</div><div><b>Last Run: </b>10-01-2019 20:54 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 1</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>assert 0 == killAM(SIGTERM)
         |  |      |
         |  123    -15
         false</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="spark"><div style="font-weight:bold;" class="panel-heading">SPARK<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>29a7d2da44585d91a9e94bf88dc7b1f42a0e5674</div><div><b>Last Run: </b>08-01-2019 08:46 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 15424</div><div>Failed Count : 1</div><div>Skipped Count : 652</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>&amp;#010;Assert on query failed: name: Exception thrown in awaitResult: &amp;#010;org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)&amp;#010; org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)&amp;#010; org.apache.spark.util.RpcUtils$.mak</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="sqoop"><div style="font-weight:bold;" class="panel-heading">SQOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>4a22691f45d7d66157ff6dfaa8fca5581e0a8955</div><div><b>Last Run: </b>04-01-2019 01:55 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="storm"><div style="font-weight:bold;" class="panel-heading">STORM<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>8a475696e908c53f1c06bf1a8f373d8ac0483427</div><div><b>Last Run: </b>10-01-2019 01:18 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1176</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="tez"><div style="font-weight:bold;" class="panel-heading">TEZ<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>a03181742abbf064557d096b3d3cd231c64c1a2a</div><div><b>Last Run: </b>10-01-2019 03:53 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1835</div><div>Failed Count : 4</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 3</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.dag.impl.TestDAGImpl.testGetDAGStatusReturnOnDagFailed</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.auxservices.TestShuffleHandler.testRecoveryFromOtherVersions</li></div><div><li>org.apache.tez.auxservices.TestShuffleHandler.testRecovery</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.dag.history.ats.acls.TestATSHistoryWithACLs.testDAGACls</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.client.TestTezClient.testPreWarmWithTimeout</li></div><div><li>org.apache.tez.dag.api.client.TestTimelineReaderFactory.testPseudoAuthenticatorConnectionUrlShouldHaveUserName</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.tez.dag.app.dag.impl.TestDAGImpl.runTestGetDAGStatusReturnOnDagFinished(TestDAGImpl.java:1854)
	at org.apache.tez.dag.app.dag.impl.TestDAGImpl.testGetDAGStatusReturnOnDagFailed(TestDAGImpl.java:1778)
</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-4761860004232821375.8: /tmp/libleveldbjni-64-1-4761860004232821375.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>javax.xml.bind.UnmarshalException
 - with linked exception:
[javax.xml.stream.XMLStreamException: java.net.SocketException: Socket closed]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;KILLED&gt; but was:&lt;FAILED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Time taken is not as expected</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.dag.impl.TestDAGImpl.testGetDAGStatusReturnOnDagFailed</div></li><li><div>org.apache.tez.auxservices.TestShuffleHandler.testRecoveryFromOtherVersions</div></li><li><div>org.apache.tez.auxservices.TestShuffleHandler.testRecovery</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.history.ats.acls.TestATSHistoryWithACLs.testDAGACls</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.client.TestTezClient.testPreWarmWithTimeout</div></li><li><div>org.apache.tez.dag.api.client.TestTimelineReaderFactory.testPseudoAuthenticatorConnectionUrlShouldHaveUserName</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zeppelin"><div style="font-weight:bold;" class="panel-heading">ZEPPELIN<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>d37cc1b611dc761b1ec69c29d6b8ceaa84f301f4</div><div><b>Last Run: </b>14-09-2018 03:06 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 868</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 2</div><div>Skipped Count : 5</div></td><td><div>Total Count : 872</div><div>Failed Count : 8</div><div>Skipped Count : 5</div></td><td><div>Total Count : 858</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 859</div><div>Failed Count : 17</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</li></div><div><li>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.helium.HeliumBundleFactoryTest.bundlePackage</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testClose</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.showPlot</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.dependenciesAreInstalled</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testNoClose</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testPySpark</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.pySparkDepLoaderTest[3]</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.testZeppelinContextResource[3]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@135fbaa4"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.tearDown(IgniteSqlInterpreterTest.java:87)
</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Fail to open IPythonInterpreter</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>com.github.eirslett.maven.plugins.frontend.lib.TaskRunnerException: 'yarn install --fetch-retries=2 --fetch-retry-factor=1 --fetch-retry-mintimeout=5000 --registry=http://registry.npmjs.org/' failed. (error code 1)</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>Index: 0, Size: 0</li></div><div><li>Index: 0, Size: 0</li></div><div><li>[%text Fail to execute line 1: import matplotlib
Traceback (most recent call last):
  File "/tmp/1536900576226-0/zeppelin_python.py", line 158, in &lt;module&gt;
    exec(code, _zcUserQueryNameSpace)
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/lib64/python2.7/site-packages/matplotlib/__init__.py", line 124, in &lt;module&gt;
    from . import cbook
ImportError: cannot import name cbook
] expected:&lt;SUCC</li></div><div><li>Index: 0, Size: 0</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;[]+---+---+
| _1| _2|
...&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]+---+---+
| _1| _2|
...&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;id name
1 a
2 b
3 c
[]&gt; but was:&lt;id name
1 a
2 b
3 c
[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0
  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]&gt;</li></div><div><li>expected:&lt;[]+---+---+
| _1| _2|
...&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]+---+---+
| _1| _2|
...&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>expected:&lt;[]2
&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]2
&gt;</li></div><div><li>expected:&lt;[]hello world
&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]hello world
&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</div></li><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</div></li><li><div>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</div></li><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</div></li><li><div>org.apache.zeppelin.helium.HeliumBundleFactoryTest.bundlePackage</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testClose</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.showPlot</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.dependenciesAreInstalled</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testNoClose</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.spark.PySparkInterpreterTest.testPySpark</div></li><li><div>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.pySparkDepLoaderTest[3]</div></li><li><div>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.testZeppelinContextResource[3]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zookeeper"><div style="font-weight:bold;" class="panel-heading">ZOOKEEPER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>4a8fda7031d68236441b13bd878936b2607c5244</div><div><b>Last Run: </b>04-01-2019 03:51 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2406</div><div>Failed Count : 2</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 2</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 1</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 4</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2395</div><div>Failed Count : 6</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalFollowerRunWithDiff</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testLeaderElectionWithDisloyalVoter_stillHasMajority</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</li></div><div><li>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</li></div><div><li>org.apache.zookeeper.test.WatcherTest.testWatcherAutoResetWithGlobal</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.PurgeTxnTest.testPurgeWhenLogRollingInProgress</li></div><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</li></div><div><li>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</li></div><div><li>org.apache.zookeeper.test.ObserverQuorumHammerTest.testHammerBasic</li></div><div><li>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>expected:&lt;4294967298&gt; but was:&lt;0&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>Server 3 should have joined quorum by now</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>test timed out after 840000 milliseconds</li></div><div><li>expected:&lt;1000&gt; but was:&lt;579&gt;</li></div><div><li>KeeperErrorCode = ConnectionLoss for /watchtest/child</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>ZkClient ops is not finished!</li></div><div><li>waiting for server 1 being up</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>test timed out after 840000 milliseconds</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalFollowerRunWithDiff</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testLeaderElectionWithDisloyalVoter_stillHasMajority</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li><li><div>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</div></li><li><div>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</div></li><li><div>org.apache.zookeeper.test.WatcherTest.testWatcherAutoResetWithGlobal</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.PurgeTxnTest.testPurgeWhenLogRollingInProgress</div></li><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li><li><div>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</div></li><li><div>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</div></li><li><div>org.apache.zookeeper.test.ObserverQuorumHammerTest.testHammerBasic</div></li><li><div>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div id="ubuntu16" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU16 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 16.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>15 (15)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>94 (33)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>68 (7)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>11 (5)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (1)</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr></tbody></table></div><div id="ubuntu18" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU18 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 18.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>76 (13)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>70 (7)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (2)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel72" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL72 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.2</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>245 (175)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (15)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>20 (20)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9 (9)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (4)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel75" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL75 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.5</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>74 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (17)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (8)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>852 (852)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>17 (14)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="ppcx86" style="display:block;font-weight:bold" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">FULL SUMMARY</div></div><table style="font-size:14" id="summarytable" class="table table-striped"><tbody><tr><th></th></tr><tr><th>Package Name</th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td>N/A</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>15 (15)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>94 (33)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>68 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>76 (13)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>70 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>245 (175)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (15)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>74 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (17)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>11 (5)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>20 (20)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9 (9)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (8)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>852 (852)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>17 (14)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (4)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div></div></body></html>