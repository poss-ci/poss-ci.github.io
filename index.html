<html><head><script src="resources/jquery.min.js"></script><link href="resources/bootstrap.min.css" rel="stylesheet"></link><link href="resources/bootstrap-theme.min.css" rel="stylesheet"></link><script src="resources/bootstrap.min.js"></script><script src="helper.js">function hideAll(){console.log("hideAll")}function showme(e){console.log("showme");var l,n=e.substring(7),o=document.getElementsByName("data");for(l=0;l&lt;o.length;l++)o[l].style.display="none";var t=document.getElementsByName("summary");for(l=0;l&lt;t.length;l++)t[l].style.display="none";document.getElementById(n).style.display="block"}</script><style>table, th, td { vertical-align:top; padding: 3px} table {table-layout:fixed} td {word-wrap:break-word} .bs-callout { padding: 5px; margin: 5px 0; border: 1px solid #eee; border-left-width: 5px; border-radius: 3px; font-weight:normal; }.bs-callout-info {border-left-color: #5bc0de;}</style></head><body><nav class="navbar navbar-light"><div style="background-color: #F0F8FF;" class="container-fluid"><ul class="nav nav-pills"><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ppcx86" onclick="showme(this.id);">FULL SUMMARY</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu16" onclick="showme(this.id);">UBUNTU16</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu18" onclick="showme(this.id);">UBUNTU18</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel72" onclick="showme(this.id);">RHEL72</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel75" onclick="showme(this.id);">RHEL75</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_developers" onclick="showme(this.id);">DEVELOPERS</a></li><p style="float:right;color:grey;font-size:13;padding-top:5px" role="presentation">08-01-2019 20:30 UTC</p></ul><div style="float:right;color:grey;font-size:12">Notations:<img src="resources/red.png" style="width: 16px; height: 16px;">Build failed </img><img src="resources/blue.png" style="width: 16px; height: 16px;">Build success with no failure </img><img src="resources/yellow.png" style="width: 16px; height: 16px;">N (M) Build success with N test failures &amp; M unique failures </img></div></div></nav><div style="table-cell" class="col-sm-2 col-md-2 sidebar"><div class="list-group"><a href="#" class="list-group-item list-group-item-action active" onclick="showme(this.id);" id="anchor_ppcx86">Packages</a><a class="list-group-item list-group-item-action" href="#" id="anchor_accumulo" onclick="showme(this.id);" title="Owned by Prajyot">ACCUMULO</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ambari" onclick="showme(this.id);" title="Owned by Prajyot">AMBARI</a><a class="list-group-item list-group-item-action" href="#" id="anchor_atlas" onclick="showme(this.id);" title="Owned by Yussuf">ATLAS</a><a class="list-group-item list-group-item-action" href="#" id="anchor_calcite" onclick="showme(this.id);" title="Owned by Pravin">CALCITE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_datafu" onclick="showme(this.id);" title="Owned by N/A">DATAFU</a><a class="list-group-item list-group-item-action" href="#" id="anchor_druid" onclick="showme(this.id);" title="Owned by N/A">DRUID</a><a class="list-group-item list-group-item-action" href="#" id="anchor_falcon" onclick="showme(this.id);" title="Owned by Yussuf">FALCON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_flume" onclick="showme(this.id);" title="Owned by Pravin">FLUME</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hadoop" onclick="showme(this.id);" title="Owned by Pravin">HADOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hbase" onclick="showme(this.id);" title="Owned by Prajyot">HBASE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hive" onclick="showme(this.id);" title="Owned by Alisha">HIVE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_kafka" onclick="showme(this.id);" title="Owned by Prajyot">KAFKA</a><a class="list-group-item list-group-item-action" href="#" id="anchor_knox" onclick="showme(this.id);" title="Owned by Yussuf">KNOX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_metron" onclick="showme(this.id);" title="Owned by Pravin">METRON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_oozie" onclick="showme(this.id);" title="Owned by Alisha">OOZIE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_phoenix" onclick="showme(this.id);" title="Owned by Prajyot">PHOENIX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_pig" onclick="showme(this.id);" title="Owned by Yussuf">PIG</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ranger" onclick="showme(this.id);" title="Owned by Yussuf">RANGER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_slider" onclick="showme(this.id);" title="Owned by Yussuf">SLIDER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_spark" onclick="showme(this.id);" title="Owned by Prajyot">SPARK</a><a class="list-group-item list-group-item-action" href="#" id="anchor_sqoop" onclick="showme(this.id);" title="Owned by Yussuf">SQOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_storm" onclick="showme(this.id);" title="Owned by Alisha">STORM</a><a class="list-group-item list-group-item-action" href="#" id="anchor_tez" onclick="showme(this.id);" title="Owned by Prajyot">TEZ</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zeppelin" onclick="showme(this.id);" title="Owned by Alisha">ZEPPELIN</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zookeeper" onclick="showme(this.id);" title="Owned by Pravin">ZOOKEEPER</a></div></div><div style="display: table-cell"><div id="developers" style="display:block;font-weight:bold;display:none;" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">DEVELOPERS</div></div><div class="panel-body"><table style="font-size:15" id="summarytable" class="table table-striped"><tr><td style="width: 100px;font-weight:bold">ALISHA</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_storm">STORM </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zeppelin">ZEPPELIN </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_oozie">OOZIE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hive">HIVE </button></td></tr><tr><td style="width: 100px;font-weight:bold">PRAVIN</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_metron">METRON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zookeeper">ZOOKEEPER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hadoop">HADOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_calcite">CALCITE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_flume">FLUME </button></td></tr><tr><td style="width: 100px;font-weight:bold">PRAJYOT</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_kafka">KAFKA </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_tez">TEZ </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hbase">HBASE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_accumulo">ACCUMULO </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_phoenix">PHOENIX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_spark">SPARK </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ambari">AMBARI </button></td></tr><tr><td style="width: 100px;font-weight:bold">YUSSUF</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_knox">KNOX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_atlas">ATLAS </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_sqoop">SQOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_slider">SLIDER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_falcon">FALCON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_pig">PIG </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ranger">RANGER </button></td></tr></table></div></div></div><div style="display: table-cell"><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="accumulo"><div style="font-weight:bold;" class="panel-heading">ACCUMULO<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>825c9b66de5694df5031a1eed3348503e667a4a2</div><div><b>Last Run: </b>01-01-2019 20:26 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 2</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1727</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 60000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ambari"><div style="font-weight:bold;" class="panel-heading">AMBARI<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> origin/trunk</div><div><b>Last Revision: </b>563d508f6eedf730e9d15183afb50790c4ffb52f</div><div><b>Last Run: </b>26-12-2018 00:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td><td><div>Total Count : 5332</div><div>Failed Count : 0</div><div>Skipped Count : 72</div></td></tr><tr><td>Result</td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="atlas"><div style="font-weight:bold;" class="panel-heading">ATLAS<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>97e131a58849d17145d9ccc0997c050866e532c3</div><div><b>Last Run: </b>05-12-2018 15:22 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 969</div><div>Failed Count : 1</div><div>Skipped Count : 30</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td><td><div>Total Count : 968</div><div>Failed Count : 0</div><div>Skipped Count : 22</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>
Wanted but not invoked:
atlasEntityStore.createOrUpdate(
    &lt;any&gt;,
    &lt;any&gt;
);
-&gt; at org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled(NotificationHookConsumerKafkaTest.java:112)
Actually, there were zero interactions with this mock.
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.atlas.notification.NotificationHookConsumerKafkaTest.testConsumerConsumesNewMessageWithAutoCommitDisabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="calcite"><div style="font-weight:bold;" class="panel-heading">CALCITE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>9667f8537010d21556a592bd0dfbf20f7d0a4411</div><div><b>Last Run: </b>07-01-2019 01:44 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6520</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td><td><div>Total Count : 6531</div><div>Failed Count : 0</div><div>Skipped Count : 188</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="datafu"><div style="font-weight:bold;" class="panel-heading">DATAFU<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(N/A)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>857cf164c30883d739c4895c9a9c758880526435</div><div><b>Last Run: </b>07-01-2019 01:11 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 278</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="druid"><div style="font-weight:bold;" class="panel-heading">DRUID<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(N/A)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>c780aacc03e30b929ba14f70d7f278811fd8ba44</div><div><b>Last Run: </b>17-10-2018 06:25 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 6</div><div>Skipped Count : 91</div></td><td><div>Total Count : 90903</div><div>Failed Count : 2</div><div>Skipped Count : 91</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</li></div><div><li>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</li></div><div><li>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</li></div><div><li>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFileSessionCredentials</li></div><div><li>org.apache.druid.storage.s3.TestAWSCredentialsProvider.testWithFixedAWSKeys</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>org.hyperic.sigar.Sigar.getPid()J</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div><div><li>Unable to find a region via the region provider chain. Must provide an explicit region in the builder or setup environment to supply a region.</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testDefaultFeed</div></li><li><div>org.apache.druid.java.util.metrics.MonitorsTest.testSetFeed</div></li><li><div>org.apache.druid.java.util.metrics.SigarLoadTest.testSigarLoad</div></li><li><div>org.apache.druid.java.util.metrics.SigarPidDiscovererTest.simpleTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="falcon"><div style="font-weight:bold;" class="panel-heading">FALCON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>470e5e9f5de9ba1b6149dec60e87d3a04270eda3</div><div><b>Last Run: </b>26-12-2018 03:27 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1003</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 998</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1003</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 996</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1001</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1001</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="flume"><div style="font-weight:bold;" class="panel-heading">FLUME<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>5d29402f8def1fd3bb3f24c9d30bebb1e3806619</div><div><b>Last Run: </b>08-01-2019 01:48 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1325</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 15</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1324</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1324</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1325</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileWindows</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileNotOnWindows</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailure</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailureAndBufferSizeChanges</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndDifferentFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBehaviorWithEmptyFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsWithinAFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsAcrossFileBoundary</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testEmptyDirectoryAfterCommittingFile</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testLineExceedsMaxLineLength</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testNameCorrespondsToLatestRead</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicSpooling</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testInitiallyEmptyDirectory</li></div><div><li>org.apache.flume.client.avro.TestSpoolingFileLineReader.testFileChangesDuringRead</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div><div><li>Platform not recognized</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Could not initialize class java.nio.file.FileSystems$DefaultFileSystemHolder</li></div><div><li>Unexpected exception, expected&lt;java.lang.IllegalStateException&gt; but was&lt;java.lang.NoClassDefFoundError&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileWindows</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndSameFileNotOnWindows</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailure</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicCommitFailureAndBufferSizeChanges</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testDestinationExistsAndDifferentFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBehaviorWithEmptyFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsWithinAFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBatchedReadsAcrossFileBoundary</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testEmptyDirectoryAfterCommittingFile</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testLineExceedsMaxLineLength</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testNameCorrespondsToLatestRead</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testBasicSpooling</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testInitiallyEmptyDirectory</div></li><li><div>org.apache.flume.client.avro.TestSpoolingFileLineReader.testFileChangesDuringRead</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hadoop"><div style="font-weight:bold;" class="panel-heading">HADOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>d66925a315644f3c3bcde589f365fc01f0033d32</div><div><b>Last Run: </b>07-01-2019 13:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 20436</div><div>Failed Count : 94</div><div>Skipped Count : 1193</div></td><td><div>Total Count : 20151</div><div>Failed Count : 68</div><div>Skipped Count : 1191</div></td><td><div>Total Count : 19583</div><div>Failed Count : 76</div><div>Skipped Count : 1143</div></td><td><div>Total Count : 19256</div><div>Failed Count : 70</div><div>Skipped Count : 1142</div></td><td><div>Total Count : 20094</div><div>Failed Count : 245</div><div>Skipped Count : 1190</div></td><td><div>Total Count : 20180</div><div>Failed Count : 85</div><div>Skipped Count : 1192</div></td><td><div>Total Count : 20507</div><div>Failed Count : 74</div><div>Skipped Count : 1192</div></td><td><div>Total Count : 20182</div><div>Failed Count : 85</div><div>Skipped Count : 1191</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState.testRegistrationMajorityQuorum</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</li></div><div><li>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerReadTimeout</li></div><div><li>org.apache.hadoop.hdfs.TestEncryptedTransfer.testLongLivedClientPipelineRecovery[0]</li></div><div><li>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testWaitForRegistrationOnRestart</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.mapred.TestJobConf.testJobConf</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.fs.azurebfs.services.TestAbfsClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</li></div><div><li>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.yarn.sls.TestReservationSystemInvariants.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</li></div><div><li>org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator.testAMSimulatorWithNodeLabels[0]</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetNewApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testSubmitApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testForceKillApplicationOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetApplicationsOnHA</li></div><div><li>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetContainerReportOnHA</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraintsByScheduler</li></div><div><li>org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory.testLogAggregationFileControllerFactory</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA.testGetApplicationReportIdempotent</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div><div><li>org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST.org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile src/test/resources/nodes.json)]</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf.perfZKRMStateStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler.testContainerReleaseWithAllocationTags[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemptionWithDRF]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodesWithStaleness[1]</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemption]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailover</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryOnDatanodeUpgrade</li></div><div><li>org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestMaintenanceState.testFileCloseAfterEnteringMaintenance</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork.testDatanodeReRegistration</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.writeRead</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateThreeBatches</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.multipleReads</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateSingleBatch</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testServerBindHost</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testNonExistentBlock</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testReadBack</li></div><div><li>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testIterate</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapAliasmap.testAliasmapBootstrap</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBDelimitedWriter</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBCorruptionDetector</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFileCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleFileCorruption</li></div><div><li>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFolderCorruption</li></div><div><li>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testTokenStore</li></div><div><li>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testCheckVersion</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength</li></div><div><li>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testGzipWithTwoInputs</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testNegativeRecordLength</li></div><div><li>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testGzipWithTwoInputs</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestUberAM.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapred.TestShuffleHandler.testRecoveryFromOtherVersions</li></div><div><li>org.apache.hadoop.mapred.TestShuffleHandler.testRecovery</li></div><div><li>org.apache.hadoop.tools.TestHadoopArchiveLogs.testFilterAppsByAggregatedStatus</li></div><div><li>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunchWithArguments</li></div><div><li>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunch</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntitiesPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntityTypes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testFromTsWithDeletion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testLevelDbRepair</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertForPreviousPeriodAfterRollPeriodRollsDB</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertAfterRollPeriodRollsDB</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntitiesWithOutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetEntitiesAclEnabled</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntityWithOutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testUpdatingOldEntityWithoutDomainId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testTokenStore</li></div><div><li>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testAMRMProxyStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyRestartTimes</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyState</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreNodeHealth</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testFinishResourceLocalization</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testNMTokenStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCompactionCycle</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLogDeleterStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testDeletionTaskStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerTokenStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLocalTrackerStateIterator</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreForResourceMapping</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStartResourceLocalization</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testApplicationStorage</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCheckVersion</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testRemoveLocalizedResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testIsNewlyCreated</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testUnexpectedKeyDoesntThrowException</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingNoService</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingV2Enabled</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveAttempt</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testBadKeyIteration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testDeleteStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testEpoch</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testApps</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testProxyCA</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testClientTokens</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testVersion</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAMTokens</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAppDeletion</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveApplication</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testReservation</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testVersioning</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistConfiguration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testMaxLogs</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testRestartReadsFromUpdatedStore</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistUpdatedConfiguration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testConfigurationUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testNullConfigurationUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testSummaryRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testAppLogsScanLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testPluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testCleanLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testScanActiveLogsAndMoveToDonePluginRead</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</li></div><div><li>org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient.testLifecycleAndOverride</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.tracing.TestTracing.testTracing</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.testAppFinishedFinished[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testSimpleDecreaseContainer</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</li></div><div><li>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExampleDotCom</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.test1OutOf2BlockpoolsWithBlockPoolPolicy</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduceRestarting</li></div><div><li>org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testMapReduce</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex</li></div><div><li>org.apache.hadoop.mapred.TestJobName.testComplexName</li></div><div><li>org.apache.hadoop.mapred.TestLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleMapsPerNode</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testMultipleReducers</li></div><div><li>org.apache.hadoop.mapred.TestMRIntermediateDataEncryption.testSingleReducer</li></div><div><li>org.apache.hadoop.mapred.TestMerge.testMerge</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromDisk</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetch.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem</li></div><div><li>org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient</li></div><div><li>org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput</li></div><div><li>org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testBinaryTokenFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestBinaryTokenFile.testTokenCacheFile</li></div><div><li>org.apache.hadoop.mapreduce.security.TestMRCredentials.test</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCacheWithWildcards</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser</li></div><div><li>org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.testValidProxyUser</li></div><div><li>org.apache.hadoop.tools.TestDistCh.testDistCh</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.testGenerateDistCacheData</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit</li></div><div><li>org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit</li></div><div><li>org.apache.hadoop.streaming.TestFileArgs.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleArchiveFiles.testCommandLine</li></div><div><li>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles</li></div><div><li>org.apache.hadoop.streaming.TestSymLink.testSymLink</li></div><div><li>org.apache.hadoop.yarn.service.TestServiceAM.testContainersReleasedWhenPreLaunchFails</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoteAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServices[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testRemoveManifest[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testValidAuxServiceName[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesManifestPermissions[1]</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServiceRecoverySetup[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered[CAPACITY]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[0]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testMasterKeyRollOver[1]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestAMRMTokens.testTokenExpiry[1]</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>expected:&lt;router[0]&gt; but was:&lt;router[3]&gt;</li></div><div><li>expected:&lt;1546918553023&gt; but was:&lt;1546918554191&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>Self-suppression not permitted</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>10159 milliseconds passed.</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li> Expected to find 'localhost:44270: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:44270: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546939389129_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546939389129_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>The actual value 15 is not within the expected range: [5.60, 8.40].</li></div><div><li>The actual value 11 is not within the expected range: [5.60, 8.40].</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>src and dst file does not match at 0 between HdfsNamedFileStatus{path=hdfs://localhost:46069/testdir/srcdat/file0; isDirectory=false; length=102400; replication=2; blocksize=1024; modification_time=1546952141602; access_time=1546952135180; owner=u1; group=g1; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} and HdfsNamedFileStatus{path=hdfs://localhost:</li></div><div><li>File group ownership should match expected:&lt;[g0]&gt; but was:&lt;[supergroup]&gt;</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>java.io.IOException: Unable to delete directory /var/lib/jenkins/workspace/hadoop/hadoop-tools/hadoop-sls/target/test-dir/output5328169727264143972/metrics.</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 12:05:28 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort</li></div><div><li>appattempt_1546932186738_0001_000001 not found in AMRMTokenSecretManager.</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>The Rolled-back process should be a different pid. Actual: 6858</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.doRestartTests(TestContainerManager.java:482)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuc</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>Error when transitioning to Active mode</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>Web app not running</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546903390477_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546903390477_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 01:16:04 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>Timed out attempt store notification</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 08:43:36,510

"Ping Checker" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.yarn.util.AbstractLivelinessMonitor$PingChecker.run(AbstractLivelinessMonitor.java:154)
        at java.lang.Thread.run(Thread.java:748)
"Timer-</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 02:24:06,714

"stripedRead-3" daemon prio=5 tid=14244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQue</li></div><div><li> Expected to find 'localhost:45047: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45047: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:40406: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:40406: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:45455: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45455: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:45135: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45135: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41967: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41967: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:38927: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:38927: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546910648076_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546910648076_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Mon Jan 07 20:12:10 CST 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>Incorrect # of containers on the greedy app expected:&lt;6&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodes(TestReplicationPolicy.java:525)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWi</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 09:30:44,749

"datanode DomainSocketWatcher" daemon prio=5 tid=153 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546899809978_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546899809978_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Mon Jan 07 18:53:38 CST 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Application attempt appattempt_1546895748910_0001_000001 doesn't exist in ApplicationMasterService cache.
 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:398)
 at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor$3.allocate(DefaultRequestInterceptor.java:224)
 at org.apache.hadoop.yarn.server.nodemanager.</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>Incorrect # of containers on the greedy app expected:&lt;6&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>test timed out after 180000 milliseconds</li></div><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>test timed out after 60000 milliseconds</li></div><div><li>DestHost:destPort localhost:11376 , LocalHost:localPort 40984ce6df2a/172.17.0.2:0. Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]</li></div><div><li>expected:&lt;1546917924065&gt; but was:&lt;1546917925238&gt;</li></div><div><li>Unable to close file because the last blockBP-389427976-172.17.0.2-1546905112446:blk_1073741827_1003 does not have enough number of replicas.</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 12000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5498011387622669649.8: /tmp/libleveldbjni-64-1-5498011387622669649.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-6454562646584349185.8: /tmp/libleveldbjni-64-1-6454562646584349185.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Actual async detected volume failures should be greater or equal than [Ljava.lang.String;@11537d1e</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7784561517699997943.8: /tmp/libleveldbjni-64-1-7784561517699997943.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>inode should complete in ~60000 ms.
Expected: is &lt;true&gt;
     but: was &lt;false&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9116724356660138512.8: /tmp/libleveldbjni-64-1-9116724356660138512.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5836970591446903027.8: /tmp/libleveldbjni-64-1-5836970591446903027.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546938205011_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546938205011_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;DEFAULT&gt; but was:&lt;HIGH&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-2823841977520574558.8: /tmp/libleveldbjni-64-1-2823841977520574558.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>The actual value 14 is not within the expected range: [5.60, 8.40].</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 11:26:18 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5816037266765405976.8: /tmp/libleveldbjni-64-1-5816037266765405976.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-8739679424167203247.8: /tmp/libleveldbjni-64-1-8739679424167203247.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB$MyRollingLevelDB</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3847991619475157513.8: /tmp/libleveldbjni-64-1-3847991619475157513.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.serviceStop(RollingLevelDBTimelineStore.java:374)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.tearDown(TestRollingLevelDBTimelineStore.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9006565544380648365.8: /tmp/libleveldbjni-64-1-9006565544380648365.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-4370864914664638310.8: /tmp/libleveldbjni-64-1-4370864914664638310.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5886235552469102165.8: /tmp/libleveldbjni-64-1-5886235552469102165.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:530)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:220)
	at org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.tearDown(TestNodeManagerShutdown.java:107)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeM</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.doRestartTests(TestContainerManager.java:482)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuc</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7421185355100852629.8: /tmp/libleveldbjni-64-1-7421185355100852629.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-7801676120722955059.8: /tmp/libleveldbjni-64-1-7801676120722955059.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>test timed out after 30000 milliseconds</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-5204713396060524684.8: /tmp/libleveldbjni-64-1-5204713396060524684.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-9103122012756037183.8: /tmp/libleveldbjni-64-1-9103122012756037183.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime(TestContinuousScheduling.java:387)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3329554230740595379.8: /tmp/libleveldbjni-64-1-3329554230740595379.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-3058546666561165170.8: /tmp/libleveldbjni-64-1-3058546666561165170.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not initialize class org.fusesource.leveldbjni.JniDBFactory</li></div><div><li>java.io.IOException: Couldn't delete data file for leveldb timeline store /var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/target/tmp/yarn/timeline/app1-timeline-cache.ldb</li></div><div><li>Could not load library. Reasons: [no leveldbjni64-1.8 in java.library.path, no leveldbjni-1.8 in java.library.path, no leveldbjni in java.library.path, /tmp/libleveldbjni-64-1-966921701115744213.8: /tmp/libleveldbjni-64-1-966921701115744213.8: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64-bit platform)]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2019-01-07 04:03:06,299

"IPC Server handler 7 on default port 39951" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer</li></div><div><li> Expected to find 'localhost:43714: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43714: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39334: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39334: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35021: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35021: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:42081: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:42081: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35506: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35506: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39931: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39931: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>expected:&lt;-6040926954844379003&gt; but was:&lt;3220549084575210641&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546900955447_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546900955447_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 00:57:38 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;8192&gt;</li></div><div><li>expected:&lt;1024&gt; but was:&lt;3072&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>No rules applied to zookeeper/localhost</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>Unexpected num under-replicated blocks expected:&lt;3&gt; but was:&lt;4&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546909492326_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546909492326_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 02:39:49 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>ProcessTree shouldn't be alive</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Process is still alive!</li></div><div><li>Process is still alive!</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>expected:&lt;host1[]:9600&gt; but was:&lt;host1[.persistent.co.in.]:9600&gt;</li></div><div><li>String index out of range: -1</li></div><div><li>example.com exists:</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2736)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:821)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>test timed out after 600000 milliseconds</li></div><div><li> Expected to find 'localhost:36193: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:36193: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:34524: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34524: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:34645: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34645: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:43286: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43286: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41167: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41167: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41926: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41926: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>expected:&lt;8000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3000&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;10000&gt; but was:&lt;0&gt;</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Job failed!</li></div><div><li>Exit code expected:&lt;0&gt; but was:&lt;-1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.runTestLazyOutput(TestMapReduceLazyOutput.java:116)
	at org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.testLazyOutput(TestMapReduceLazyOutput.java:153)
	at sun.reflect.NativeMe</li></div><div><li>Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0: expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>dist job res is not 0 expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithClientCerts(TestEncryptedShu</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(TestEncryptedShuffle.java:159)
	at org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithoutClientCerts(TestEncrypted</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWit</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:307)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(Te</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSharedCache(TestMRJobs.java:1344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>Job status: Task failed task_1546945709352_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>No thread dump</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceCheckAndRemoteJar(TestMRJobs.java:280)
	at sun.reflect.NativeMethodAccesso</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1086)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache(TestMRJobs.java:1095)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistribut</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testRandomWriter(TestMRJobs.java:626)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun</li></div><div><li>No MapTask log found! expected:&lt;1&gt; but was:&lt;4&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalIndividualResourceUnderLimit(TestMRJobs.java:303)
	at sun.reflect.NativeMethodAcce</li></div><div><li>Job status: Task failed task_1546945709352_0015_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0
</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobWithChangePriority(TestMRJobs.java:449)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobInternal(TestMRJobs.java:393)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJobWithLocalResourceUnderLimit(TestMRJobs.java:246)
	at sun.reflect.NativeMethodAccessorImpl.i</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.__testCurrentUser(TestMiniMRProxyUser.java:132)
	at sun.reflect.NativeMethodAccessorImpl.in</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(TestMiniMRProxyUser.java:127)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.access$000(TestMiniMRProxyUser.java:43)
	at org.apache.hadoop.mapreduce.v2.TestMiniMRProxyU</li></div><div><li>expected:&lt;[sub1]&gt; but was:&lt;[jenkins]&gt;</li></div><div><li>GenerateDistCacheData job failed.</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Client exited with nonzero status expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;This is just the cache string &gt; but was:&lt;null&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Expected success for Probe Status, time="Tue Jan 08 13:23:24 UTC 2019", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
	at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters(TestFederationInterceptor.java:308)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMeth</li></div><div><li>java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
	at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt(TestFederationInterceptor.java:817)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAcce</li></div><div><li>The permission of the jar is wrong.Should throw out exception.</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>java.util.NoSuchElementException
	at java.util.HashMap$HashIterator.nextNode(HashMap.java:1444)
	at java.util.HashMap$ValueIterator.next(HashMap.java:1471)
	at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxUnexpectedStop(TestAuxServices.java:663)
	at sun.reflect.NativeMethodAccessorIm</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testCustomizedAuxServiceClassPath(TestAuxServices.java:415)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccess</li></div><div><li>Invalid mix of services expected:&lt;6&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Should receive the exception.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered(TestWorkPreservingRMRestart.java:1165)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.Native</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div><div><li>java.lang.reflect.InvocationTargetException</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.server.federation.store.TestStateStoreMembershipState.testRegistrationMajorityQuorum</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerWriteTimeout</div></li><li><div>org.apache.hadoop.hdfs.TestDistributedFileSystem.testDFSClientPeerReadTimeout</div></li><li><div>org.apache.hadoop.hdfs.TestEncryptedTransfer.testLongLivedClientPipelineRecovery[0]</div></li><li><div>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testWaitForRegistrationOnRestart</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testCompleteFileAfterCrashFailover</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.mapred.TestJobConf.testJobConf</div></li><li><div>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.fs.azurebfs.services.TestAbfsClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testRecursiveChunkCopy</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testChunkCopyOneFile</div></li><li><div>org.apache.hadoop.tools.TestDistCpSystem.testDistcpLargeFile</div></li><li><div>org.apache.hadoop.yarn.sls.TestReservationSystemInvariants.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</div></li><li><div>org.apache.hadoop.yarn.sls.appmaster.TestAMSimulator.testAMSimulatorWithNodeLabels[0]</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetNewApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testSubmitApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testForceKillApplicationOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetApplicationsOnHA</div></li><li><div>org.apache.hadoop.yarn.client.TestApplicationClientProtocolOnHA.testGetContainerReportOnHA</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClientPlacementConstraints.testAMRMClientWithPlacementConstraintsByScheduler</div></li><li><div>org.apache.hadoop.yarn.logaggregation.filecontroller.TestLogAggregationFileControllerFactory.testLogAggregationFileControllerFactory</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeRollbackDueToFailure</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA.testGetApplicationReportIdempotent</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</div></li><li><div>org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST.org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</div></li><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</div></li><li><div>org.apache.hadoop.yarn.sls.TestSLSStreamAMSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile src/test/resources/nodes.json)]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStorePerf.perfZKRMStateStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.TestAbstractYarnScheduler.testContainerReleaseWithAllocationTags[CAPACITY]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemptionWithDRF]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</div></li><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testChooseTargetWithMoreThanAvailableNodesWithStaleness[1]</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption.testRelaxLocalityPreemptionWithNoLessAMInRemainingNodes[FairSharePreemption]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailover</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</div></li><li><div>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</div></li><li><div>org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryOnDatanodeUpgrade</div></li><li><div>org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestMaintenanceState.testFileCloseAfterEnteringMaintenance</div></li><li><div>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</div></li><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestComputeInvalidateWork.testDatanodeReRegistration</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.writeRead</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateThreeBatches</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.multipleReads</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.iterateSingleBatch</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testServerBindHost</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestInMemoryLevelDBAliasMapClient.testNonExistentBlock</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testReadBack</div></li><li><div>org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TestLevelDBFileRegionAliasMap.testIterate</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testReportBadBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapAliasmap.testAliasmapBootstrap</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestHAAppend.testMultipleAppendsDuringCatchupTailing</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBDelimitedWriter</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testPBCorruptionDetector</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFileCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionMultipleFileCorruption</div></li><li><div>org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.testCorruptionDetectionSingleFolderCorruption</div></li><li><div>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testTokenStore</div></li><li><div>org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerLeveldbStateStoreService.testCheckVersion</div></li><li><div>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength</div></li><li><div>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testGzipWithTwoInputs</div></li><li><div>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testNegativeRecordLength</div></li><li><div>org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testGzipWithTwoInputs</div></li><li><div>org.apache.hadoop.mapreduce.v2.TestUberAM.testJobWithChangePriority</div></li><li><div>org.apache.hadoop.mapred.TestShuffleHandler.testRecoveryFromOtherVersions</div></li><li><div>org.apache.hadoop.mapred.TestShuffleHandler.testRecovery</div></li><li><div>org.apache.hadoop.tools.TestHadoopArchiveLogs.testFilterAppsByAggregatedStatus</div></li><li><div>org.apache.hadoop.fs.azure.TestClientThrottlingAnalyzer.testManySuccessAndErrorsAndWaiting</div></li><li><div>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunchWithArguments</div></li><li><div>org.apache.hadoop.yarn.server.applicationhistoryservice.TestApplicationHistoryServer.testLaunch</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntitiesPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testDeleteEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntityTypes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testFromTsWithDeletion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testLevelDbRepair</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLeveldbTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertForPreviousPeriodAfterRollPeriodRollsDB</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDB.testInsertAfterRollPeriodRollsDB</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToNonExistingEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testValidateConfig</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRootDirPermission</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCacheSizes</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testRelatingToEntityInSamePut</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestRollingLevelDBTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntitiesWithOutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetEntitiesAclEnabled</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testGetOldEntityWithOutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestTimelineDataManager.testUpdatingOldEntityWithoutDomainId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testTokenStore</div></li><li><div>org.apache.hadoop.yarn.server.timeline.recovery.TestLeveldbTimelineStateStore.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testStateStoreRemovalOnDecommission</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerUpgradeSuccessExplicitRollback</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testAMRMProxyStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyRestartTimes</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testEmptyState</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreNodeHealth</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testFinishResourceLocalization</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testNMTokenStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCompactionCycle</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLogDeleterStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testDeletionTaskStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testContainerTokenStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testLocalTrackerStateIterator</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStateStoreForResourceMapping</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testStartResourceLocalization</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testApplicationStorage</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testCheckVersion</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testRemoveLocalizedResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testIsNewlyCreated</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.recovery.TestNMLeveldbStateStoreService.testUnexpectedKeyDoesntThrowException</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingNoService</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher.testTimelineServiceEventPublishingV2Enabled</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStoreClientRetry</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveAttempt</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testBadKeyIteration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testDeleteStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testEpoch</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testApps</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testProxyCA</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testClientTokens</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testVersion</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAMTokens</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testAppDeletion</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testRemoveApplication</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestLeveldbRMStateStore.testReservation</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testVersioning</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistConfiguration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testMaxLogs</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testRestartReadsFromUpdatedStore</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testPersistUpdatedConfiguration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testConfigurationUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.TestLeveldbConfigurationStore.testNullConfigurationUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testSummaryRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testAppLogsScanLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testPluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testCleanLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testScanActiveLogsAndMoveToDonePluginRead</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomains</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithPrimaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetSingleEntity</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntities</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetDomain</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEvents</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithSecondaryFilters</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromId</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestLevelDBCacheTimelineStore.testGetEntitiesWithFromTs</div></li><li><div>org.apache.hadoop.yarn.server.timeline.TestOverrideTimelineStoreYarnClient.testLifecycleAndOverride</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.tracing.TestTracing.testTracing</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.testAppFinishedFinished[1]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerSchedulingRequestUpdate.testBasicPendingResourceUpdate</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testSimpleDecreaseContainer</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.registry.secure.TestSecureLogins.testValidKerberosName</div></li><li><div>org.apache.hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks.testSetRepIncWithUnderReplicatedBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testKillProcessGroup</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithLegacyFormat</div></li><li><div>org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat</div></li><li><div>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExampleDotCom</div></li><li><div>org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes.test1OutOf2BlockpoolsWithBlockPoolPolicy</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</div></li><li><div>org.apache.hadoop.yarn.service.TestServiceAM.testContainersReleasedWhenPreLaunchFails</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testMultipleSubClusters</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor.testSecondAttempt</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testReleasedContainerNotRecovered[CAPACITY]</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hbase"><div style="font-weight:bold;" class="panel-heading">HBASE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>466fa920fee572fe20db3b77ebf539dc304d5f31</div><div><b>Last Run: </b>03-01-2019 14:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2681</div><div>Failed Count : 6</div><div>Skipped Count : 20</div></td><td><div>Total Count : 4771</div><div>Failed Count : 7</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4760</div><div>Failed Count : 10</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4771</div><div>Failed Count : 7</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4759</div><div>Failed Count : 0</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4771</div><div>Failed Count : 2</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4759</div><div>Failed Count : 1</div><div>Skipped Count : 41</div></td><td><div>Total Count : 4769</div><div>Failed Count : 5</div><div>Skipped Count : 41</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div><div><li>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div><div><li>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.testRowsSeenMetricWithAsync</li></div><div><li>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide</li></div><div><li>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide</li></div><div><li>org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportWithTargetName</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testConsecutiveExports</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testEmptyExportFileSystemState</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportFileSystemStateWithSkipTmp</li></div><div><li>org.apache.hadoop.hbase.snapshot.TestExportSnapshotWithTemporaryDirectory.testExportRetry</li></div><div><li>org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner.org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.regionserver.TestCompactingToCellFlatMapMemStore.testForceCopyOfBigCellIntoImmutableSegment[0]</li></div><div><li>org.apache.hadoop.hbase.replication.regionserver.TestReplicator.testReplicatorWithErrors</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.client.TestAsyncProcess.testWriteBufferPeriodicFlushTimeoutMs</li></div><div><li>org.apache.hadoop.hbase.client.TestAsyncTable.testSimpleMultiple[1]</li></div><div><li>org.apache.hadoop.hbase.client.TestAsyncTable.org.apache.hadoop.hbase.client.TestAsyncTable</li></div><div><li>org.apache.hadoop.hbase.client.TestAsyncTable.org.apache.hadoop.hbase.client.TestAsyncTable</li></div><div><li>org.apache.hadoop.hbase.regionserver.TestCompactionWithCoprocessor.testStopStartCompaction</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>Archived hfiles [] and table hfiles [eca10b4bd514410f9cb5d919ce5115bb] is missing snapshot file:54105385475b403780ba5c28163837b9</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread RS-EventLoopGroup-5-2</li></div><div><li>test timed out after 780 seconds</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>test timed out after 780 seconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>i=1 expected:&lt;8389924&gt; but was:&lt;8389992&gt;</li></div><div><li>We did not replicate enough rows expected:&lt;10&gt; but was:&lt;9&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 780 seconds</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;0&gt; but was:&lt;392&gt;</li></div><div><li>java.lang.InterruptedException
	at org.apache.hadoop.hbase.client.TestAsyncTable.testSimpleMultiple(TestAsyncTable.java:153)
</li></div><div><li>test timed out after 780 seconds</li></div><div><li>Appears to be stuck in thread RS-EventLoopGroup-1-2</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.master.cleaner.TestSnapshotFromMaster.testSnapshotHFileArchiving</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.testRowsSeenMetricWithAsync</div></li><li><div>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide</div></li><li><div>org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide.org.apache.hadoop.hbase.TestServerSideScanMetricsFromClientSide</div></li><li><div>org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner.org.apache.hadoop.hbase.master.cleaner.TestHFileLinkCleaner</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.regionserver.TestCompactingToCellFlatMapMemStore.testForceCopyOfBigCellIntoImmutableSegment[0]</div></li><li><div>org.apache.hadoop.hbase.replication.regionserver.TestReplicator.testReplicatorWithErrors</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.regionserver.TestRecoveredEdits.org.apache.hadoop.hbase.regionserver.TestRecoveredEdits</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.client.TestAsyncProcess.testWriteBufferPeriodicFlushTimeoutMs</div></li><li><div>org.apache.hadoop.hbase.client.TestAsyncTable.testSimpleMultiple[1]</div></li><li><div>org.apache.hadoop.hbase.client.TestAsyncTable.org.apache.hadoop.hbase.client.TestAsyncTable</div></li><li><div>org.apache.hadoop.hbase.client.TestAsyncTable.org.apache.hadoop.hbase.client.TestAsyncTable</div></li><li><div>org.apache.hadoop.hbase.regionserver.TestCompactionWithCoprocessor.testStopStartCompaction</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hive"><div style="font-weight:bold;" class="panel-heading">HIVE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>926c1e8e352582a2bb89d458fb45c89c698c56fc</div><div><b>Last Run: </b>01-01-2019 15:00 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 7703</div><div>Failed Count : 4</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 2</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 1</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 3</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 5</div><div>Skipped Count : 246</div></td><td><div>Total Count : 7724</div><div>Failed Count : 1</div><div>Skipped Count : 246</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hive.hcatalog.api.TestHCatClient.org.apache.hive.hcatalog.api.TestHCatClient</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div><div><li>org.apache.hadoop.hive.metastore.TestObjectStore.testMasterKeyOps</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</li></div><div><li>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</li></div><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div><div><li>org.apache.hadoop.hive.metastore.TestObjectStore.testPartitionOps</li></div><div><li>org.apache.hadoop.hive.metastore.TestObjectStore.testQueryCloseOnError</li></div><div><li>org.apache.hadoop.hive.metastore.TestObjectStore.testMaxEventResponse</li></div><div><li>org.apache.hadoop.hive.metastore.TestObjectStore.testUseSSLProperty</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Connection refused (Connection refused)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div><div><li>No current connection.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Failed to execute "create table junitTypeTest1(f1 decimal(2)) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>Failed to execute "create table junitTypeTest1(f1 decimal) stored as AVRO TBLPROPERTIES ('transactional'='false')". Driver returned 1 Error: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: MetaException(message:java.lang.NoSuchMethodError org.codehaus.jackson.JsonNode.asInt()I)</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div><div><li>Timeout when executing method: getPartition; 309041ms exceeds 100000ms</li></div><div><li>Timeout when executing method: getPartition; 309111ms exceeds 100000ms</li></div><div><li>Timeout when executing method: getPartition; 309151ms exceeds 100000ms</li></div><div><li>Timeout when executing method: getPartition; 309191ms exceeds 100000ms</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:845)
	at org.apac</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</div></li><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</div></li><li><div>org.apache.hive.hcatalog.api.TestHCatClient.org.apache.hive.hcatalog.api.TestHCatClient</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hive.metastore.TestObjectStore.testMasterKeyOps</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimalX</div></li><li><div>org.apache.hive.hcatalog.pig.TestAvroHCatStorer.testWriteDecimal</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hive.metastore.TestObjectStore.testPartitionOps</div></li><li><div>org.apache.hadoop.hive.metastore.TestObjectStore.testQueryCloseOnError</div></li><li><div>org.apache.hadoop.hive.metastore.TestObjectStore.testMaxEventResponse</div></li><li><div>org.apache.hadoop.hive.metastore.TestObjectStore.testUseSSLProperty</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="kafka"><div style="font-weight:bold;" class="panel-heading">KAFKA<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>4616c0aaff5766b6305baeed521efdfaae0094e8</div><div><b>Last Run: </b>27-12-2018 19:00 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 2</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 5</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 10295</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div><div><li>kafka.api.UserQuotaTest.testQuotaOverrideDelete</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.PlaintextConsumerTest.testLowMaxFetchSizeForRequestAndPartition</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testAdvertisedListenerUpdate</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testAddRemoveSaslListeners</li></div><div><li>kafka.server.DynamicBrokerReconfigurationTest.testKeyStoreAlter</li></div><div><li>org.apache.kafka.streams.integration.TableTableJoinIntegrationTest.testOuterOuter[caching enabled = true]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToZonedDateTime</li></div><div><li>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToEarliestOnTopicsAndPartitions</li></div><div><li>kafka.api.CustomQuotaCallbackTest.testCustomQuotaCallback</li></div><div><li>kafka.api.SaslOAuthBearerSslEndToEndAuthorizationTest.testProduceConsumeTopicAutoCreateTopicCreateAcl</li></div><div><li>kafka.api.SslEndToEndAuthorizationTest.testProduceConsumeWithPrefixedAcls</li></div><div><li>kafka.server.DeleteTopicsRequestTest.testValidDeleteTopicRequests</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div><div><li>java.lang.AssertionError: Client with id=QuotasTestProducer-1 should have been throttled</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Timed out before consuming expected 2700 records. The number consumed was 1080.</li></div><div><li>org.scalatest.junit.JUnitTestFailedError: Expected exception java.util.concurrent.ExecutionException to be thrown, but java.util.concurrent.TimeoutException was thrown</li></div><div><li>java.lang.AssertionError: Partition [__consumer_offsets,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Partition [testtopic2,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Condition not met within timeout 15000. Never received expected final result.</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: expected:&lt;http://bar.com&gt; but was:&lt;null&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Expected that consumer group has consumed all messages from topic/partition.</li></div><div><li>java.lang.AssertionError: Partition [topic1,0] metadata not propagated after 15000 ms</li></div><div><li>java.lang.AssertionError: Too many quotaLimit calls Map(PRODUCE -&gt; 1, FETCH -&gt; 1, REQUEST -&gt; 3)</li></div><div><li>org.apache.kafka.common.errors.TopicExistsException: Topic 'e2etopic' already exists.</li></div><div><li>kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING</li></div><div><li>java.lang.AssertionError: There should be no errors, found Map(topic-3 -&gt; NONE, topic-4 -&gt; REQUEST_TIMED_OUT)</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li><li><div>kafka.api.UserQuotaTest.testQuotaOverrideDelete</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.PlaintextConsumerTest.testLowMaxFetchSizeForRequestAndPartition</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testAdvertisedListenerUpdate</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testAddRemoveSaslListeners</div></li><li><div>kafka.server.DynamicBrokerReconfigurationTest.testKeyStoreAlter</div></li><li><div>org.apache.kafka.streams.integration.TableTableJoinIntegrationTest.testOuterOuter[caching enabled = true]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.kafka.connect.runtime.rest.RestServerTest.testCORSEnabled</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToZonedDateTime</div></li><li><div>kafka.admin.ResetConsumerGroupOffsetTest.testResetOffsetsToEarliestOnTopicsAndPartitions</div></li><li><div>kafka.api.CustomQuotaCallbackTest.testCustomQuotaCallback</div></li><li><div>kafka.api.SaslOAuthBearerSslEndToEndAuthorizationTest.testProduceConsumeTopicAutoCreateTopicCreateAcl</div></li><li><div>kafka.api.SslEndToEndAuthorizationTest.testProduceConsumeWithPrefixedAcls</div></li><li><div>kafka.server.DeleteTopicsRequestTest.testValidDeleteTopicRequests</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="knox"><div style="font-weight:bold;" class="panel-heading">KNOX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>fc1f085f30d9bdb9ba75d640c487e8bb1a8c0607</div><div><b>Last Run: </b>18-12-2018 01:04 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1102</div><div>Failed Count : 2</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 3</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1101</div><div>Failed Count : 9</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1103</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithServicesAndApplications</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithEmptyNamespace</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testServiceAnonAuth</li></div><div><li>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithApplication</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithLeadingSlashNamespace</li></div><div><li>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading</li></div><div><li>org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig</li></div><div><li>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig</li></div><div><li>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</li></div><div><li>org.apache.knox.gateway.Knox242FuncTest.org.apache.knox.gateway.Knox242FuncTest</li></div><div><li>org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.testZooKeeperConfigMonitorSASLNodesExistWithAcceptableACL</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Timed out 10000 waiting for URL http://localhost:38127/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>test timed out after 5000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.setUp(AtlasZookeeperURLManagerTest.java:59)
</li></div><div><li>test timed out after 5000 milliseconds</li></div><div><li>test timed out after 5000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.setUp(AtlasZookeeperURLManagerTest.java:59)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.createZNodes(HBaseZookeeperURLManagerTest.java:121)
	at org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading(HBaseZookeeperURLManagerTest.java:71)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.configureAndStartZKCluster(ZooKeeperConfigurationMonitorTest.java:113)
	at org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.setupSuite(ZooKeeperConfigurationMonitorTest.java:84)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig(RemoteConfigurationRegistryClientServiceTest.ja</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig(RemoteConfigurationRegistryClientServiceTest.java:152)
</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.initializeTestClientAndZNodes(RemoteConfigurationRegistryClientServiceTest.java:278)
	at org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig(RemoteConfigurationRegistryClientServiceTest.jav</li></div><div><li>Timed out 10000 waiting for URL http://localhost:39710/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>Timed out 10000 waiting for URL http://localhost:45967/gateway/test-cluster/test-service-path/test-service-resource</li></div><div><li>java.lang.AssertionError
	at org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.configureAndStartZKCluster(RemoteConfigurationMonitorTest.java:190)
	at org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.setupTest(RemoteConfigurationMonitorTest.java:112)
</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithServicesAndApplications</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithEmptyNamespace</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testServiceAnonAuth</div></li><li><div>org.apache.knox.gateway.deploy.DeploymentFactoryFuncTest.testDeploymentWithApplication</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.AtlasZookeeperURLManagerTest.testAtlasAPIURLManagerWithLeadingSlashNamespace</div></li><li><div>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSecureNSHBaseZookeeperURLManagerLoading</div></li><li><div>org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest.org.apache.knox.gateway.topology.monitor.ZooKeeperConfigurationMonitorTest</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testUnsecuredZooKeeperWithSimpleRegistryConfig</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSimpleRegistryConfig</div></li><li><div>org.apache.knox.gateway.service.config.remote.zk.RemoteConfigurationRegistryClientServiceTest.testZooKeeperWithSingleExternalRegistryConfig</div></li><li><div>org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest.org.apache.knox.gateway.GatewayLdapDynamicGroupFuncTest</div></li><li><div>org.apache.knox.gateway.Knox242FuncTest.org.apache.knox.gateway.Knox242FuncTest</div></li><li><div>org.apache.knox.gateway.topology.monitor.RemoteConfigurationMonitorTest.testZooKeeperConfigMonitorSASLNodesExistWithAcceptableACL</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="metron"><div style="font-weight:bold;" class="panel-heading">METRON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>862244721fef7ba7389000cc2f3d0756bb07d69d</div><div><b>Last Run: </b>06-01-2019 12:39 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2088</div><div>Failed Count : 13</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[0]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testBytesMatch[1]</li></div><div><li>org.apache.metron.pcap.pattern.ByteArrayMatchingUtilTest.testStringMatch[1]</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathStringReturned</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatVariable</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathFormatConstant</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testHandleAttemptsRotateIfStreamClosed</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testGetHdfsPathMultipleFunctions</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles</li></div><div><li>org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER(pattern, data): Unable to parse: BYTEARRAY_MATCHER(pattern, data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing,pattern=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data): Unable to parse: BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse BYTEARRAY_MATCHER('`metron`', data): Unable to parse: BYTEARRAY_MATCHER('`metron`', data) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables data=missing</li></div><div><li>Unable to parse: TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key)) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>Unable to parse: FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key.2=test.value.2,test.key=test.value,test.key.3=test.value.3</li></div><div><li>Unable to parse: FORMAT('/test/folder/') due to: org/apache/http/conn/HttpClientConnectionManager</li></div><div><li>java.lang.NullPointerException
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testSingleFileIfNoStreamClosed(HdfsWriterTest.java:447)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Unable to parse: FORMAT('%s', test.key) due to: org/apache/http/conn/HttpClientConnectionManager with relevant variables test.key=test.value</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFile(HdfsWriterTest.java:313)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:6</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteMultipleFiles(HdfsWriterTest.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.metron.writer.hdfs.HdfsWriterTest.testWriteSingleFileWithNull(HdfsWriterTest.java:408)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="oozie"><div style="font-weight:bold;" class="panel-heading">OOZIE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>7e329cb11782634c1bd6f8ec32a21f4746af3bd3</div><div><b>Last Run: </b>03-01-2019 21:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 3106</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 1</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 3</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 2</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 1</div><div>Skipped Count : 0</div></td><td><div>Total Count : 3106</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</li></div><div><li>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent</li></div><div><li>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</li></div><div><li>org.apache.oozie.test.TestWorkflowRetries.testWorkflowWithStartAndEndCompletesSuccessfully</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;RUNNING&gt; but was:&lt;RUNNINGWITHERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;RUNNING&gt; but was:&lt;RUNNINGWITHERROR&gt;</li></div><div><li>E1018: Coord Job Rerun Error: part or all actions are not eligible to rerun!</li></div><div><li>Could not find own virtual machine</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Array index 4412 is not set to true</li></div><div><li>expected:&lt;RUNNING&gt; but was:&lt;SUCCEEDED&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to open socket file: target process not responding or HotSpot VM not loaded</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</div></li><li><div>org.apache.oozie.event.TestEventGeneration.testCoordinatorActionEvent</div></li><li><div>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</div></li><li><div>org.apache.oozie.test.TestWorkflowRetries.testWorkflowWithStartAndEndCompletesSuccessfully</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.util.TestMetricsInstrumentation.testJMXInstrumentation</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="phoenix"><div style="font-weight:bold;" class="panel-heading">PHOENIX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>3671097af252fd15f6481f4b2e7090b10cd0ff14</div><div><b>Last Run: </b>03-01-2019 23:45 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1731</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="pig"><div style="font-weight:bold;" class="panel-heading">PIG<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>a7f36ddca7c65df651c10ecf9f39255f88388bce</div><div><b>Last Run: </b>03-01-2019 02:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 9</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testSameParamInMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileComboDuplicate</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileCombo</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleParamsinSingleLine</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareDefaultComboDuplicates</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testFileParamsFromMultipleFiles</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testMultipleDeclareScope</li></div><div><li>org.apache.pig.test.TestParamSubPreproc.testCmdlineFileDeclareComboDuplicates</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 27 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div><div><li>Command line parameter substitution failed. Expected : store inactiveAccounts into '/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct'; , but got : store inactiveAccounts into \'/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct\'; in line num : 26 expected:&lt;...activeAccounts into ['/user/kaleidoscope/pow_stats/20080228/acct/InactiveAcct]';&gt; but was:&lt;...activeAccounts into [\'/user/kale</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ranger"><div style="font-weight:bold;" class="panel-heading">RANGER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>39a53b6c448145c2a68839233281671f754e519b</div><div><b>Last Run: </b>03-01-2019 01:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1315</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="slider"><div style="font-weight:bold;" class="panel-heading">SLIDER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/develop</div><div><b>Last Revision: </b>1d4f519d763210f46e327338be72efa99e65cb5d</div><div><b>Last Run: </b>03-01-2019 20:54 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 1</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>assert 0 == killAM(SIGTERM)
         |  |      |
         |  123    -15
         false</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.slider.agent.standalone.TestStandaloneAMKill.testKillStandaloneAM</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="spark"><div style="font-weight:bold;" class="panel-heading">SPARK<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>29a7d2da44585d91a9e94bf88dc7b1f42a0e5674</div><div><b>Last Run: </b>08-01-2019 08:46 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 15424</div><div>Failed Count : 1</div><div>Skipped Count : 652</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>&amp;#010;Assert on query failed: name: Exception thrown in awaitResult: &amp;#010;org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)&amp;#010; org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)&amp;#010; org.apache.spark.util.RpcUtils$.mak</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="sqoop"><div style="font-weight:bold;" class="panel-heading">SQOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>4a22691f45d7d66157ff6dfaa8fca5581e0a8955</div><div><b>Last Run: </b>04-01-2019 01:55 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td><td><div>Total Count : 906</div><div>Failed Count : 0</div><div>Skipped Count : 51</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="storm"><div style="font-weight:bold;" class="panel-heading">STORM<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>074fb35a0a5ab746d5508d2a60b48a7948a2cdda</div><div><b>Last Run: </b>03-01-2019 01:18 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1140</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1170</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.storm.kafka.spout.KafkaSpoutReactivationTest.testSpoutShouldResumeWhereItLeftOffWithUncommittedEarliestStrategy</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Timeout after waiting for 10000 ms.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.storm.kafka.spout.KafkaSpoutReactivationTest.testSpoutShouldResumeWhereItLeftOffWithUncommittedEarliestStrategy</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="tez"><div style="font-weight:bold;" class="panel-heading">TEZ<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Prajyot)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>a03181742abbf064557d096b3d3cd231c64c1a2a</div><div><b>Last Run: </b>03-01-2019 03:53 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1838</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 3</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1838</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.test.TestRecovery.testRecovery_HashJoin</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;KILLED&gt; but was:&lt;FAILED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;KILLED&gt; but was:&lt;FAILED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;KILLED&gt; but was:&lt;FAILED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>port out of range:-1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li><li><div>org.apache.tez.test.TestRecovery.testRecovery_HashJoin</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zeppelin"><div style="font-weight:bold;" class="panel-heading">ZEPPELIN<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>d37cc1b611dc761b1ec69c29d6b8ceaa84f301f4</div><div><b>Last Run: </b>14-09-2018 03:06 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 868</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 2</div><div>Skipped Count : 5</div></td><td><div>Total Count : 872</div><div>Failed Count : 8</div><div>Skipped Count : 5</div></td><td><div>Total Count : 858</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 859</div><div>Failed Count : 17</div><div>Skipped Count : 5</div></td><td><div>Total Count : 869</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</li></div><div><li>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</li></div><div><li>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.helium.HeliumBundleFactoryTest.bundlePackage</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testClose</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.showPlot</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.dependenciesAreInstalled</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testNoClose</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testPySpark</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.pySparkDepLoaderTest[3]</li></div><div><li>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.testZeppelinContextResource[3]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</li></div><div><li>org.apache.zeppelin.rest.NotebookRestApiTest.testRunWithServerRestart</li></div><div><li>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@135fbaa4"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteInterpreterTest.tearDown(IgniteInterpreterTest.java:75)
</li></div><div><li>Unable to establish plain connection. Was remote cluster configured with SSL? [rmtAddr=/127.0.0.1:47507, errMsg="Failed to deserialize object with given class loader: sun.misc.Launcher$AppClassLoader@75b84c92"]</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.tearDown(IgniteSqlInterpreterTest.java:87)
</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Fail to open IPythonInterpreter</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>com.github.eirslett.maven.plugins.frontend.lib.TaskRunnerException: 'yarn install --fetch-retries=2 --fetch-retry-factor=1 --fetch-retry-mintimeout=5000 --registry=http://registry.npmjs.org/' failed. (error code 1)</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>Index: 0, Size: 0</li></div><div><li>Index: 0, Size: 0</li></div><div><li>[%text Fail to execute line 1: import matplotlib
Traceback (most recent call last):
  File "/tmp/1536900576226-0/zeppelin_python.py", line 158, in &lt;module&gt;
    exec(code, _zcUserQueryNameSpace)
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/lib64/python2.7/site-packages/matplotlib/__init__.py", line 124, in &lt;module&gt;
    from . import cbook
ImportError: cannot import name cbook
] expected:&lt;SUCC</li></div><div><li>Index: 0, Size: 0</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;[]+---+---+
| _1| _2|
...&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]+---+---+
| _1| _2|
...&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;id name
1 a
2 b
3 c
[]&gt; but was:&lt;id name
1 a
2 b
3 c
[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0
  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]&gt;</li></div><div><li>expected:&lt;[]+---+---+
| _1| _2|
...&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]+---+---+
| _1| _2|
...&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>expected:&lt;[]2
&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]2
&gt;</li></div><div><li>expected:&lt;[]hello world
&gt; but was:&lt;[/usr/lib64/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
]hello world
&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>shared interpreter restart:
Expected: HTTP response &lt;200&gt; from /api/interpreter/setting/restart/md
     but: got &lt;500&gt; Request failed.</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.zeppelin.service.JobManagerService$NoteJobInfo.&lt;init&gt;(JobManagerService.java:124)
	at org.apache.zeppelin.service.JobManagerService.getNoteJobInfo(JobManagerService.java:52)
	at org.apache.zeppelin.socket.NotebookServer$NotebookInformationListener.onParagraphStatusChange(NotebookServer.java:1896)
	at org.apache.zeppelin.socket.NotebookServer.onSt</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.rest.InterpreterRestApiTest.testRestartInterpreterPerNote</div></li><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpret</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteInterpreterTest.testInterpretInvalidInput</div></li><li><div>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</div></li><li><div>org.apache.zeppelin.ignite.IgniteSqlInterpreterTest.testSql</div></li><li><div>org.apache.zeppelin.rest.ZeppelinRestApiTest.org.apache.zeppelin.rest.ZeppelinRestApiTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</div></li><li><div>org.apache.zeppelin.helium.HeliumBundleFactoryTest.bundlePackage</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testClose</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.showPlot</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.dependenciesAreInstalled</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterMatplotlibTest.testNoClose</div></li><li><div>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.spark.PySparkInterpreterTest.testPySpark</div></li><li><div>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</div></li><li><div>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.pySparkDepLoaderTest[3]</div></li><li><div>org.apache.zeppelin.rest.ZeppelinSparkClusterTest.testZeppelinContextResource[3]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zookeeper"><div style="font-weight:bold;" class="panel-heading">ZOOKEEPER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>4a8fda7031d68236441b13bd878936b2607c5244</div><div><b>Last Run: </b>04-01-2019 03:51 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2406</div><div>Failed Count : 2</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 2</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 1</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 4</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2395</div><div>Failed Count : 6</div><div>Skipped Count : 1</div></td><td><div>Total Count : 2406</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalFollowerRunWithDiff</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testLeaderElectionWithDisloyalVoter_stillHasMajority</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</li></div><div><li>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</li></div><div><li>org.apache.zookeeper.test.WatcherTest.testWatcherAutoResetWithGlobal</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.PurgeTxnTest.testPurgeWhenLogRollingInProgress</li></div><div><li>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</li></div><div><li>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</li></div><div><li>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</li></div><div><li>org.apache.zookeeper.test.ObserverQuorumHammerTest.testHammerBasic</li></div><div><li>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>expected:&lt;4294967298&gt; but was:&lt;0&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>Server 3 should have joined quorum by now</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>waiting for server 1 being up</li></div><div><li>test timed out after 840000 milliseconds</li></div><div><li>expected:&lt;1000&gt; but was:&lt;579&gt;</li></div><div><li>KeeperErrorCode = ConnectionLoss for /watchtest/child</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>ZkClient ops is not finished!</li></div><div><li>waiting for server 1 being up</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>test timed out after 840000 milliseconds</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalFollowerRunWithDiff</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testLeaderElectionWithDisloyalVoter_stillHasMajority</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li><li><div>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</div></li><li><div>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</div></li><li><div>org.apache.zookeeper.test.WatcherTest.testWatcherAutoResetWithGlobal</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.PurgeTxnTest.testPurgeWhenLogRollingInProgress</div></li><li><div>org.apache.zookeeper.server.quorum.QuorumPeerMainTest.testQuorumV6</div></li><li><div>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</div></li><li><div>org.apache.zookeeper.test.DisconnectedWatcherTest.testManyChildWatchersAutoReset</div></li><li><div>org.apache.zookeeper.test.ObserverQuorumHammerTest.testHammerBasic</div></li><li><div>org.apache.zookeeper.test.QuorumHammerTest.testHammerBasic</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div id="ubuntu16" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU16 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 16.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>15 (15)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>94 (33)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>68 (7)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr></tbody></table></div><div id="ubuntu18" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU18 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 18.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>76 (13)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>70 (7)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>10 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel72" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL72 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.2</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>245 (175)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (15)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9 (9)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (4)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel75" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL75 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.5</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>74 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (17)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>17 (14)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="ppcx86" style="display:block;font-weight:bold" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">FULL SUMMARY</div></div><table style="font-size:14" id="summarytable" class="table table-striped"><tbody><tr><th></th></tr><tr><th>Package Name</th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td>N/A</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_calcite" onclick="showme(this.id);">CALCITE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_datafu" onclick="showme(this.id);">DATAFU</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_druid" onclick="showme(this.id);">DRUID</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>15 (15)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>94 (33)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>68 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>76 (13)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>70 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>245 (175)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (15)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>74 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>85 (17)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>10 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (4)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>5 (5)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9 (9)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13</td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>9</td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>8 (7)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>17 (14)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>4 (4)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div></div></body></html>