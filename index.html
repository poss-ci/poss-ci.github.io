<html><head><script src="resources/jquery.min.js"></script><link href="resources/bootstrap.min.css" rel="stylesheet"></link><link href="resources/bootstrap-theme.min.css" rel="stylesheet"></link><script src="resources/bootstrap.min.js"></script><script src="helper.js">function hideAll(){console.log("hideAll")}function showme(e){console.log("showme");var l,n=e.substring(7),o=document.getElementsByName("data");for(l=0;l&lt;o.length;l++)o[l].style.display="none";var t=document.getElementsByName("summary");for(l=0;l&lt;t.length;l++)t[l].style.display="none";document.getElementById(n).style.display="block"}</script><style>table, th, td { vertical-align:top; padding: 3px} table {table-layout:fixed} td {word-wrap:break-word} .bs-callout { padding: 5px; margin: 5px 0; border: 1px solid #eee; border-left-width: 5px; border-radius: 3px; font-weight:normal; }.bs-callout-info {border-left-color: #5bc0de;}</style></head><body><nav class="navbar navbar-light"><div style="background-color: #F0F8FF;" class="container-fluid"><ul class="nav nav-pills"><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ppcx86" onclick="showme(this.id);">FULL SUMMARY</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu16" onclick="showme(this.id);">UBUNTU16</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_ubuntu18" onclick="showme(this.id);">UBUNTU18</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel72" onclick="showme(this.id);">RHEL72</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_rhel75" onclick="showme(this.id);">RHEL75</a></li><li role="presentation"><a style="font-weight:bold" href="#" id="anchor_developers" onclick="showme(this.id);">DEVELOPERS</a></li><p style="float:right;color:grey;font-size:13;padding-top:5px" role="presentation">05-07-2018 15:30 UTC</p></ul><div style="float:right;color:grey;font-size:12">Notations:<img src="resources/red.png" style="width: 16px; height: 16px;">Build failed </img><img src="resources/blue.png" style="width: 16px; height: 16px;">Build success with no failure </img><img src="resources/yellow.png" style="width: 16px; height: 16px;">N (M) Build success with N test failures &amp; M unique failures </img></div></div></nav><div style="table-cell" class="col-sm-2 col-md-2 sidebar"><div class="list-group"><a href="#" class="list-group-item list-group-item-action active" onclick="showme(this.id);" id="anchor_ppcx86">Packages</a><a class="list-group-item list-group-item-action" href="#" id="anchor_accumulo" onclick="showme(this.id);" title="Owned by Valencia">ACCUMULO</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ambari" onclick="showme(this.id);" title="Owned by Valencia">AMBARI</a><a class="list-group-item list-group-item-action" href="#" id="anchor_atlas" onclick="showme(this.id);" title="Owned by Yussuf">ATLAS</a><a class="list-group-item list-group-item-action" href="#" id="anchor_falcon" onclick="showme(this.id);" title="Owned by Yussuf">FALCON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_flume" onclick="showme(this.id);" title="Owned by Pravin">FLUME</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hadoop" onclick="showme(this.id);" title="Owned by Pravin">HADOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hbase" onclick="showme(this.id);" title="Owned by Valencia">HBASE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_hive" onclick="showme(this.id);" title="Owned by Alisha">HIVE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_kafka" onclick="showme(this.id);" title="Owned by Valencia">KAFKA</a><a class="list-group-item list-group-item-action" href="#" id="anchor_knox" onclick="showme(this.id);" title="Owned by Yussuf">KNOX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_metron" onclick="showme(this.id);" title="Owned by Pravin">METRON</a><a class="list-group-item list-group-item-action" href="#" id="anchor_oozie" onclick="showme(this.id);" title="Owned by Alisha">OOZIE</a><a class="list-group-item list-group-item-action" href="#" id="anchor_phoenix" onclick="showme(this.id);" title="Owned by Valencia">PHOENIX</a><a class="list-group-item list-group-item-action" href="#" id="anchor_pig" onclick="showme(this.id);" title="Owned by Yussuf">PIG</a><a class="list-group-item list-group-item-action" href="#" id="anchor_ranger" onclick="showme(this.id);" title="Owned by Yussuf">RANGER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_slider" onclick="showme(this.id);" title="Owned by Yussuf">SLIDER</a><a class="list-group-item list-group-item-action" href="#" id="anchor_spark" onclick="showme(this.id);" title="Owned by Valencia">SPARK</a><a class="list-group-item list-group-item-action" href="#" id="anchor_sqoop" onclick="showme(this.id);" title="Owned by Yussuf">SQOOP</a><a class="list-group-item list-group-item-action" href="#" id="anchor_storm" onclick="showme(this.id);" title="Owned by Alisha">STORM</a><a class="list-group-item list-group-item-action" href="#" id="anchor_tez" onclick="showme(this.id);" title="Owned by Valencia">TEZ</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zeppelin" onclick="showme(this.id);" title="Owned by Alisha">ZEPPELIN</a><a class="list-group-item list-group-item-action" href="#" id="anchor_zookeeper" onclick="showme(this.id);" title="Owned by Pravin">ZOOKEEPER</a></div></div><div style="display: table-cell"><div id="developers" style="display:block;font-weight:bold;display:none;" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">DEVELOPERS</div></div><div class="panel-body"><table style="font-size:15" id="summarytable" class="table table-striped"><tr><td style="width: 100px;font-weight:bold">ALISHA</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_storm">STORM </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zeppelin">ZEPPELIN </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_oozie">OOZIE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hive">HIVE </button></td></tr><tr><td style="width: 100px;font-weight:bold">PRAVIN</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_metron">METRON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_zookeeper">ZOOKEEPER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hadoop">HADOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_flume">FLUME </button></td></tr><tr><td style="width: 100px;font-weight:bold">VALENCIA</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_kafka">KAFKA </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_tez">TEZ </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_hbase">HBASE </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_accumulo">ACCUMULO </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_phoenix">PHOENIX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_spark">SPARK </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ambari">AMBARI </button></td></tr><tr><td style="width: 100px;font-weight:bold">YUSSUF</td><td><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_knox">KNOX </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_atlas">ATLAS </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_sqoop">SQOOP </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_slider">SLIDER </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_falcon">FALCON </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_pig">PIG </button><button type="button" class="btn btn-link btn-xs" onclick="showme(this.id);" id="anchor_ranger">RANGER </button></td></tr></table></div></div></div><div style="display: table-cell"><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="accumulo"><div style="font-weight:bold;" class="panel-heading">ACCUMULO<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>13a025d740a3f7bc3ca078f3557bff45f7751c60</div><div><b>Last Run: </b>03-07-2018 20:26 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 1</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 2</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td><td><div>Total Count : 1665</div><div>Failed Count : 0</div><div>Skipped Count : 6</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</li></div><div><li>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 60000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 60000 milliseconds</li></div><div><li>test timed out after 30000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.testPerTableClasspath</div></li><li><div>org.apache.accumulo.minicluster.MiniAccumuloClusterTest.test</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ambari"><div style="font-weight:bold;" class="panel-heading">AMBARI<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> origin/trunk</div><div><b>Last Revision: </b>aef0c47d9e8369b52b5e271d390071d3f193e37b</div><div><b>Last Run: </b>04-07-2018 12:21 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5568</div><div>Failed Count : 3</div><div>Skipped Count : 87</div></td><td><div>Total Count : 0</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 5568</div><div>Failed Count : 3</div><div>Skipped Count : 87</div></td><td><div>Total Count : 5568</div><div>Failed Count : 3</div><div>Skipped Count : 87</div></td><td><div>Total Count : 5568</div><div>Failed Count : 2</div><div>Skipped Count : 87</div></td><td><div>Total Count : 5568</div><div>Failed Count : 2</div><div>Skipped Count : 87</div></td><td><div>Total Count : 5568</div><div>Failed Count : 2</div><div>Skipped Count : 87</div></td></tr><tr><td>Result</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;"></img>FAILURE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.ambari.server.controller.test.BufferedThreadPoolExecutorCompletionServiceTest.testScalingThreadPoolExecutor</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</li></div><div><li>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div><div><li>[Deadlocked Thread:
------------------
"Thread-22" Id=54 WAITING on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@1f7148c4 owned by "Thread-32" Id=64
 at sun.misc.Unsafe.park(Native Method)
 -  waiting on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@1f7148c4
 at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
 at java.util.concurrent.locks.Abstrac</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div><div><li>[Deadlocked Thread:
------------------
"Thread-22" Id=54 WAITING on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@4322c771 owned by "Thread-35" Id=67
 at sun.misc.Unsafe.park(Native Method)
 -  waiting on java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync@4322c771
 at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
 at java.util.concurrent.locks.Abstrac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div><div><li>expected:&lt;10&gt; but was:&lt;9&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>mapper</li></div><div><li>mapper</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</div></li><li><div>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</div></li><li><div>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.metrics2.sink.timeline.AggregatedMetricsPublisherTest.testProcessMetrics</div></li><li><div>org.apache.hadoop.metrics2.sink.timeline.RawMetricsPublisherTest.testProcessMetrics</div></li><li><div>org.apache.ambari.server.state.cluster.ClusterDeadlockTest.testDeadlockWhileRestartingComponents</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.ambari.server.controller.test.BufferedThreadPoolExecutorCompletionServiceTest.testScalingThreadPoolExecutor</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="atlas"><div style="font-weight:bold;" class="panel-heading">ATLAS<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>15388229741b19c4567527da11bbb1daf2f9399f</div><div><b>Last Run: </b>04-07-2018 15:22 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 912</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="falcon"><div style="font-weight:bold;" class="panel-heading">FALCON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>411d90c2ffb59559770d23d4bd2f7675e46392e6</div><div><b>Last Run: </b>04-07-2018 04:15 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 994</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1003</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 998</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 996</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1003</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1002</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 1001</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="flume"><div style="font-weight:bold;" class="panel-heading">FLUME<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>719afe908d39a87cb046dcd974eebaa7886a00e8</div><div><b>Last Run: </b>03-07-2018 06:08 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1235</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1234</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 0</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td><td><div>Total Count : 1235</div><div>Failed Count : 1</div><div>Skipped Count : 7</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError
	at org.apache.flume.channel.file.TestLog.doTestMinimumRequiredSpaceTooSmallForPut(TestLog.java:241)
	at org.apache.flume.channel.file.TestLog.testMinimumRequiredSpaceTooSmallForPut(TestLog.java:210)
</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hadoop"><div style="font-weight:bold;" class="panel-heading">HADOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>d9ba6f3656e8dc97d2813181e27d12e52dca4328</div><div><b>Last Run: </b>03-07-2018 09:07 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 19549</div><div>Failed Count : 23</div><div>Skipped Count : 1184</div></td><td><div>Total Count : 19193</div><div>Failed Count : 32</div><div>Skipped Count : 1184</div></td><td><div>Total Count : 18780</div><div>Failed Count : 20</div><div>Skipped Count : 1138</div></td><td><div>Total Count : 18400</div><div>Failed Count : 25</div><div>Skipped Count : 1137</div></td><td><div>Total Count : 19621</div><div>Failed Count : 29</div><div>Skipped Count : 1184</div></td><td><div>Total Count : 19202</div><div>Failed Count : 24</div><div>Skipped Count : 1183</div></td><td><div>Total Count : 19511</div><div>Failed Count : 48</div><div>Skipped Count : 1183</div></td><td><div>Total Count : 19202</div><div>Failed Count : 29</div><div>Skipped Count : 1183</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.balancer.TestBalancerRPCDelay.testBalancerRPCDelay</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.testRaceDeleteCurrentDirUpdater</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.testOverwriteNonEmptyDirectory</li></div><div><li>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy.testCloseWithExceptionsInStreamer</li></div><div><li>org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy.testStripedFile1</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.testRaceDeleteHandler</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA.testRollbackWithJournalNodes</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=ConnectionFactory]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testAuthUrlConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testRedirectConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.hdfs.web.TestWebHdfsTimeouts.testTwoStepWriteConnectTimeout[timeoutSource=Configuration]</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testThrottling</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverMultipleZKfcs</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor</li></div><div><li>org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressorWithExeedBufferLimit</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompressInMultiThreads</li></div><div><li>org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor.testSnappyCompressDecompress</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFile.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatchAtStartupWithHA</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testPreStartQueueing</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.registry.server.dns.TestRegistryDNS.testExternalCNAMERecord</li></div><div><li>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExternalCNAMERecord</li></div><div><li>TestDockerUtil.test_add_rw_mounts</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2.testPutTimelineEntities[2]</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.hdfs.TestRollingUpgrade.testCheckpointWithMultipleNN</li></div><div><li>org.apache.hadoop.hdfs.TestRollingUpgrade.testRollBackImage</li></div><div><li>org.apache.hadoop.hdfs.TestRollingUpgrade.testDFSAdminRollingUpgradeCommands</li></div><div><li>org.apache.hadoop.hdfs.TestRollingUpgrade.testRollback</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore.testZKRMStateStoreRealZK</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testMultiNodeOperations</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.hdfs.TestBlockStoragePolicy.testChangeHotFileRep</li></div><div><li>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</li></div><div><li>org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval</li></div><div><li>org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval</li></div><div><li>org.apache.hadoop.hdfs.TestFileCorruption.testCorruptionWithDiskFailure</li></div><div><li>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</li></div><div><li>org.apache.hadoop.hdfs.TestReconstructStripedFile.testNNSendsErasureCodingTasks</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</li></div><div><li>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testCancelFutureThenReencrypt</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestStartup.testStorageBlockContentsStaleAfterNNRestart</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics.testExcessBlocks</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality.testExcludeDataNodes</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled</li></div><div><li>org.apache.hadoop.yarn.sls.TestSLSGenericSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</li></div><div><li>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testChangeContainerResource</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestRM.testApplicationKillAtAcceptedState[FAIR]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.testRMRestartNodeMapping[FAIR]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.testRMRestart[FAIR]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart.testAMRestartNotLostContainerCompleteMsg[FAIR]</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenApplicationCompleted</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChildMaxResources</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testReservationThresholdGatesReservations</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testFairShareAndWeightsInNestedUserQueueRule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testStat</li></div><div><li>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedStat</li></div><div><li>org.apache.hadoop.util.TestShell.testEnvVarsWithInheritance</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.testRenameFileBeingAppended</li></div><div><li>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRootDirectory.testRmRootRecursive</li></div><div><li>org.apache.hadoop.hdfs.server.federation.router.TestRouterClientRejectOverload.testOverloadControl</li></div><div><li>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy.testCloseWithExceptionsInStreamer</li></div><div><li>org.apache.hadoop.hdfs.TestLeaseRecovery2.testHardLeaseRecoveryAfterNameNodeRestart2</li></div><div><li>org.apache.hadoop.hdfs.TestPread.testPreadFailureWithChangedBlockLocations</li></div><div><li>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</li></div><div><li>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</li></div><div><li>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</li></div><div><li>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</li></div><div><li>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree</li></div><div><li>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testDecreaseAfterIncreaseWithAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestQueueManagementDynamicEditPolicy.testEditSchedule</li></div><div><li>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage.org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesHBaseStorage</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageApps</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageDomain</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageEntities</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema.org.apache.hadoop.yarn.server.timelineservice.storage.TestHBaseTimelineStorageSchema</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowActivity</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRun</li></div><div><li>org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>test timed out after 100000 milliseconds</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 12:14:37,127

"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=4810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.Abst</li></div><div><li> Expected to find 'localhost:42510: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:42510: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:42511: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:42511: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:36623: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:36623: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:34401: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:34401: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:45796: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:45796: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:41349: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:41349: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>Expected success for Probe Status, time="Tue Jul 03 20:57:59 UTC 2018", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>No namenode available under nameservice ns0</li></div><div><li>Failed: the number of failed blocks = 2 &gt; the number of parity blocks = 1</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.junit.Assert.assertFalse(Assert.java:74)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.doTest(TestSafeModeWithStripedFile.java:171)
	at org.apache.hadoop.hdfs.TestSafeModeWithStripedFile.testStripedFile1(TestSafeModeWit</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 12:44:10,358

"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4fad9bb2" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesyst</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 12:41:31,944

"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=3412 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.Abst</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA.testRollbackWithJournalNodes(TestDFSUpgradeWithHA.java:687)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invok</li></div><div><li> Expected to find 'localhost:46372: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:46372: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:33818: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:33818: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:39782: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:39782: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li> Expected to find 'localhost:37794: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:37794: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:35079: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:35079: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li> Expected to find 'localhost:43764: connect timed out' but got unexpected exception: java.net.SocketTimeoutException: localhost:43764: Read timed out
 at java.net.SocketInputStream.socketRead0(Native Method)
 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
 at java.net.SocketInputStream.read(SocketInputStream.java:171)
 at java.net.SocketInputStream.read(SocketInputStream.java</li></div><div><li>expected timeout</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>Throttle is too permissive</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 09:39:32,550

"pool-26-thread-1"  prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(Abs</li></div><div><li>expected:&lt;14.0&gt; but was:&lt;15.0&gt;</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>Expected success for Probe Status, time="Tue Jul 03 15:42:49 CDT 2018", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>ProcessTree shouldn't be alive</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to become active. Local node did not get an opportunity to do so from ZooKeeper, or the local node took too long to transition to active.</li></div><div><li> Expected to find 'testCompressorDecompressor error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at com.google.common.ba</li></div><div><li> Expected to find 'testCompressorDecompressorWithExeedBufferLimit error !!!' but got unexpected exception: java.lang.NullPointerException
 at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
 at com.google.common.base.Joiner.toString(Joiner.java:532)
 at com.google.common.base.Joiner.appendTo(Joiner.java:124)
 at com.google.common.base.Joiner.appendTo(Joiner.java:181)
 at </li></div><div><li>Deferred</li></div><div><li>Could not decompress data. Input is invalid.</li></div><div><li>String index out of range: -1</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead(TestBlockReaderLocal.java:840)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke</li></div><div><li>Actual async detected volume failures should be greater or equal than [Ljava.lang.String;@790b160c</li></div><div><li>Unexpected num under-replicated blocks expected:&lt;3&gt; but was:&lt;4&gt;</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>Expected success for Probe Status, time="Tue Jul 03 17:32:32 CDT 2018", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>ProcessTree shouldn't be alive</li></div><div><li>expected:&lt;2&gt; but was:&lt;1&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:621)
	at org.junit.Assert.assertNotNull(Assert.java:631)
	at org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken(TestDelegationTokenRenewer.java:1067)
	at sun.reflect.NativeMetho</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>expected:&lt;1530642599717&gt; but was:&lt;1530642600839&gt;</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>test timed out after 120000 milliseconds</li></div><div><li>test timed out after 20000 milliseconds</li></div><div><li>Actual async detected volume failures should be greater or equal than [Ljava.lang.String;@300e5ecd</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 01:48:16,128

"pool-4-thread-1"  prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(Abstr</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testPreStartQueueing(TestTaskRunner.java:244)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImp</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;2&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor144.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveC</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Application attempt appattempt_1530652217339_0001_000001 doesn't exist in ApplicationMasterService cache.
 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:404)
 at org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor$3.allocate(DefaultRequestInterceptor.java:224)
 at org.apache.hadoop.yarn.server.nodemanager.</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>/var/lib/jenkins/workspace/hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/native/container-executor/test/utils/test_docker_util.cc:962
      Expected: 0
To be equal to: ret
      Which is: 14</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:621)
	at org.junit.Assert.assertNotNull(Assert.java:631)
	at org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken(TestDelegationTokenRenewer.java:1067)
	at sun.reflect.NativeMetho</li></div><div><li>Entities should have been published successfully.</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>String index out of range: -1</li></div><div><li>Test resulted in an unexpected exit</li></div><div><li>Test resulted in an unexpected exit</li></div><div><li>expected null, but was:&lt;javax.management.openmbean.CompositeDataSupport(compositeType=javax.management.openmbean.CompositeType(name=org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo$Bean,items=((itemName=blockPoolId,itemType=javax.management.openmbean.SimpleType(name=java.lang.String)),(itemName=createdRollbackImages,itemType=javax.management.openmbean.SimpleType(name=java.lang.Boolean)),(itemNam</li></div><div><li>expected null, but was:&lt;javax.management.openmbean.CompositeDataSupport(compositeType=javax.management.openmbean.CompositeType(name=org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo$Bean,items=((itemName=blockPoolId,itemType=javax.management.openmbean.SimpleType(name=java.lang.String)),(itemName=createdRollbackImages,itemType=javax.management.openmbean.SimpleType(name=java.lang.Boolean)),(itemNam</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>Expected success for Probe Status, time="Tue Jul 03 20:34:14 UTC 2018", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 04:10:59,731

"ContainersLauncher #0"  prio=5 tid=827 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQue</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.testRemoveAttempt(RMStateStoreTestBase.java:686)
	at org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore.testZKRMStateStoreRealZK(TestZ</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>Expected InvalidToken</li></div><div><li>String index out of range: -1</li></div><div><li>Write can't finish.</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>expected:&lt;3&gt; but was:&lt;2&gt;</li></div><div><li>expected:&lt;1530646510171&gt; but was:&lt;1530646511213&gt;</li></div><div><li>Unable to close file because the last blockBP-443741402-172.17.0.2-1530641187551:blk_1073741828_1004 does not have enough number of replicas.</li></div><div><li>Test resulted in an unexpected exit</li></div><div><li>Test resulted in an unexpected exit</li></div><div><li>test timed out after 300000 milliseconds</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 04:27:26,715

"stripedRead-7" daemon prio=5 tid=6280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueu</li></div><div><li>Actual async detected volume failures should be greater or equal than [Ljava.lang.String;@5a5c0dcb</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 02:47:43,346

"IPC Client (547139125) connection to localhost/127.0.0.1:36574 from jenkins" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1017)
        at org.apache.hadoop.i</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 01:31:39,601

"BP-993703669-172.17.0.2-1530624681267 heartbeating to localhost/127.0.0.1:41264" daemon prio=5 tid=3266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(Incrementa</li></div><div><li>expected:&lt;0&gt; but was:&lt;2&gt;</li></div><div><li>Bad value for metric ExcessBlocks expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>expected:&lt;3&gt; but was:&lt;2&gt;</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>TestSLSRunner catched exception from child thread (TaskRunner.TaskDefinition): [java.lang.reflect.UndeclaredThrowableException]</li></div><div><li>Not all node managers were reported running expected:&lt;3&gt; but was:&lt;2&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.client.api.impl.BaseAMRMClientTest.teardown(BaseAMRMClientTest.java:199)
	at sun.reflect.GeneratedMethodAccessor144.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveC</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>expected:&lt;&lt;memory:4096, vCores:2&gt;&gt; but was:&lt;&lt;memory:1024, vCores:1&gt;&gt;</li></div><div><li>expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>Attempt state is not correct (timeout). expected:&lt;ALLOCATED&gt; but was:&lt;SCHEDULED&gt;</li></div><div><li>expected:&lt;1&gt; but was:&lt;0&gt;</li></div><div><li>Attempt state is not correct (timeout). expected:&lt;ALLOCATED&gt; but was:&lt;SCHEDULED&gt;</li></div><div><li>test timed out after 40000 milliseconds</li></div><div><li>expected:&lt;1024&gt; but was:&lt;7168&gt;</li></div><div><li>expected:&lt;0&gt; but was:&lt;1024&gt;</li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>App 1 is not running with the correct number of containers expected:&lt;2&gt; but was:&lt;0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testReservationThresholdGatesReservations(TestFairScheduler.java:1637)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodA</li></div><div><li>expected:&lt;4096&gt; but was:&lt;8192&gt;</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:621)
	at org.junit.Assert.assertNotNull(Assert.java:631)
	at org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken(TestDelegationTokenRenewer.java:1067)
	at sun.reflect.NativeMetho</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>java.lang.IllegalArgumentException: length != 10(unixSymbolicPermission=-rw-r--r--.)</li></div><div><li>String index out of range: -1</li></div><div><li>Failed to append to non-existent file /test/test/target for client 127.0.0.1
 at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
 at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
 at org.apache.hadoop.hdfs.protocolPB.Client</li></div><div><li>No namenode available under nameservice ns0</li></div><div><li>expected:&lt;0&gt; but was:&lt;1&gt;</li></div><div><li>Failed: the number of failed blocks = 2 &gt; the number of parity blocks = 1</li></div><div><li>lease holder should now be the NN</li></div><div><li>1</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 12:20:14,837

"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4b1d6571" daemon prio=5 tid=200 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.S</li></div><div><li>Job didn't finish in 30 seconds</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyEntityTypeFileExists(TestDistributedShell.java:628)
	at org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.checkTimelineV2(TestDis</li></div><div><li>Expected success for Probe Status, time="Tue Jul 03 20:52:38 UTC 2018", outcome="failure", message="Failure in Default probe: IP presence with DNS checking and DNS server address 8.8.8.8", exception="java.io.IOException: comp-0: DNS checking is enabled, but lookup for example.com is not available yet"</li></div><div><li>Child process owned by init escaped process tree.</li></div><div><li>Timed out waiting for condition. Thread diagnostics:
Timestamp: 2018-07-03 04:46:23,018

"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server Responder" daemon prio=5 tid=787 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    </li></div><div><li>expected:&lt;3072&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;2048&gt; but was:&lt;4096&gt;</li></div><div><li>expected:&lt;0.5&gt; but was:&lt;0.0&gt;</li></div><div><li>java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime(TestContinuousScheduling.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div><div><li>org/apache/hadoop/crypto/key/KeyProviderTokenIssuer</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.server.balancer.TestBalancerRPCDelay.testBalancerRPCDelay</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.testRaceDeleteCurrentDirUpdater</div></li><li><div>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.testOverwriteNonEmptyDirectory</div></li><li><div>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy.testCloseWithExceptionsInStreamer</div></li><li><div>org.apache.hadoop.hdfs.TestSafeModeWithStripedFileWithRandomECPolicy.testStripedFile1</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.testRaceDeleteHandler</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA.testRollbackWithJournalNodes</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testThrottling</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverMultipleZKfcs</div></li><li><div>org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatus</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestCapacitySchedulerMetrics.testCSMetrics</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer.testContainerIncreaseAllocationExpiration</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</div></li><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFile.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatchAtStartupWithHA</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testPreStartQueueing</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testGetMatchingFitWithProfiles[0]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientWithContainerResourceChange[1]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMProxy.testAMRMProxyTokenRenewal</div></li><li><div>org.apache.hadoop.registry.server.dns.TestRegistryDNS.testExternalCNAMERecord</div></li><li><div>org.apache.hadoop.registry.server.dns.TestSecureRegistryDNS.testExternalCNAMERecord</div></li><li><div>TestDockerUtil.test_add_rw_mounts</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</div></li><li><div>org.apache.hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2.testPutTimelineEntities[2]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hdfs.TestRollingUpgrade.testCheckpointWithMultipleNN</div></li><li><div>org.apache.hadoop.hdfs.TestRollingUpgrade.testRollBackImage</div></li><li><div>org.apache.hadoop.hdfs.TestRollingUpgrade.testDFSAdminRollingUpgradeCommands</div></li><li><div>org.apache.hadoop.hdfs.TestRollingUpgrade.testRollback</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</div></li><li><div>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStore.testZKRMStateStoreRealZK</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testMultiNodeOperations</div></li><li><div>org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites</div></li><li><div>org.apache.hadoop.hdfs.TestBlockStoragePolicy.testChangeHotFileRep</div></li><li><div>org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithPreserveOption</div></li><li><div>org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval</div></li><li><div>org.apache.hadoop.hdfs.TestDecommission.testBlocksPerInterval</div></li><li><div>org.apache.hadoop.hdfs.TestFileCorruption.testCorruptionWithDiskFailure</div></li><li><div>org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks.testReadFileWithMissingBlocks</div></li><li><div>org.apache.hadoop.hdfs.TestReconstructStripedFile.testNNSendsErasureCodingTasks</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting.testHotSwapOutFailedVolumeAndReporting</div></li><li><div>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery.testDnRestartWithSavedReplicas</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestReencryption.testCancelFutureThenReencrypt</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestStartup.testStorageBlockContentsStaleAfterNNRestart</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics.testExcessBlocks</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.web.resources.TestWebHdfsDataLocality.testExcludeDataNodes</div></li><li><div>org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled</div></li><li><div>org.apache.hadoop.yarn.sls.TestSLSGenericSynth.testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, (nodeFile null)]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</div></li><li><div>org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAMRMClientAllocReqId[2]</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testChangeContainerResource</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing.testKillOnlyRequiredOpportunisticContainers</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestRM.testApplicationKillAtAcceptedState[FAIR]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.testRMRestartNodeMapping[FAIR]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.testRMRestart[FAIR]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRestart.testAMRestartNotLostContainerCompleteMsg[FAIR]</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenContainerCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing.testIncreaseContainerUnreservedWhenApplicationCompleted</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChildMaxResources</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testReservationThresholdGatesReservations</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testFairShareAndWeightsInNestedUserQueueRule</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testRMRestartWithExpiredToken</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractRootDirectory.testRmRootRecursive</div></li><li><div>org.apache.hadoop.hdfs.server.federation.router.TestRouterClientRejectOverload.testOverloadControl</div></li><li><div>org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy.testCloseWithExceptionsInStreamer</div></li><li><div>org.apache.hadoop.hdfs.TestLeaseRecovery2.testHardLeaseRecoveryAfterNameNodeRestart2</div></li><li><div>org.apache.hadoop.hdfs.TestPread.testPreadFailureWithChangedBlockLocations</div></li><li><div>org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency.testGenerationStampInFuture</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2CustomizedFlow</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2</div></li><li><div>org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithoutDomainV2DefaultFlow</div></li><li><div>org.apache.hadoop.yarn.service.monitor.probe.TestDefaultProbe.testDefaultProbe[2]</div></li><li><div>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalingResourceWhileContainerRunning</div></li><li><div>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestContinuousScheduling.testFairSchedulerContinuousSchedulingInitTime</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hbase"><div style="font-weight:bold;" class="panel-heading">HBASE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>6198e1fc7dfa85c3bc6b2855f9a5fb5f4b2354ff</div><div><b>Last Run: </b>28-06-2018 14:31 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 4642</div><div>Failed Count : 0</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4654</div><div>Failed Count : 0</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4642</div><div>Failed Count : 0</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4654</div><div>Failed Count : 0</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4642</div><div>Failed Count : 2</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4654</div><div>Failed Count : 1</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4642</div><div>Failed Count : 2</div><div>Skipped Count : 39</div></td><td><div>Total Count : 4654</div><div>Failed Count : 2</div><div>Skipped Count : 39</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[0: blockSize=8,192, bucketSizes=null]</li></div><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[1: blockSize=16,384, bucketSizes=[I@ae45eb6]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[1: blockSize=16,384, bucketSizes=[I@ae45eb6]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[0: blockSize=8,192, bucketSizes=null]</li></div><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[1: blockSize=16,384, bucketSizes=[I@ae45eb6]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[0: blockSize=8,192, bucketSizes=null]</li></div><div><li>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[1: blockSize=16,384, bucketSizes=[I@ae45eb6]</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div><div><li>expected: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt; but was: java.nio.HeapByteBuffer&lt;java.nio.HeapByteBuffer[pos=0 lim=113 cap=133]&gt;</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.hadoop.hbase.io.hfile.bucket.TestBucketCache.testCacheBlockNextBlockMetadataMissing[0: blockSize=8,192, bucketSizes=null]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="hive"><div style="font-weight:bold;" class="panel-heading">HIVE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>f519db7eafacb4b4d2d9fe2a9e10e908d8077224</div><div><b>Last Run: </b>03-07-2018 15:00 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td><td><div>Total Count : 7249</div><div>Failed Count : 1</div><div>Skipped Count : 232</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.hadoop.hive.llap.tezplugins.TestLlapTaskCommunicator.testFinishableStateUpdateFailure</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.NullPointerException
	at org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec$Builder.setUser(LlapDaemonProtocolProtos.java:4899)
	at org.apache.hadoop.hive.llap.tez.Converters.constructSignableVertexSpec(Converters.java:135)
	at org.apache.hadoop.hive.llap.tezplugins.LlapTaskCommunicator.constructSubmitWorkRequest(LlapTaskCommunicator.java:806)
	at org.apac</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="kafka"><div style="font-weight:bold;" class="panel-heading">KAFKA<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>8250738ae41f6f0a87dc1e21e7623c5d69cae148</div><div><b>Last Run: </b>03-07-2018 06:07 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 9315</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 3</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 9315</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.PlaintextEndToEndAuthorizationTest.testNoProduceWithDescribeAcl</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.UserQuotaTest.testQuotaOverrideDelete</li></div><div><li>kafka.security.auth.SimpleAclAuthorizerTest.testHighConcurrencyModificationOfResourceAcls</li></div><div><li>kafka.server.RequestQuotaTest.testResponseThrottleTimeWhenBothFetchAndRequestQuotasViolated</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.SaslPlaintextConsumerTest.testCoordinatorFailover</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.api.UserQuotaTest.testThrottledProducerConsumer</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.admin.ReassignPartitionsClusterTest.shouldExecuteThrottledReassignment</li></div><div><li>kafka.api.AuthorizerIntegrationTest.testConsumeWithTopicAndGroupRead</li></div><div><li>kafka.api.SslProducerSendTest.testSendCompressedMessageWithCreateTime</li></div><div><li>kafka.security.auth.SimpleAclAuthorizerTest.testHighConcurrencyModificationOfResourceAcls</li></div><div><li>kafka.server.AddPartitionsToTxnRequestTest.shouldReceiveOperationNotAttemptedWhenOtherPartitionHasError</li></div><div><li>org.apache.kafka.streams.integration.RegexSourceIntegrationTest.shouldAddStateStoreToRegexDefinedSource</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.SecurityException: zookeeper.set.acl is true, but the verification of the JAAS login file failed.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Should have been throttled</li></div><div><li>java.lang.AssertionError: expected acls:
	User:36 has Allow permission for operations: Read from hosts: *
	User:7 has Allow permission for operations: Read from hosts: *
	User:21 has Allow permission for operations: Read from hosts: *
	User:39 has Allow permission for operations: Read from hosts: *
	User:43 has Allow permission for operations: Read from hosts: *
	User:3 has Allow permission for op</li></div><div><li>java.util.concurrent.ExecutionException: java.lang.AssertionError: Throttle time metrics for consumer quota not updated: small-quota-consumer-client</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /brokers/ids</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>java.lang.AssertionError: Should have been throttled</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>kafka.common.AdminCommandFailedException: Partition reassignment currently in progress for Map(my-topic-0 -&gt; Buffer(101, 102)). Aborting operation</li></div><div><li>kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING</li></div><div><li>kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING</li></div><div><li>java.lang.AssertionError: expected acls:
	User:36 has Allow permission for operations: Read from hosts: *
	User:7 has Allow permission for operations: Read from hosts: *
	User:21 has Allow permission for operations: Read from hosts: *
	User:39 has Allow permission for operations: Read from hosts: *
	User:43 has Allow permission for operations: Read from hosts: *
	User:3 has Allow permission for op</li></div><div><li>kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING</li></div><div><li>java.lang.AssertionError: Condition not met within timeout 30000. metadata for topic=outputTopic partition=0 not propagated to all brokers</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.PlaintextEndToEndAuthorizationTest.testNoProduceWithDescribeAcl</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.UserQuotaTest.testQuotaOverrideDelete</div></li><li><div>kafka.security.auth.SimpleAclAuthorizerTest.testHighConcurrencyModificationOfResourceAcls</div></li><li><div>kafka.server.RequestQuotaTest.testResponseThrottleTimeWhenBothFetchAndRequestQuotasViolated</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.SaslPlaintextConsumerTest.testCoordinatorFailover</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.api.UserQuotaTest.testThrottledProducerConsumer</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>kafka.admin.ReassignPartitionsClusterTest.shouldExecuteThrottledReassignment</div></li><li><div>kafka.api.AuthorizerIntegrationTest.testConsumeWithTopicAndGroupRead</div></li><li><div>kafka.api.SslProducerSendTest.testSendCompressedMessageWithCreateTime</div></li><li><div>kafka.security.auth.SimpleAclAuthorizerTest.testHighConcurrencyModificationOfResourceAcls</div></li><li><div>kafka.server.AddPartitionsToTxnRequestTest.shouldReceiveOperationNotAttemptedWhenOtherPartitionHasError</div></li><li><div>org.apache.kafka.streams.integration.RegexSourceIntegrationTest.shouldAddStateStoreToRegexDefinedSource</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="knox"><div style="font-weight:bold;" class="panel-heading">KNOX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>b2ec86f71046867d7798635853a9c7076f6e3a20</div><div><b>Last Run: </b>03-07-2018 06:05 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1082</div><div>Failed Count : 1</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1083</div><div>Failed Count : 2</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSpecifiedNSHBaseZookeeperURLManagerLoadingWhenSecureAndUnsecureZNodesPresent</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.knox.gateway.ha.provider.impl.HS2ZookeeperURLManagerTest.testMarkingFailedURL</li></div><div><li>org.apache.knox.gateway.ha.provider.impl.HS2ZookeeperURLManagerTest.testMarkingFailedURL</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>KeeperErrorCode = ConnectionLoss for /hbase-unsecure</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Multiple entries with same key: InstanceSpec{dataDirectory=/tmp/1530598157501-1, port=36665, electionPort=44818, quorumPort=42591, deleteDataDirectoryOnClose=true, serverId=21, tickTime=-1, maxClientCnxns=-1, customProperties={}, hostname=127.0.0.1} org.apache.curator.test.InstanceSpec@59c444b6=[InstanceSpec{dataDirectory=/tmp/1530598157500-0, port=40942, electionPort=41849, quorumPort=34543, dele</li></div><div><li>java.lang.NullPointerException: null
	at org.apache.knox.gateway.ha.provider.impl.HS2ZookeeperURLManagerTest.teardown(HS2ZookeeperURLManagerTest.java:78)
</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.HBaseZookeeperURLManagerTest.testSpecifiedNSHBaseZookeeperURLManagerLoadingWhenSecureAndUnsecureZNodesPresent</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.knox.gateway.ha.provider.impl.HS2ZookeeperURLManagerTest.testMarkingFailedURL</div></li><li><div>org.apache.knox.gateway.ha.provider.impl.HS2ZookeeperURLManagerTest.testMarkingFailedURL</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="metron"><div style="font-weight:bold;" class="panel-heading">METRON<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>fc9ff85368c2a974d30ad6ccdb73a4cc26fd025c</div><div><b>Last Run: </b>03-07-2018 06:07 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1842</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="oozie"><div style="font-weight:bold;" class="panel-heading">OOZIE<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>5b55169c6743194223a0756756fc7247eb673aca</div><div><b>Last Run: </b>28-06-2018 21:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 2897</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 1</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 1</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 1</div><div>Skipped Count : 2</div></td><td><div>Total Count : 2897</div><div>Failed Count : 1</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandDate</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.action.hadoop.TestPyspark.testPyspark</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;RUNNING&gt; but was:&lt;RUNNINGWITHERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;RUNNING&gt; but was:&lt;KILLED&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;[SUCCEED]ED&gt; but was:&lt;[FAILED/KILL]ED&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Array index 6739 is not set to true</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandActionNumbers</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.command.coord.TestCoordActionsKillXCommand.testActionKillCommandDate</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.action.hadoop.TestPyspark.testPyspark</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.oozie.service.TestZKUUIDService.testMultipleIDGeneration_withMultiThread</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="phoenix"><div style="font-weight:bold;" class="panel-heading">PHOENIX<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>6195f8e7b5efeecd5c736ba0ef121b706c875d8d</div><div><b>Last Run: </b>28-06-2018 23:45 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1705</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="pig"><div style="font-weight:bold;" class="panel-heading">PIG<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>d84817abaa292af1320e69615a8f02e25c72d876</div><div><b>Last Run: </b>05-07-2018 02:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 723</div><div>Failed Count : 6</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td><td><div>Total Count : 895</div><div>Failed Count : 0</div><div>Skipped Count : 0</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.pig.test.TestBuiltin.testRANDOMWithJob</li></div><div><li>org.apache.pig.test.TestLoad.testCommaSeparatedString3</li></div><div><li>org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194</li></div><div><li>org.apache.pig.test.TestPigServer.testRegisterRemoteScript</li></div><div><li>org.apache.pig.test.TestSchema.testEnabledDisambiguationPassesForDupeAliases</li></div><div><li>org.apache.pig.test.TestStore.testStore</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.pig.test.TestBuiltin.testRANDOMWithJob</div></li><li><div>org.apache.pig.test.TestLoad.testCommaSeparatedString3</div></li><li><div>org.apache.pig.test.TestLocalRearrange.testMultiQueryJiraPig1194</div></li><li><div>org.apache.pig.test.TestPigServer.testRegisterRemoteScript</div></li><li><div>org.apache.pig.test.TestSchema.testEnabledDisambiguationPassesForDupeAliases</div></li><li><div>org.apache.pig.test.TestStore.testStore</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="ranger"><div style="font-weight:bold;" class="panel-heading">RANGER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>c129e7fefe929db9d7381567227580c0a4821663</div><div><b>Last Run: </b>05-07-2018 01:58 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td><td><div>Total Count : 1174</div><div>Failed Count : 0</div><div>Skipped Count : 2</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="slider"><div style="font-weight:bold;" class="panel-heading">SLIDER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/develop</div><div><b>Last Revision: </b>1d4f519d763210f46e327338be72efa99e65cb5d</div><div><b>Last Run: </b>28-06-2018 20:54 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td><td><div>Total Count : 607</div><div>Failed Count : 0</div><div>Skipped Count : 13</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="spark"><div style="font-weight:bold;" class="panel-heading">SPARK<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>ca8243f30fc6939ee099a9534e3b811d5c64d2cf</div><div><b>Last Run: </b>04-07-2018 18:59 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 14404</div><div>Failed Count : 0</div><div>Skipped Count : 669</div></td><td><div>Total Count : 1662</div><div>Failed Count : 863</div><div>Skipped Count : 3</div></td><td><div>Total Count : 14404</div><div>Failed Count : 1</div><div>Skipped Count : 669</div></td><td><div>Total Count : 16121</div><div>Failed Count : 1</div><div>Skipped Count : 676</div></td><td><div>Total Count : 14404</div><div>Failed Count : 2</div><div>Skipped Count : 669</div></td><td><div>Total Count : 1660</div><div>Failed Count : 871</div><div>Skipped Count : 3</div></td><td><div>Total Count : 14404</div><div>Failed Count : 7</div><div>Skipped Count : 669</div></td><td><div>Total Count : 16121</div><div>Failed Count : 1</div><div>Skipped Count : 676</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.network.RpcIntegrationSuite.sendRpcWithStreamFailures</li></div><div><li>org.apache.spark.JavaJdbcRDDSuite.testJavaJdbcRDD</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToGrow</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.setAndRetrieveAKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.multipleValuesForSameKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.testPeakMemoryUsed</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedTestWithRecordsLargerThanPageSize</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.spillInIterator</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.destructiveIteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratingOverDataPagesWithWastedSpace</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedStressTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.emptyMap</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToGrow</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.setAndRetrieveAKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.multipleValuesForSameKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.testPeakMemoryUsed</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedTestWithRecordsLargerThanPageSize</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.spillInIterator</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.destructiveIteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratingOverDataPagesWithWastedSpace</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedStressTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.emptyMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.flatMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.flatMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreach</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreach</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.map</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.map</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zip</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zip</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.keyBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.keyBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.groupBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.groupBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</li></div><div><li>test.org.apache.spark.JavaAPISuite.sparkContextUnion</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</li></div><div><li>test.org.apache.spark.JavaAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.JavaAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.getNumPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.getNumPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.wholeTextFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.wholeTextFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.lookup</li></div><div><li>test.org.apache.spark.JavaAPISuite.lookup</li></div><div><li>test.org.apache.spark.JavaAPISuite.countAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryRecords</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryRecords</li></div><div><li>test.org.apache.spark.JavaAPISuite.toLocalIterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.toLocalIterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.sample</li></div><div><li>test.org.apache.spark.JavaAPISuite.sample</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.JavaAPISuite.flatMap</li></div><div><li>test.org.apache.spark.JavaAPISuite.flatMap</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup3</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup3</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup4</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup4</li></div><div><li>test.org.apache.spark.JavaAPISuite.randomSplit</li></div><div><li>test.org.apache.spark.JavaAPISuite.randomSplit</li></div><div><li>test.org.apache.spark.JavaAPISuite.persist</li></div><div><li>test.org.apache.spark.JavaAPISuite.persist</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreach</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreach</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.accumulators</li></div><div><li>test.org.apache.spark.JavaAPISuite.accumulators</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFilesCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFilesCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregateByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregateByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.map</li></div><div><li>test.org.apache.spark.JavaAPISuite.map</li></div><div><li>test.org.apache.spark.JavaAPISuite.max</li></div><div><li>test.org.apache.spark.JavaAPISuite.max</li></div><div><li>test.org.apache.spark.JavaAPISuite.min</li></div><div><li>test.org.apache.spark.JavaAPISuite.min</li></div><div><li>test.org.apache.spark.JavaAPISuite.top</li></div><div><li>test.org.apache.spark.JavaAPISuite.top</li></div><div><li>test.org.apache.spark.JavaAPISuite.zip</li></div><div><li>test.org.apache.spark.JavaAPISuite.zip</li></div><div><li>test.org.apache.spark.JavaAPISuite.fold</li></div><div><li>test.org.apache.spark.JavaAPISuite.glom</li></div><div><li>test.org.apache.spark.JavaAPISuite.take</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.intersection</li></div><div><li>test.org.apache.spark.JavaAPISuite.intersection</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.cartesian</li></div><div><li>test.org.apache.spark.JavaAPISuite.cartesian</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</li></div><div><li>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeOrdered</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeOrdered</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeAggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeAggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</li></div><div><li>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</li></div><div><li>test.org.apache.spark.JavaAPISuite.approximateResults</li></div><div><li>test.org.apache.spark.JavaAPISuite.approximateResults</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinct</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinct</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMax</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMax</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMin</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMin</li></div><div><li>test.org.apache.spark.JavaAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.iterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.iterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.emptyRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.emptyRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachPartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachPartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.combineByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.combineByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.isEmpty</li></div><div><li>test.org.apache.spark.JavaAPISuite.isEmpty</li></div><div><li>test.org.apache.spark.JavaSparkContextSuite.javaSparkContext</li></div><div><li>test.org.apache.spark.JavaSparkContextSuite.scalaSparkContext</li></div><div><li>org.apache.spark.sql.kafka010.KafkaDataConsumerSuite.SPARK-23623: concurrent use of KafkaDataConsumer</li></div><div><li>org.apache.spark.streaming.kafka010.JavaDirectKafkaStreamSuite.testKafkaStream</li></div><div><li>org.apache.spark.streaming.kafka010.JavaKafkaRDDSuite.testKafkaRDD</li></div><div><li>org.apache.spark.graphx.EdgeRDDSuite.checkpointing</li></div><div><li>org.apache.spark.graphx.GraphLoaderSuite.GraphLoader.edgeListFile</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.joinVertices</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectNeighborIds</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.removeSelfEdges</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.filter</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.convertToCanonicalEdges</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionOut</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionIn</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionEither</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionOut</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionIn</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionEither</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.fromEdgeTuples</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.fromEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.apply</li></div><div><li>org.apache.spark.graphx.GraphSuite.triplets</li></div><div><li>org.apache.spark.graphx.GraphSuite.partitionBy</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapVertices</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapVertices changing type with same erased type</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapTriplets</li></div><div><li>org.apache.spark.graphx.GraphSuite.reverse</li></div><div><li>org.apache.spark.graphx.GraphSuite.reverse with join elimination</li></div><div><li>org.apache.spark.graphx.GraphSuite.subgraph</li></div><div><li>org.apache.spark.graphx.GraphSuite.mask</li></div><div><li>org.apache.spark.graphx.GraphSuite.groupEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.aggregateMessages</li></div><div><li>org.apache.spark.graphx.GraphSuite.outerJoinVertices</li></div><div><li>org.apache.spark.graphx.GraphSuite.more edge partitions than vertex partitions</li></div><div><li>org.apache.spark.graphx.GraphSuite.checkpoint</li></div><div><li>org.apache.spark.graphx.GraphSuite.cache, getStorageLevel</li></div><div><li>org.apache.spark.graphx.GraphSuite.non-default number of edge partitions</li></div><div><li>org.apache.spark.graphx.GraphSuite.unpersist graph RDD</li></div><div><li>org.apache.spark.graphx.GraphSuite.SPARK-14219: pickRandomVertex</li></div><div><li>org.apache.spark.graphx.PregelSuite.1 iteration</li></div><div><li>org.apache.spark.graphx.PregelSuite.chain propagation</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.filter</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.mapValues</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus with RDD[(VertexId, VD)]</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff with RDD[(VertexId, VD)]</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff vertices with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.leftJoin</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.leftJoin vertices with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.innerJoin</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.innerJoin vertices with the non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.aggregateUsingIndex</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.mergeFunc</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.cache, getStorageLevel</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.checkpoint</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Grid Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Grid Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Chain Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Chain Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Connected Components on a Toy Connected Graph</li></div><div><li>org.apache.spark.graphx.lib.LabelPropagationSuite.Label Propagation</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Star PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Star PersonalPageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Grid PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Chain PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Chain PersonalizedPageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Loop with source PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Loop with sink PageRank</li></div><div><li>org.apache.spark.graphx.lib.SVDPlusPlusSuite.Test SVD++ with mean square error on training set</li></div><div><li>org.apache.spark.graphx.lib.ShortestPathsSuite.Shortest Path Computations</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Island Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Cycle Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.2 Cycle Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles with bi-directed edges</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle with duplicate edges</li></div><div><li>org.apache.spark.graphx.util.GraphGeneratorsSuite.GraphGenerators.logNormalGraph</li></div><div><li>org.apache.spark.graphx.util.GraphGeneratorsSuite.SPARK-5064 GraphGenerators.rmatGraph numEdges upper bound</li></div><div><li>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Persisting</li></div><div><li>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Checkpointing</li></div><div><li>org.apache.spark.ml.JavaPipelineSuite.pipeline</li></div><div><li>org.apache.spark.ml.JavaPipelineSuite.pipeline</li></div><div><li>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</li></div><div><li>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</li></div><div><li>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</li></div><div><li>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</li></div><div><li>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</li></div><div><li>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</li></div><div><li>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</li></div><div><li>org.apache.spark.ml.feature.JavaPCASuite.testPCA</li></div><div><li>org.apache.spark.ml.feature.JavaPCASuite.testPCA</li></div><div><li>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</li></div><div><li>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</li></div><div><li>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</li></div><div><li>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</li></div><div><li>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</li></div><div><li>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</li></div><div><li>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</li></div><div><li>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</li></div><div><li>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</li></div><div><li>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</li></div><div><li>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</li></div><div><li>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</li></div><div><li>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</li></div><div><li>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</li></div><div><li>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</li></div><div><li>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</li></div><div><li>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</li></div><div><li>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</li></div><div><li>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</li></div><div><li>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</li></div><div><li>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</li></div><div><li>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</li></div><div><li>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</li></div><div><li>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</li></div><div><li>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</li></div><div><li>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</li></div><div><li>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</li></div><div><li>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</li></div><div><li>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</li></div><div><li>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</li></div><div><li>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</li></div><div><li>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</li></div><div><li>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</li></div><div><li>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</li></div><div><li>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</li></div><div><li>org.apache.spark.repl.ReplSuite.SPARK-15236: use Hive catalog</li></div><div><li>org.apache.spark.repl.ReplSuite.SPARK-15236: use in-memory catalog</li></div><div><li>org.apache.spark.repl.ReplSuite.broadcast vars</li></div><div><li>org.apache.spark.repl.ReplSuite.line wrapper only initialized once when used as encoder outer scope</li></div><div><li>org.apache.spark.repl.ReplSuite.define case class and create Dataset together with paste mode</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.simple foreach with accumulator</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external classes</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external functions</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external functions that access vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.broadcast vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.interacting with files</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.local-cluster mode</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.SPARK-2576 importing implicits</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.Datasets and encoders</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.SPARK-2632 importing a method from non serializable class and not using it.</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl - shuffling</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.replicating blocks of object with class defined in repl</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.newProductSeqEncoder with REPL defined class</li></div><div><li>org.apache.spark.sql.catalyst.expressions.HiveHasherSuite.testKnownStringAndIntInputs</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setAndRetrieve</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.randomizedTest</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.iteratorTest</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setUpdateAndRetrieve</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingCapacity</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingPageSize</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testFormatAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testJsonAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testLoadAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testOptionsAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testSaveModeAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testCsvAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testParquetAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextFileAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTake</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTake</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.test</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</li></div><div><li>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</li></div><div><li>test.org.apache.spark.sql.execution.sort.RecordBinaryComparatorSuite.testBinaryComparatorForMixedColumns</li></div><div><li>org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite.lazily initialize Hive client</li></div><div><li>org.apache.spark.sql.hive.JavaDataFrameSuite.testUDAF</li></div><div><li>org.apache.spark.sql.hive.JavaDataFrameSuite.saveTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableWithSchemaAndQueryIt</li></div><div><li>org.apache.spark.streaming.JavaMapWithStateSuite.testBasicFunction</li></div><div><li>org.apache.spark.streaming.JavaReceiverAPISuite.testReceiver</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCount</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCount</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUnion</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUnion</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGlom</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGlom</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRawSocketStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRawSocketStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextState</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextState</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.streaming.StreamingQueryListenerSuite.single listener, check trigger events are generated correctly</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</li></div><div><li>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.network.RpcIntegrationSuite.sendRpcWithStreamFailures</li></div><div><li>org.apache.spark.JavaJdbcRDDSuite.testJavaJdbcRDD</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToGrow</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.setAndRetrieveAKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.multipleValuesForSameKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.testPeakMemoryUsed</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedTestWithRecordsLargerThanPageSize</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.spillInIterator</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.destructiveIteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratingOverDataPagesWithWastedSpace</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedStressTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.emptyMap</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToGrow</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.setAndRetrieveAKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.multipleValuesForSameKey</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.testPeakMemoryUsed</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedTestWithRecordsLargerThanPageSize</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.spillInIterator</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.destructiveIteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratingOverDataPagesWithWastedSpace</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedStressTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratorTest</li></div><div><li>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.emptyMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.flatMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.flatMap</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreach</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreach</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.map</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.map</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zip</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zip</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.keyBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.keyBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.groupBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.groupBy</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</li></div><div><li>test.org.apache.spark.JavaAPISuite.sparkContextUnion</li></div><div><li>test.org.apache.spark.JavaAPISuite.sparkContextUnion</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</li></div><div><li>test.org.apache.spark.JavaAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.JavaAPISuite.leftOuterJoin</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.getNumPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.getNumPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.wholeTextFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.wholeTextFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.lookup</li></div><div><li>test.org.apache.spark.JavaAPISuite.lookup</li></div><div><li>test.org.apache.spark.JavaAPISuite.countAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.countAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFiles</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryRecords</li></div><div><li>test.org.apache.spark.JavaAPISuite.binaryRecords</li></div><div><li>test.org.apache.spark.JavaAPISuite.toLocalIterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.toLocalIterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.sample</li></div><div><li>test.org.apache.spark.JavaAPISuite.sample</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</li></div><div><li>test.org.apache.spark.JavaAPISuite.flatMap</li></div><div><li>test.org.apache.spark.JavaAPISuite.flatMap</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup3</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup3</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup4</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup4</li></div><div><li>test.org.apache.spark.JavaAPISuite.randomSplit</li></div><div><li>test.org.apache.spark.JavaAPISuite.persist</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreach</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreach</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.accumulators</li></div><div><li>test.org.apache.spark.JavaAPISuite.accumulators</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFilesCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.textFilesCompressed</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</li></div><div><li>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.sortByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregateByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregateByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.map</li></div><div><li>test.org.apache.spark.JavaAPISuite.map</li></div><div><li>test.org.apache.spark.JavaAPISuite.max</li></div><div><li>test.org.apache.spark.JavaAPISuite.max</li></div><div><li>test.org.apache.spark.JavaAPISuite.min</li></div><div><li>test.org.apache.spark.JavaAPISuite.min</li></div><div><li>test.org.apache.spark.JavaAPISuite.top</li></div><div><li>test.org.apache.spark.JavaAPISuite.top</li></div><div><li>test.org.apache.spark.JavaAPISuite.zip</li></div><div><li>test.org.apache.spark.JavaAPISuite.zip</li></div><div><li>test.org.apache.spark.JavaAPISuite.fold</li></div><div><li>test.org.apache.spark.JavaAPISuite.fold</li></div><div><li>test.org.apache.spark.JavaAPISuite.glom</li></div><div><li>test.org.apache.spark.JavaAPISuite.glom</li></div><div><li>test.org.apache.spark.JavaAPISuite.take</li></div><div><li>test.org.apache.spark.JavaAPISuite.take</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.keyBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.intersection</li></div><div><li>test.org.apache.spark.JavaAPISuite.intersection</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.aggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.cartesian</li></div><div><li>test.org.apache.spark.JavaAPISuite.cartesian</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</li></div><div><li>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.groupBy</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</li></div><div><li>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeOrdered</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeOrdered</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.foldByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeAggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeAggregate</li></div><div><li>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</li></div><div><li>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</li></div><div><li>test.org.apache.spark.JavaAPISuite.approximateResults</li></div><div><li>test.org.apache.spark.JavaAPISuite.approximateResults</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.treeReduce</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinct</li></div><div><li>test.org.apache.spark.JavaAPISuite.countApproxDistinct</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMax</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMax</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMin</li></div><div><li>test.org.apache.spark.JavaAPISuite.naturalMin</li></div><div><li>test.org.apache.spark.JavaAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.sequenceFile</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup</li></div><div><li>test.org.apache.spark.JavaAPISuite.cogroup</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.repartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.iterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.iterator</li></div><div><li>test.org.apache.spark.JavaAPISuite.emptyRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.emptyRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithIndex</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachPartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachPartition</li></div><div><li>test.org.apache.spark.JavaAPISuite.combineByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.combineByKey</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.takeAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</li></div><div><li>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.collectAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.foreachAsync</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.zipPartitions</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</li></div><div><li>test.org.apache.spark.JavaAPISuite.isEmpty</li></div><div><li>test.org.apache.spark.JavaAPISuite.isEmpty</li></div><div><li>test.org.apache.spark.JavaSparkContextSuite.javaSparkContext</li></div><div><li>test.org.apache.spark.JavaSparkContextSuite.scalaSparkContext</li></div><div><li>org.apache.spark.streaming.kafka010.JavaDirectKafkaStreamSuite.testKafkaStream</li></div><div><li>org.apache.spark.streaming.kafka010.JavaKafkaRDDSuite.testKafkaRDD</li></div><div><li>org.apache.spark.graphx.EdgeRDDSuite.cache, getStorageLevel</li></div><div><li>org.apache.spark.graphx.EdgeRDDSuite.checkpointing</li></div><div><li>org.apache.spark.graphx.GraphLoaderSuite.GraphLoader.edgeListFile</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.joinVertices</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectNeighborIds</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.removeSelfEdges</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.filter</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.convertToCanonicalEdges</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionOut</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionIn</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionEither</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionOut</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionIn</li></div><div><li>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionEither</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.fromEdgeTuples</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.fromEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.Graph.apply</li></div><div><li>org.apache.spark.graphx.GraphSuite.triplets</li></div><div><li>org.apache.spark.graphx.GraphSuite.partitionBy</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapVertices</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapVertices changing type with same erased type</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.mapTriplets</li></div><div><li>org.apache.spark.graphx.GraphSuite.reverse</li></div><div><li>org.apache.spark.graphx.GraphSuite.reverse with join elimination</li></div><div><li>org.apache.spark.graphx.GraphSuite.subgraph</li></div><div><li>org.apache.spark.graphx.GraphSuite.mask</li></div><div><li>org.apache.spark.graphx.GraphSuite.groupEdges</li></div><div><li>org.apache.spark.graphx.GraphSuite.aggregateMessages</li></div><div><li>org.apache.spark.graphx.GraphSuite.outerJoinVertices</li></div><div><li>org.apache.spark.graphx.GraphSuite.more edge partitions than vertex partitions</li></div><div><li>org.apache.spark.graphx.GraphSuite.checkpoint</li></div><div><li>org.apache.spark.graphx.GraphSuite.cache, getStorageLevel</li></div><div><li>org.apache.spark.graphx.GraphSuite.non-default number of edge partitions</li></div><div><li>org.apache.spark.graphx.GraphSuite.unpersist graph RDD</li></div><div><li>org.apache.spark.graphx.GraphSuite.SPARK-14219: pickRandomVertex</li></div><div><li>org.apache.spark.graphx.PregelSuite.1 iteration</li></div><div><li>org.apache.spark.graphx.PregelSuite.chain propagation</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.filter</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.mapValues</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus with RDD[(VertexId, VD)]</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.minus with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff with RDD[(VertexId, VD)]</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.diff vertices with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.leftJoin</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.leftJoin vertices with non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.innerJoin</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.innerJoin vertices with the non-equal number of partitions</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.aggregateUsingIndex</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.mergeFunc</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.cache, getStorageLevel</li></div><div><li>org.apache.spark.graphx.VertexRDDSuite.checkpoint</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Grid Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Grid Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Chain Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Chain Connected Components</li></div><div><li>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Connected Components on a Toy Connected Graph</li></div><div><li>org.apache.spark.graphx.lib.LabelPropagationSuite.Label Propagation</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Star PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Star PersonalPageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Grid PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Chain PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Chain PersonalizedPageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Loop with source PageRank</li></div><div><li>org.apache.spark.graphx.lib.PageRankSuite.Loop with sink PageRank</li></div><div><li>org.apache.spark.graphx.lib.SVDPlusPlusSuite.Test SVD++ with mean square error on training set</li></div><div><li>org.apache.spark.graphx.lib.ShortestPathsSuite.Shortest Path Computations</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Island Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Cycle Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.2 Cycle Strongly Connected Components</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles with bi-directed edges</li></div><div><li>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle with duplicate edges</li></div><div><li>org.apache.spark.graphx.util.GraphGeneratorsSuite.GraphGenerators.logNormalGraph</li></div><div><li>org.apache.spark.graphx.util.GraphGeneratorsSuite.SPARK-5064 GraphGenerators.rmatGraph numEdges upper bound</li></div><div><li>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Persisting</li></div><div><li>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Checkpointing</li></div><div><li>org.apache.spark.ml.JavaPipelineSuite.pipeline</li></div><div><li>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</li></div><div><li>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</li></div><div><li>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</li></div><div><li>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</li></div><div><li>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</li></div><div><li>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</li></div><div><li>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</li></div><div><li>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</li></div><div><li>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</li></div><div><li>org.apache.spark.ml.feature.JavaPCASuite.testPCA</li></div><div><li>org.apache.spark.ml.feature.JavaPCASuite.testPCA</li></div><div><li>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</li></div><div><li>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</li></div><div><li>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</li></div><div><li>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</li></div><div><li>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</li></div><div><li>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</li></div><div><li>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</li></div><div><li>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</li></div><div><li>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</li></div><div><li>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</li></div><div><li>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</li></div><div><li>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</li></div><div><li>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</li></div><div><li>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</li></div><div><li>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</li></div><div><li>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</li></div><div><li>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</li></div><div><li>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</li></div><div><li>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</li></div><div><li>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</li></div><div><li>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</li></div><div><li>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</li></div><div><li>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</li></div><div><li>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</li></div><div><li>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</li></div><div><li>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</li></div><div><li>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</li></div><div><li>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</li></div><div><li>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</li></div><div><li>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</li></div><div><li>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</li></div><div><li>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</li></div><div><li>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</li></div><div><li>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</li></div><div><li>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</li></div><div><li>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</li></div><div><li>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</li></div><div><li>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</li></div><div><li>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</li></div><div><li>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</li></div><div><li>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</li></div><div><li>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</li></div><div><li>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</li></div><div><li>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</li></div><div><li>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</li></div><div><li>org.apache.spark.repl.ReplSuite.SPARK-15236: use Hive catalog</li></div><div><li>org.apache.spark.repl.ReplSuite.SPARK-15236: use in-memory catalog</li></div><div><li>org.apache.spark.repl.ReplSuite.broadcast vars</li></div><div><li>org.apache.spark.repl.ReplSuite.line wrapper only initialized once when used as encoder outer scope</li></div><div><li>org.apache.spark.repl.ReplSuite.define case class and create Dataset together with paste mode</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.simple foreach with accumulator</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external classes</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external functions</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.external functions that access vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.broadcast vars</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.interacting with files</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.local-cluster mode</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.SPARK-2576 importing implicits</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.Datasets and encoders</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.SPARK-2632 importing a method from non serializable class and not using it.</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl - shuffling</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.replicating blocks of object with class defined in repl</li></div><div><li>org.apache.spark.repl.SingletonReplSuite.newProductSeqEncoder with REPL defined class</li></div><div><li>org.apache.spark.sql.catalyst.expressions.HiveHasherSuite.testKnownStringAndIntInputs</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.failureToAllocateFirstPage</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setAndRetrieve</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.randomizedTest</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.iteratorTest</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setUpdateAndRetrieve</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingCapacity</li></div><div><li>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingPageSize</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</li></div><div><li>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testFormatAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testJsonAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testLoadAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testOptionsAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testSaveModeAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testCsvAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testParquetAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextFileAPI</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTake</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTake</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.test</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.test</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</li></div><div><li>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</li></div><div><li>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</li></div><div><li>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</li></div><div><li>test.org.apache.spark.sql.execution.sort.RecordBinaryComparatorSuite.testBinaryComparatorForMixedColumns</li></div><div><li>org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite.lazily initialize Hive client</li></div><div><li>org.apache.spark.sql.hive.JavaDataFrameSuite.testUDAF</li></div><div><li>org.apache.spark.sql.hive.JavaDataFrameSuite.saveTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveTableAndQueryIt</li></div><div><li>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableWithSchemaAndQueryIt</li></div><div><li>org.apache.spark.streaming.JavaMapWithStateSuite.testBasicFunction</li></div><div><li>org.apache.spark.streaming.JavaReceiverAPISuite.testReceiver</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.Java8APISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testStreamingContextTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCount</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCount</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUnion</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUnion</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindowWithInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGlom</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGlom</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testFilter</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testReduce</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testTransform</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextState</li></div><div><li>test.org.apache.spark.streaming.JavaAPISuite.testContextState</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.assign from earliest offsets (failOnDataLoss: false)</li></div><div><li>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.subscribing topic by name from latest offsets (failOnDataLoss: false)</li></div><div><li>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.subscribing topic by pattern from earliest offsets (failOnDataLoss: false)</li></div><div><li>org.apache.spark.sql.kafka010.KafkaContinuousSourceTopicDeletionSuite.subscribing topic by pattern with topic deletions</li></div><div><li>org.apache.spark.sql.catalyst.util.DateTimeUtilsSuite.daysToMillis and millisToDays</li></div><div><li>org.apache.spark.sql.JoinSuite.test SortMergeJoin (with spill)</li></div><div><li>org.apache.spark.sql.streaming.StreamingQueryListenersConfSuite.test if the configured query lister is loaded</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.spark.sql.catalyst.util.DateTimeUtilsSuite.daysToMillis and millisToDays</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>SparkContext has been shutdown</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAcce</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAcce</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAcce</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAcce</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.N</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>SparkContext has been shutdown</li></div><div><li>SparkContext has been shutdown</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
sun.reflect.D</li></div><div><li>java.lang.NullPointerException</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.EdgeRDDSuite.withSpark(Edge</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphLoaderSuite.withSpark(GraphLoaderSuite.scala:28)&amp;#010;org.apache.spark.graphx.GraphLoaderSuite$$anonfun$2.app</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(GraphOpsSuite.scala:23)&amp;#010;org.apache.spark.graphx.GraphOpsSuite$$anonfun$9.apply(GraphO</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.w</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphSuite.scala:27)&amp;#010;org.apache.spark.graphx.GraphSuite$$anonfun$23.apply(GraphSuite.sca</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.PregelSuite.withSpark(PregelSuite.scala:22)&amp;#010;org.apache.spark.graphx.PregelSuite$$anonfun$4.apply(PregelSuite.</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.withSpark(LabelPropagationSuite.scala:23)&amp;#010;org.apache.spark.graphx.lib.LabelPropagat</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.LabelPropagationSuite.w</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.withSpark(StronglyConnectedComponentsSuite.scala:24)&amp;#010;org.apache.spark.gr</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.withSpark(StronglyConnectedComponentsSuite.scala:24)&amp;#010;org.apache.spark.gr</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.TriangleCountSuite.withSpark(TriangleCountSuite.scala:25)&amp;#010;org.apache.spark.graphx.lib.TriangleCountSuite$</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.TriangleCountSuite.with</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.TriangleCountSuite.with</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.withSpark(GraphGeneratorsSuite.scala:23)&amp;#010;org.apache.spark.graphx.util.GraphGenerato</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.withSpark(PeriodicGraphCheckpointerSuite.scala:28)&amp;#010;org.apache.spark.graph</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.util.JavaDefaultReadWriteSuite.setUp(JavaDefaultReadWriteSuite.java:34)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflec</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.util.JavaDefaultReadWriteSuite.setUp(JavaDefaultReadWriteSuite.java:34)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflec</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.util.JavaDefaultReadWriteSuite.setUp(JavaDefaultReadWriteSuite.java:34)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflec</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.classification.JavaLogisticRegressionSuite.setUp(JavaLogisticRegressionSuite.java:43)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.tearDown(JavaLibSVMRelationSuite.java:57)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.util.JavaDefaultReadWriteSuite.setUp(JavaDefaultReadWriteSuite.java:34)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflec</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.ml.util.JavaDefaultReadWriteSuite.tearDown(JavaDefaultReadWriteSuite.java:41)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:4</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.tearDown(JavaStreamingLogisticRegressionSuite.java:55)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:4</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.tearDown(JavaStreamingKMeansSuite.java:54)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:4</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.tearDown(JavaStreamingLinearRegressionSuite.java:54)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.mllib.clustering.JavaLDASuite.setUp(JavaLDASuite.java:41)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.M</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Error while instantiating 'org.apache.spark.sql.internal.SessionStateBuilder':</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; java.lang.NoClassDefFoundError: org/spark_project/guava/cache/Weigher&amp;#010;  at org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.&lt;init&gt;(ExternalShuffleBlockHandler.java:64)&amp;#010;  at org.apache.spark.deploy.ExternalShuffleService.newShuffleBlockHandler(ExternalShuffleService.scala:63)&amp;#010;  at org.apache.spark</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; v).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2 = sc.parallelize(1 to 10).map(x =&gt;</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt;      |      | defined class C&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:18: error: not found: value sc&amp;#010;       val res = sc.parallelize(1 to 10).map(x =&gt; (new C).foo).collect().reduceLeft(_+_)&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530733676805: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; double: (x: Int)Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res = sc.parallelize(1 to 10).map(x =&gt; double(x)).collect().reduceLeft(_+_)&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530733677062: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; getV: ()Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; getV()).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; array: Array[Int] = Array(0, 0, 0, 0, 0)&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val broadcastArray = sc.broadcast(array)&amp;#010;                            ^&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(0 to 4).map(x =&gt; broadcastArray.value(x</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value sc&amp;#010;       var file = sc.textFile("/var/lib/jenkins/workspace/spark/repl/target/tmp/spark-38234d09-1631-4a53-b21c-0fe5e66afc0a/input").cache()&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value file&amp;#010;       val res1 = file.count()&amp;#010;            </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; getV: ()Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; getV()).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value spark&amp;#010;       import spark.implicits._&amp;#010;              ^&amp;#010;&amp;#010;scala&gt; defined class TestCaseClass&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:22: error: not found: value sc&amp;#010;       sc.parallelize(1 to 10).map(x =&gt; TestCaseClass(x)).toDF().collect()&amp;#010;       ^&amp;#010;&amp;#010;scala&gt; &amp;#010</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.functions._&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.{Encoder, Encoders}&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.expressions.Aggregator&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.TypedColumn&amp;#010;&amp;#010;scala&gt;      |      |      |      |      |      |      | java.lang.NoClassDefFoun</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class TestClass&amp;#010;&amp;#010;scala&gt; t: TestClass = TestClass@569cd827&amp;#010;&amp;#010;scala&gt; import t.testMethod&amp;#010;&amp;#010;scala&gt; defined class TestCaseClass&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:31: error: not found: value sc&amp;#010;       sc.parallelize(1 to 10).map(x =&gt; TestCaseClass(x)).collect()&amp;#010;       ^&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Foo&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:28: error: not found: value sc&amp;#010;       val res = sc.parallelize((1 to 100).map(Foo), 10).collect()&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530733684356: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Foo&amp;#010;&amp;#010;scala&gt; list: List[(Int, Foo)] = List((1,Foo(1)), (1,Foo(2)))&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:28: error: not found: value sc&amp;#010;       val res = sc.parallelize(list).groupByKey().collect()&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530733684660: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; timeout: Int = 60000&amp;#010;&amp;#010;scala&gt; start: Long = 1530733685384&amp;#010;&amp;#010;scala&gt;      |      |      | &lt;console&gt;:31: error: not found: value sc&amp;#010;       while(sc.statusTracker.getExecutorInfos.size != 3 &amp;&amp;&amp;#010;             ^&amp;#010;&amp;#010;scala&gt;      |      | &amp;#010;scala&gt; import org.apache.spark.storage.StorageLevel._&amp;</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Click&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:33: error: not found: value spark&amp;#010;       spark.implicits.newProductSeqEncoder[Click]&amp;#010;       ^&amp;#010;&amp;#010;scala&gt;      | _result_1530733687178: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImp</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaApplySchemaSuite.tearDown(JavaApplySchemaSuite.java:60)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaApplySchemaSuite.tearDown(JavaApplySchemaSuite.java:60)
</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeC</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.&lt;init&gt;(JavaDataFrameReaderWriterSuite.java:33)
sun.reflect.NativeConstructorAcces</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.Delega</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.Delegating</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.Delegating</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaSaveLoadSuite.setUp(JavaSaveLoadSuite.java:57)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.Deleg</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaSaveLoadSuite.tearDown(JavaSaveLoadSuite.java:76)
</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite$$anonfun$1.apply(HiveMetastoreLazyInitializationSuite.scala:32)&amp;#010;org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)&amp;#010;org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)&amp;#010;org.scalatest.Transformer.apply(Trans</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>java.lang.ExceptionInInitializerError
	at org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.setUp(JavaMetastoreDataSourcesSuite.java:66)
Caused by: java.lang.IllegalStateException: 
Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.setUp(JavaMetastoreDataSourcesSuite.java:66)
sun.reflect.NativeMet</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(StreamingContext.scala:85)
org.apache.spark.streaming.api.java.JavaStreamingContext.&lt;init&gt;(JavaStreaming</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(StreamingContext.scala:85)
org.apache.spark.streaming.api.java.JavaStreamingContext.&lt;init&gt;(JavaStreaming</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(StreamingContext.scala:85)
org.apache.spark.streaming.api.java.JavaStreamingContext.&lt;init&gt;(JavaStreaming</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Timeout of './bin/spark-submit' '--class' 'org.apache.spark.sql.hive.SparkSQLConfTest' '--name' 'SparkSQLConfTest' '--master' 'local-cluster[2,1,1024]' '--conf' 'spark.ui.enabled=false' '--conf' 'spark.master.rest.enabled=false' '--conf' 'spark.sql.hive.metastore.version=0.12' '--conf' 'spark.sql.hive.metastore.jars=maven' '--driver-java-options' '-Dderby.system.durability=test' 'file:/var/lib/jen</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>&amp;#010;Assert on query failed: : Queue() was empty&amp;#010;org.scalatest.Assertions$class.newAssertionFailedException(Assertions.scala:528)&amp;#010; org.scalatest.FunSuite.newAssertionFailedException(FunSuite.scala:1560)&amp;#010; org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501)&amp;#010; org.apache.spark.sql.streaming.StreamingQueryListenerSuite$$anonfun$2$$anonfun$apply$mcV$sp$8.appl</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>&amp;#010;Assert on query failed: Execute: Exception thrown in awaitResult: &amp;#010;org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:222)&amp;#010; org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)&amp;#010; org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)&amp;#010; org.apache.spark.util.RpcUtils$.</li></div><div><li>Timeout of './bin/spark-submit' '--class' 'org.apache.spark.sql.hive.SparkSQLConfTest' '--name' 'SparkSQLConfTest' '--master' 'local-cluster[2,1,1024]' '--conf' 'spark.ui.enabled=false' '--conf' 'spark.master.rest.enabled=false' '--conf' 'spark.sql.hive.metastore.version=0.12' '--conf' 'spark.sql.hive.metastore.jars=maven' '--driver-java-options' '-Dderby.system.durability=test' 'file:/var/lib/jen</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;1&gt; but was:&lt;2&gt;</li></div><div><li>SparkContext has been shutdown</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.Java8RDDAPISuite.tearDown(Java8RDDAPISuite.java:59)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Metho</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Metho</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Metho</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:64)
test.org.apache.spark.JavaAPISuite.setUp(JavaAPISuite.java:90)
sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.JavaAPISuite.tearDown(JavaAPISuite.java:97)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
test.org.apache.spark.JavaSparkContextSuite.javaSparkContext(JavaSparkContextSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphLoaderSuite.withSpark(GraphLoaderSuite.scala:28)&amp;#010;org.apache.spark.graphx.GraphLoaderSuite$$anonfun$2.app</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(GraphOpsSuite.scala:23)&amp;#010;org.apache.spark.graphx.GraphOpsSuite$$anonfun$9.apply(GraphO</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphOpsSuite.withSpark(Gra</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphSuite.scala:27)&amp;#010;org.apache.spark.graphx.GraphSuite$$anonfun$11.apply(GraphSuite.sca</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphSuite.scala:27)&amp;#010;org.apache.spark.graphx.GraphSuite$$anonfun$42.apply(GraphSuite.sca</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.GraphSuite.withSpark(GraphS</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.PregelSuite.withSpark(PregelSuite.scala:22)&amp;#010;org.apache.spark.graphx.PregelSuite$$anonfun$4.apply(PregelSuite.</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.VertexRDDSuite.withSpark(Ve</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.VertexRDDSuite.withSpark(Ve</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.VertexRDDSuite.withSpark(Ve</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.VertexRDDSuite.withSpark(Ve</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.ConnectedComponentsSuit</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.ConnectedComponentsSuit</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.SVDPlusPlusSuite.withSpark(SVDPlusPlusSuite.scala:24)&amp;#010;org.apache.spark.graphx.lib.SVDPlusPlusSuite$$anonf</li></div><div><li>java.lang.NullPointerException was thrown.</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.withSpark(StronglyConnectedComponentsSuite.scala:24)&amp;#010;org.apache.spark.gr</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.lib.StronglyConnectedCompon</li></div><div><li>SparkContext has been shutdown</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.GraphGeneratorsSuite.w</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.withSpark(PeriodicGraphCheckpointerSuite.scala:28)&amp;#010;org.apache.spark.graph</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:&amp;#010;org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:127)&amp;#010;org.apache.spark.graphx.LocalSparkContext$class.withSpark(LocalSparkContext.scala:32)&amp;#010;org.apache.spark.graphx.util.PeriodicGraphCheckpoin</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.JavaPipelineSuite.setUp(JavaPipelineSuite.java:42)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Metho</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Error while instantiating 'org.apache.spark.sql.internal.SessionStateBuilder':</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Error while instantiating 'org.apache.spark.sql.internal.SessionStateBuilder':</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.tuning.JavaCrossValidatorSuite.setUp(JavaCrossValidatorSuite.java:42)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.clustering.JavaKMeansSuite.setUp(JavaKMeansSuite.java:40)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMe</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.ml.util.JavaDefaultReadWriteSuite.tearDown(JavaDefaultReadWriteSuite.java:41)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:4</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.tearDown(JavaStreamingLogisticRegressionSuite.java:55)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invo</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.tearDown(JavaStreamingKMeansSuite.java:54)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:4</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.tearDown(JavaStreamingLinearRegressionSuite.java:54)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
	at org.apache.spark.mllib.stat.JavaStatisticsSuite.tearDown(JavaStatisticsSuite.java:65)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.junit.runners.model.FrameworkMethod$1.run</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SharedSparkSession.setUp(SharedSparkSession.java:39)
org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.setUp(JavaKolmogorovSmirnovTestSuite.java:40)
sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.j</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_161)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_161)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_161)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'Exception':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_161)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;Welcome to&amp;#010;      ____              __&amp;#010;     / __/__  ___ _____/ /__&amp;#010;    _\ \/ _ \/ _ `/ __/  '_/&amp;#010;   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0-SNAPSHOT&amp;#010;      /_/&amp;#010;         &amp;#010;Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_161)&amp;#010;Type in expressions to have them evaluated.&amp;#010;Type :he</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; java.lang.NoClassDefFoundError: org/spark_project/guava/cache/Weigher&amp;#010;  at org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.&lt;init&gt;(ExternalShuffleBlockHandler.java:64)&amp;#010;  at org.apache.spark.deploy.ExternalShuffleService.newShuffleBlockHandler(ExternalShuffleService.scala:63)&amp;#010;  at org.apache.spark</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; v).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2 = sc.parallelize(1 to 10).map(x =&gt;</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt;      |      | defined class C&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:18: error: not found: value sc&amp;#010;       val res = sc.parallelize(1 to 10).map(x =&gt; (new C).foo).collect().reduceLeft(_+_)&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530734451162: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; double: (x: Int)Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res = sc.parallelize(1 to 10).map(x =&gt; double(x)).collect().reduceLeft(_+_)&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530734451629: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; getV: ()Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; getV()).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; array: Array[Int] = Array(0, 0, 0, 0, 0)&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val broadcastArray = sc.broadcast(array)&amp;#010;                            ^&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(0 to 4).map(x =&gt; broadcastArray.value(x</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value sc&amp;#010;       var file = sc.textFile("/var/lib/jenkins/workspace/spark/repl/target/tmp/spark-12041cc5-c541-4349-9cfa-ebe74b2cefd1/input").cache()&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value file&amp;#010;       val res1 = file.count()&amp;#010;            </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; v: Int = 7&amp;#010;&amp;#010;scala&gt; getV: ()Int&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res1 = sc.parallelize(1 to 10).map(x =&gt; getV()).collect().reduceLeft(_+_)&amp;#010;                  ^&amp;#010;&amp;#010;scala&gt; v: Int = 10&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:19: error: not found: value sc&amp;#010;       val res2</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:17: error: not found: value spark&amp;#010;       import spark.implicits._&amp;#010;              ^&amp;#010;&amp;#010;scala&gt; defined class TestCaseClass&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:22: error: not found: value sc&amp;#010;       sc.parallelize(1 to 10).map(x =&gt; TestCaseClass(x)).toDF().collect()&amp;#010;       ^&amp;#010;&amp;#010;scala&gt; &amp;#010</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.functions._&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.{Encoder, Encoders}&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.expressions.Aggregator&amp;#010;&amp;#010;scala&gt; import org.apache.spark.sql.TypedColumn&amp;#010;&amp;#010;scala&gt;      |      |      |      |      |      |      | java.lang.NoClassDefFoun</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class TestClass&amp;#010;&amp;#010;scala&gt; t: TestClass = TestClass@55ce98da&amp;#010;&amp;#010;scala&gt; import t.testMethod&amp;#010;&amp;#010;scala&gt; defined class TestCaseClass&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:31: error: not found: value sc&amp;#010;       sc.parallelize(1 to 10).map(x =&gt; TestCaseClass(x)).collect()&amp;#010;       ^&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Foo&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:28: error: not found: value sc&amp;#010;       val res = sc.parallelize((1 to 100).map(Foo), 10).collect()&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530734462985: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Foo&amp;#010;&amp;#010;scala&gt; list: List[(Int, Foo)] = List((1,Foo(1)), (1,Foo(2)))&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:28: error: not found: value sc&amp;#010;       val res = sc.parallelize(list).groupByKey().collect()&amp;#010;                 ^&amp;#010;&amp;#010;scala&gt;      | _result_1530734463454: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; timeout: Int = 60000&amp;#010;&amp;#010;scala&gt; start: Long = 1530734464790&amp;#010;&amp;#010;scala&gt;      |      |      | &lt;console&gt;:31: error: not found: value sc&amp;#010;       while(sc.statusTracker.getExecutorInfos.size != 3 &amp;&amp;&amp;#010;             ^&amp;#010;&amp;#010;scala&gt;      |      | &amp;#010;scala&gt; import org.apache.spark.storage.StorageLevel._&amp;</li></div><div><li>isContain was true Interpreter output contained 'error:':&amp;#010;&amp;#010;scala&gt; defined class Click&amp;#010;&amp;#010;scala&gt; &lt;console&gt;:33: error: not found: value spark&amp;#010;       spark.implicits.newProductSeqEncoder[Click]&amp;#010;       ^&amp;#010;&amp;#010;scala&gt;      | _result_1530734467003: Int = 1&amp;#010;&amp;#010;scala&gt; </li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Could not initialize class org.apache.spark.unsafe.types.UTF8String</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaApplySchemaSuite.tearDown(JavaApplySchemaSuite.java:60)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaApplySchemaSuite.tearDown(JavaApplySchemaSuite.java:60)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaApplySchemaSuite.setUp(JavaApplySchemaSuite.java:54)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native </li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDataFrameSuite.tearDown(JavaDataFrameSuite.java:61)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImp</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImp</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImp</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetAggregatorSuiteBase.setUp(JavaDatasetAggregatorSuiteBase.java:45)
sun.reflect.NativeMethodAccessorImp</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaDatasetSuite.tearDown(JavaDatasetSuite.java:64)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaSaveLoadSuite.tearDown(JavaSaveLoadSuite.java:76)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaSaveLoadSuite.tearDown(JavaSaveLoadSuite.java:76)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.test.TestSparkSession.&lt;init&gt;(TestSQLContext.scala:34)
test.org.apache.spark.sql.JavaDatasetSuite.setUp(JavaDatasetSuite.java:57)
sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.refl</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDAFSuite.tearDown(JavaUDAFSuite.java:42)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:925)
test.org.apache.spark.sql.JavaUDFSuite.setUp(JavaUDFSuite.java:45)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMetho</li></div><div><li>java.lang.NullPointerException
	at test.org.apache.spark.sql.JavaUDFSuite.tearDown(JavaUDFSuite.java:50)
</li></div><div><li>org/spark_project/guava/primitives/Ints</li></div><div><li>Cannot call methods on a stopped SparkContext.&amp;#010;This stopped SparkContext was created at:&amp;#010;&amp;#010;org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite$$anonfun$1.apply(HiveMetastoreLazyInitializationSuite.scala:32)&amp;#010;org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)&amp;#010;org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)&amp;#010;org.scalatest.Transformer.apply(Trans</li></div><div><li>java.lang.ExceptionInInitializerError
	at org.apache.spark.sql.hive.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:50)
Caused by: java.lang.IllegalStateException: 
Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.hive.JavaDataFrameSuite.setUp(JavaDataFrameSuite.java:50)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.r</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Could not initialize class org.apache.spark.sql.hive.test.TestHive$</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(StreamingContext.scala:85)
org.apache.spark.streaming.api.java.JavaStreamingContext.&lt;init&gt;(JavaStreaming</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>LiveListenerBus is stopped.</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(StreamingContext.scala:85)
org.apache.spark.streaming.api.java.JavaStreamingContext.&lt;init&gt;(JavaStreaming</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div><div><li>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:76)
org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:838)
org.apache.spark.streaming.StreamingContext.&lt;init&gt;(Streami</li></div><div><li>java.lang.NullPointerException
</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>&amp;#010;Timed out waiting for stream: The code passed to failAfter did not complete within 30 seconds.&amp;#010;java.lang.Thread.getStackTrace(Thread.java:1559)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfterImpl(TimeLimits.scala:234)&amp;#010; org.apache.spark.sql.kafka010.KafkaSourceTest.failAfterImpl(KafkaMicroBatchSourceSuite.scala:52)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfter(</li></div><div><li>&amp;#010;Timed out waiting for stream: The code passed to failAfter did not complete within 30 seconds.&amp;#010;java.lang.Thread.getStackTrace(Thread.java:1559)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfterImpl(TimeLimits.scala:234)&amp;#010; org.apache.spark.sql.kafka010.KafkaSourceTest.failAfterImpl(KafkaMicroBatchSourceSuite.scala:52)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfter(</li></div><div><li>&amp;#010;Timed out waiting for stream: The code passed to failAfter did not complete within 30 seconds.&amp;#010;java.lang.Thread.getStackTrace(Thread.java:1559)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfterImpl(TimeLimits.scala:234)&amp;#010; org.apache.spark.sql.kafka010.KafkaSourceTest.failAfterImpl(KafkaMicroBatchSourceSuite.scala:52)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfter(</li></div><div><li>&amp;#010;Timed out waiting for stream: The code passed to failAfter did not complete within 30 seconds.&amp;#010;java.lang.Thread.getStackTrace(Thread.java:1559)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfterImpl(TimeLimits.scala:234)&amp;#010; org.apache.spark.sql.kafka010.KafkaSourceTest.failAfterImpl(KafkaMicroBatchSourceSuite.scala:52)&amp;#010; org.scalatest.concurrent.TimeLimits$class.failAfter(</li></div><div><li>9131 did not equal 9130 Round trip of 9130 did not work in tz sun.util.calendar.ZoneInfo[id="Pacific/Enderbury",offset=46800000,dstSavings=0,useDaylight=false,transitions=5,lastRule=null]</li></div><div><li>assertion failed: expected full outer join to not spill, but did</li></div><div><li>null equaled null</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>9131 did not equal 9130 Round trip of 9130 did not work in tz sun.util.calendar.ZoneInfo[id="Pacific/Enderbury",offset=46800000,dstSavings=0,useDaylight=false,transitions=5,lastRule=null]</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.network.RpcIntegrationSuite.sendRpcWithStreamFailures</div></li><li><div>org.apache.spark.JavaJdbcRDDSuite.testJavaJdbcRDD</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToGrow</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.setAndRetrieveAKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.multipleValuesForSameKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.testPeakMemoryUsed</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedTestWithRecordsLargerThanPageSize</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.spillInIterator</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.destructiveIteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratingOverDataPagesWithWastedSpace</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedStressTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.emptyMap</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToGrow</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.setAndRetrieveAKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.multipleValuesForSameKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.testPeakMemoryUsed</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedTestWithRecordsLargerThanPageSize</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.spillInIterator</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.destructiveIteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratingOverDataPagesWithWastedSpace</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedStressTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.emptyMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.flatMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.flatMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreach</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreach</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.map</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.map</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zip</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zip</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.keyBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.keyBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.groupBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.groupBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</div></li><li><div>test.org.apache.spark.JavaAPISuite.sparkContextUnion</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</div></li><li><div>test.org.apache.spark.JavaAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.JavaAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.getNumPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.getNumPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.wholeTextFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.wholeTextFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.lookup</div></li><li><div>test.org.apache.spark.JavaAPISuite.lookup</div></li><li><div>test.org.apache.spark.JavaAPISuite.countAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryRecords</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryRecords</div></li><li><div>test.org.apache.spark.JavaAPISuite.toLocalIterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.toLocalIterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.sample</div></li><li><div>test.org.apache.spark.JavaAPISuite.sample</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.JavaAPISuite.flatMap</div></li><li><div>test.org.apache.spark.JavaAPISuite.flatMap</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup3</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup3</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup4</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup4</div></li><li><div>test.org.apache.spark.JavaAPISuite.randomSplit</div></li><li><div>test.org.apache.spark.JavaAPISuite.randomSplit</div></li><li><div>test.org.apache.spark.JavaAPISuite.persist</div></li><li><div>test.org.apache.spark.JavaAPISuite.persist</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreach</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreach</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.accumulators</div></li><li><div>test.org.apache.spark.JavaAPISuite.accumulators</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFilesCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFilesCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregateByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregateByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.map</div></li><li><div>test.org.apache.spark.JavaAPISuite.map</div></li><li><div>test.org.apache.spark.JavaAPISuite.max</div></li><li><div>test.org.apache.spark.JavaAPISuite.max</div></li><li><div>test.org.apache.spark.JavaAPISuite.min</div></li><li><div>test.org.apache.spark.JavaAPISuite.min</div></li><li><div>test.org.apache.spark.JavaAPISuite.top</div></li><li><div>test.org.apache.spark.JavaAPISuite.top</div></li><li><div>test.org.apache.spark.JavaAPISuite.zip</div></li><li><div>test.org.apache.spark.JavaAPISuite.zip</div></li><li><div>test.org.apache.spark.JavaAPISuite.fold</div></li><li><div>test.org.apache.spark.JavaAPISuite.glom</div></li><li><div>test.org.apache.spark.JavaAPISuite.take</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.intersection</div></li><li><div>test.org.apache.spark.JavaAPISuite.intersection</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.cartesian</div></li><li><div>test.org.apache.spark.JavaAPISuite.cartesian</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</div></li><li><div>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeOrdered</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeOrdered</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeAggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeAggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</div></li><li><div>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</div></li><li><div>test.org.apache.spark.JavaAPISuite.approximateResults</div></li><li><div>test.org.apache.spark.JavaAPISuite.approximateResults</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinct</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinct</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMax</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMax</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMin</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMin</div></li><li><div>test.org.apache.spark.JavaAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.iterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.iterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.emptyRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.emptyRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachPartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachPartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.combineByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.combineByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.isEmpty</div></li><li><div>test.org.apache.spark.JavaAPISuite.isEmpty</div></li><li><div>test.org.apache.spark.JavaSparkContextSuite.javaSparkContext</div></li><li><div>test.org.apache.spark.JavaSparkContextSuite.scalaSparkContext</div></li><li><div>org.apache.spark.sql.kafka010.KafkaDataConsumerSuite.SPARK-23623: concurrent use of KafkaDataConsumer</div></li><li><div>org.apache.spark.streaming.kafka010.JavaDirectKafkaStreamSuite.testKafkaStream</div></li><li><div>org.apache.spark.streaming.kafka010.JavaKafkaRDDSuite.testKafkaRDD</div></li><li><div>org.apache.spark.graphx.EdgeRDDSuite.checkpointing</div></li><li><div>org.apache.spark.graphx.GraphLoaderSuite.GraphLoader.edgeListFile</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.joinVertices</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectNeighborIds</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.removeSelfEdges</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.filter</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.convertToCanonicalEdges</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionOut</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionIn</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionEither</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionOut</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionIn</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionEither</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.fromEdgeTuples</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.fromEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.apply</div></li><li><div>org.apache.spark.graphx.GraphSuite.triplets</div></li><li><div>org.apache.spark.graphx.GraphSuite.partitionBy</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapVertices</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapVertices changing type with same erased type</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapTriplets</div></li><li><div>org.apache.spark.graphx.GraphSuite.reverse</div></li><li><div>org.apache.spark.graphx.GraphSuite.reverse with join elimination</div></li><li><div>org.apache.spark.graphx.GraphSuite.subgraph</div></li><li><div>org.apache.spark.graphx.GraphSuite.mask</div></li><li><div>org.apache.spark.graphx.GraphSuite.groupEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.aggregateMessages</div></li><li><div>org.apache.spark.graphx.GraphSuite.outerJoinVertices</div></li><li><div>org.apache.spark.graphx.GraphSuite.more edge partitions than vertex partitions</div></li><li><div>org.apache.spark.graphx.GraphSuite.checkpoint</div></li><li><div>org.apache.spark.graphx.GraphSuite.cache, getStorageLevel</div></li><li><div>org.apache.spark.graphx.GraphSuite.non-default number of edge partitions</div></li><li><div>org.apache.spark.graphx.GraphSuite.unpersist graph RDD</div></li><li><div>org.apache.spark.graphx.GraphSuite.SPARK-14219: pickRandomVertex</div></li><li><div>org.apache.spark.graphx.PregelSuite.1 iteration</div></li><li><div>org.apache.spark.graphx.PregelSuite.chain propagation</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.filter</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.mapValues</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus with RDD[(VertexId, VD)]</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff with RDD[(VertexId, VD)]</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff vertices with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.leftJoin</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.leftJoin vertices with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.innerJoin</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.innerJoin vertices with the non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.aggregateUsingIndex</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.mergeFunc</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.cache, getStorageLevel</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.checkpoint</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Grid Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Grid Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Chain Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Chain Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Connected Components on a Toy Connected Graph</div></li><li><div>org.apache.spark.graphx.lib.LabelPropagationSuite.Label Propagation</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Star PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Star PersonalPageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Grid PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Chain PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Chain PersonalizedPageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Loop with source PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Loop with sink PageRank</div></li><li><div>org.apache.spark.graphx.lib.SVDPlusPlusSuite.Test SVD++ with mean square error on training set</div></li><li><div>org.apache.spark.graphx.lib.ShortestPathsSuite.Shortest Path Computations</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Island Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Cycle Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.2 Cycle Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles with bi-directed edges</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle with duplicate edges</div></li><li><div>org.apache.spark.graphx.util.GraphGeneratorsSuite.GraphGenerators.logNormalGraph</div></li><li><div>org.apache.spark.graphx.util.GraphGeneratorsSuite.SPARK-5064 GraphGenerators.rmatGraph numEdges upper bound</div></li><li><div>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Persisting</div></li><li><div>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Checkpointing</div></li><li><div>org.apache.spark.ml.JavaPipelineSuite.pipeline</div></li><li><div>org.apache.spark.ml.JavaPipelineSuite.pipeline</div></li><li><div>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</div></li><li><div>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</div></li><li><div>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</div></li><li><div>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</div></li><li><div>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</div></li><li><div>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</div></li><li><div>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</div></li><li><div>org.apache.spark.ml.feature.JavaPCASuite.testPCA</div></li><li><div>org.apache.spark.ml.feature.JavaPCASuite.testPCA</div></li><li><div>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</div></li><li><div>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</div></li><li><div>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</div></li><li><div>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</div></li><li><div>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</div></li><li><div>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</div></li><li><div>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</div></li><li><div>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</div></li><li><div>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</div></li><li><div>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</div></li><li><div>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</div></li><li><div>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</div></li><li><div>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</div></li><li><div>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</div></li><li><div>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</div></li><li><div>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</div></li><li><div>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</div></li><li><div>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</div></li><li><div>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</div></li><li><div>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</div></li><li><div>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</div></li><li><div>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</div></li><li><div>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</div></li><li><div>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</div></li><li><div>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</div></li><li><div>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</div></li><li><div>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</div></li><li><div>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</div></li><li><div>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</div></li><li><div>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</div></li><li><div>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</div></li><li><div>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</div></li><li><div>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</div></li><li><div>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</div></li><li><div>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</div></li><li><div>org.apache.spark.repl.ReplSuite.SPARK-15236: use Hive catalog</div></li><li><div>org.apache.spark.repl.ReplSuite.SPARK-15236: use in-memory catalog</div></li><li><div>org.apache.spark.repl.ReplSuite.broadcast vars</div></li><li><div>org.apache.spark.repl.ReplSuite.line wrapper only initialized once when used as encoder outer scope</div></li><li><div>org.apache.spark.repl.ReplSuite.define case class and create Dataset together with paste mode</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.simple foreach with accumulator</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external classes</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external functions</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external functions that access vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.broadcast vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.interacting with files</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.local-cluster mode</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.SPARK-2576 importing implicits</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.Datasets and encoders</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.SPARK-2632 importing a method from non serializable class and not using it.</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl - shuffling</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.replicating blocks of object with class defined in repl</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.newProductSeqEncoder with REPL defined class</div></li><li><div>org.apache.spark.sql.catalyst.expressions.HiveHasherSuite.testKnownStringAndIntInputs</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setAndRetrieve</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.randomizedTest</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.iteratorTest</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setUpdateAndRetrieve</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingCapacity</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingPageSize</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testFormatAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testJsonAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testLoadAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testOptionsAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testSaveModeAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testCsvAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testParquetAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextFileAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTake</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTake</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.test</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</div></li><li><div>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</div></li><li><div>test.org.apache.spark.sql.execution.sort.RecordBinaryComparatorSuite.testBinaryComparatorForMixedColumns</div></li><li><div>org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite.lazily initialize Hive client</div></li><li><div>org.apache.spark.sql.hive.JavaDataFrameSuite.testUDAF</div></li><li><div>org.apache.spark.sql.hive.JavaDataFrameSuite.saveTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableWithSchemaAndQueryIt</div></li><li><div>org.apache.spark.streaming.JavaMapWithStateSuite.testBasicFunction</div></li><li><div>org.apache.spark.streaming.JavaReceiverAPISuite.testReceiver</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCount</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCount</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUnion</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUnion</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGlom</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGlom</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRawSocketStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRawSocketStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextState</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextState</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.streaming.StreamingQueryListenerSuite.single listener, check trigger events are generated correctly</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.streaming.continuous.ContinuousStressSuite.only one epoch</div></li><li><div>org.apache.spark.sql.hive.HiveSparkSubmitSuite.SPARK-8020: set sql conf in spark conf</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.network.RpcIntegrationSuite.sendRpcWithStreamFailures</div></li><li><div>org.apache.spark.JavaJdbcRDDSuite.testJavaJdbcRDD</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToGrow</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.setAndRetrieveAKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.multipleValuesForSameKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.testPeakMemoryUsed</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedTestWithRecordsLargerThanPageSize</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.spillInIterator</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.destructiveIteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratingOverDataPagesWithWastedSpace</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.randomizedStressTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.iteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite.emptyMap</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToGrow</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.setAndRetrieveAKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.multipleValuesForSameKey</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.testPeakMemoryUsed</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedTestWithRecordsLargerThanPageSize</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.spillInIterator</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.destructiveIteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratingOverDataPagesWithWastedSpace</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.randomizedStressTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.iteratorTest</div></li><li><div>org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite.emptyMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.flatMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.flatMap</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreach</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreach</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.map</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.map</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zip</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zip</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.keyBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.keyBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.groupBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.groupBy</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.foreachWithAnonymousClass</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.Java8RDDAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFilesCaching</div></li><li><div>test.org.apache.spark.JavaAPISuite.sparkContextUnion</div></li><li><div>test.org.apache.spark.JavaAPISuite.sparkContextUnion</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndComputation</div></li><li><div>test.org.apache.spark.JavaAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.JavaAPISuite.leftOuterJoin</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyByOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.getNumPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.getNumPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.wholeTextFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.wholeTextFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.writeWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.lookup</div></li><li><div>test.org.apache.spark.JavaAPISuite.lookup</div></li><li><div>test.org.apache.spark.JavaAPISuite.countAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.countAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFiles</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryRecords</div></li><li><div>test.org.apache.spark.JavaAPISuite.binaryRecords</div></li><li><div>test.org.apache.spark.JavaAPISuite.toLocalIterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.toLocalIterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartitionAndSortWithinPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.sample</div></li><li><div>test.org.apache.spark.JavaAPISuite.sample</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapsFromPairsToPairs</div></li><li><div>test.org.apache.spark.JavaAPISuite.flatMap</div></li><li><div>test.org.apache.spark.JavaAPISuite.flatMap</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup3</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup3</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup4</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup4</div></li><li><div>test.org.apache.spark.JavaAPISuite.randomSplit</div></li><li><div>test.org.apache.spark.JavaAPISuite.persist</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreach</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreach</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.hadoopFileCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.accumulators</div></li><li><div>test.org.apache.spark.JavaAPISuite.accumulators</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFilesCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.textFilesCompressed</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionCancellation</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</div></li><li><div>test.org.apache.spark.JavaAPISuite.checkpointAndRestore</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.sortByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregateByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregateByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.map</div></li><li><div>test.org.apache.spark.JavaAPISuite.map</div></li><li><div>test.org.apache.spark.JavaAPISuite.max</div></li><li><div>test.org.apache.spark.JavaAPISuite.max</div></li><li><div>test.org.apache.spark.JavaAPISuite.min</div></li><li><div>test.org.apache.spark.JavaAPISuite.min</div></li><li><div>test.org.apache.spark.JavaAPISuite.top</div></li><li><div>test.org.apache.spark.JavaAPISuite.top</div></li><li><div>test.org.apache.spark.JavaAPISuite.zip</div></li><li><div>test.org.apache.spark.JavaAPISuite.zip</div></li><li><div>test.org.apache.spark.JavaAPISuite.fold</div></li><li><div>test.org.apache.spark.JavaAPISuite.fold</div></li><li><div>test.org.apache.spark.JavaAPISuite.glom</div></li><li><div>test.org.apache.spark.JavaAPISuite.glom</div></li><li><div>test.org.apache.spark.JavaAPISuite.take</div></li><li><div>test.org.apache.spark.JavaAPISuite.take</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDDHistoGram</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectUnderlyingScalaRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.keyBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitionsWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.intersection</div></li><li><div>test.org.apache.spark.JavaAPISuite.intersection</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.aggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.cartesian</div></li><li><div>test.org.apache.spark.JavaAPISuite.cartesian</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinctByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.readWithNewAPIHadoopFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</div></li><li><div>test.org.apache.spark.JavaAPISuite.testRegisterKryoClasses</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.groupBy</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</div></li><li><div>test.org.apache.spark.JavaAPISuite.sampleByKeyExact</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeOrdered</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeOrdered</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.foldByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfInts</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeAggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeAggregate</div></li><li><div>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</div></li><li><div>test.org.apache.spark.JavaAPISuite.testGetPersistentRDDs</div></li><li><div>test.org.apache.spark.JavaAPISuite.approximateResults</div></li><li><div>test.org.apache.spark.JavaAPISuite.approximateResults</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.treeReduce</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapAndSerialize</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinct</div></li><li><div>test.org.apache.spark.JavaAPISuite.countApproxDistinct</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.javaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.mapOnPairRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.testAsyncActionErrorWrapping</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMax</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMax</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMin</div></li><li><div>test.org.apache.spark.JavaAPISuite.naturalMin</div></li><li><div>test.org.apache.spark.JavaAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.sequenceFile</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup</div></li><li><div>test.org.apache.spark.JavaAPISuite.cogroup</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.repartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.iterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.iterator</div></li><li><div>test.org.apache.spark.JavaAPISuite.emptyRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.emptyRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithIndex</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachPartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachPartition</div></li><li><div>test.org.apache.spark.JavaAPISuite.combineByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.combineByKey</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.takeAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsMapWithIntArrayValues</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</div></li><li><div>test.org.apache.spark.JavaAPISuite.objectFilesOfComplexTypes</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipWithUniqueId</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.collectAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.foreachAsync</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.zipPartitions</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.reduceOnJavaDoubleRDD</div></li><li><div>test.org.apache.spark.JavaAPISuite.isEmpty</div></li><li><div>test.org.apache.spark.JavaAPISuite.isEmpty</div></li><li><div>test.org.apache.spark.JavaSparkContextSuite.javaSparkContext</div></li><li><div>test.org.apache.spark.JavaSparkContextSuite.scalaSparkContext</div></li><li><div>org.apache.spark.streaming.kafka010.JavaDirectKafkaStreamSuite.testKafkaStream</div></li><li><div>org.apache.spark.streaming.kafka010.JavaKafkaRDDSuite.testKafkaRDD</div></li><li><div>org.apache.spark.graphx.EdgeRDDSuite.cache, getStorageLevel</div></li><li><div>org.apache.spark.graphx.EdgeRDDSuite.checkpointing</div></li><li><div>org.apache.spark.graphx.GraphLoaderSuite.GraphLoader.edgeListFile</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.joinVertices</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectNeighborIds</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.removeSelfEdges</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.filter</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.convertToCanonicalEdges</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionOut</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionIn</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesCycleDirectionEither</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionOut</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionIn</div></li><li><div>org.apache.spark.graphx.GraphOpsSuite.collectEdgesChainDirectionEither</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.fromEdgeTuples</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.fromEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.Graph.apply</div></li><li><div>org.apache.spark.graphx.GraphSuite.triplets</div></li><li><div>org.apache.spark.graphx.GraphSuite.partitionBy</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapVertices</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapVertices changing type with same erased type</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.mapTriplets</div></li><li><div>org.apache.spark.graphx.GraphSuite.reverse</div></li><li><div>org.apache.spark.graphx.GraphSuite.reverse with join elimination</div></li><li><div>org.apache.spark.graphx.GraphSuite.subgraph</div></li><li><div>org.apache.spark.graphx.GraphSuite.mask</div></li><li><div>org.apache.spark.graphx.GraphSuite.groupEdges</div></li><li><div>org.apache.spark.graphx.GraphSuite.aggregateMessages</div></li><li><div>org.apache.spark.graphx.GraphSuite.outerJoinVertices</div></li><li><div>org.apache.spark.graphx.GraphSuite.more edge partitions than vertex partitions</div></li><li><div>org.apache.spark.graphx.GraphSuite.checkpoint</div></li><li><div>org.apache.spark.graphx.GraphSuite.cache, getStorageLevel</div></li><li><div>org.apache.spark.graphx.GraphSuite.non-default number of edge partitions</div></li><li><div>org.apache.spark.graphx.GraphSuite.unpersist graph RDD</div></li><li><div>org.apache.spark.graphx.GraphSuite.SPARK-14219: pickRandomVertex</div></li><li><div>org.apache.spark.graphx.PregelSuite.1 iteration</div></li><li><div>org.apache.spark.graphx.PregelSuite.chain propagation</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.filter</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.mapValues</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus with RDD[(VertexId, VD)]</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.minus with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff with RDD[(VertexId, VD)]</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.diff vertices with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.leftJoin</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.leftJoin vertices with non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.innerJoin</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.innerJoin vertices with the non-equal number of partitions</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.aggregateUsingIndex</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.mergeFunc</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.cache, getStorageLevel</div></li><li><div>org.apache.spark.graphx.VertexRDDSuite.checkpoint</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Grid Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Grid Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Chain Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Reverse Chain Connected Components</div></li><li><div>org.apache.spark.graphx.lib.ConnectedComponentsSuite.Connected Components on a Toy Connected Graph</div></li><li><div>org.apache.spark.graphx.lib.LabelPropagationSuite.Label Propagation</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Star PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Star PersonalPageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Grid PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Chain PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Chain PersonalizedPageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Loop with source PageRank</div></li><li><div>org.apache.spark.graphx.lib.PageRankSuite.Loop with sink PageRank</div></li><li><div>org.apache.spark.graphx.lib.SVDPlusPlusSuite.Test SVD++ with mean square error on training set</div></li><li><div>org.apache.spark.graphx.lib.ShortestPathsSuite.Shortest Path Computations</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Island Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.Cycle Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.StronglyConnectedComponentsSuite.2 Cycle Strongly Connected Components</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count two triangles with bi-directed edges</div></li><li><div>org.apache.spark.graphx.lib.TriangleCountSuite.Count a single triangle with duplicate edges</div></li><li><div>org.apache.spark.graphx.util.GraphGeneratorsSuite.GraphGenerators.logNormalGraph</div></li><li><div>org.apache.spark.graphx.util.GraphGeneratorsSuite.SPARK-5064 GraphGenerators.rmatGraph numEdges upper bound</div></li><li><div>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Persisting</div></li><li><div>org.apache.spark.graphx.util.PeriodicGraphCheckpointerSuite.Checkpointing</div></li><li><div>org.apache.spark.ml.JavaPipelineSuite.pipeline</div></li><li><div>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaGBTClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionWithSetters</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionTrainingSummary</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionPredictorClassifierMethods</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaLogisticRegressionSuite.logisticRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</div></li><li><div>org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite.testMLPC</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.testNaiveBayes</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaNaiveBayesSuite.naiveBayesDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaOneVsRestSuite.oneVsRestDefaultParams</div></li><li><div>org.apache.spark.ml.classification.JavaRandomForestClassifierSuite.runDT</div></li><li><div>org.apache.spark.ml.clustering.JavaKMeansSuite.fitAndTransform</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</div></li><li><div>org.apache.spark.ml.feature.JavaBucketizerSuite.bucketizerMultipleColumnsTest</div></li><li><div>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaDCTSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</div></li><li><div>org.apache.spark.ml.feature.JavaHashingTFSuite.hashingTF</div></li><li><div>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</div></li><li><div>org.apache.spark.ml.feature.JavaNormalizerSuite.normalizer</div></li><li><div>org.apache.spark.ml.feature.JavaPCASuite.testPCA</div></li><li><div>org.apache.spark.ml.feature.JavaPCASuite.testPCA</div></li><li><div>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</div></li><li><div>org.apache.spark.ml.feature.JavaPolynomialExpansionSuite.polynomialExpansionTest</div></li><li><div>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</div></li><li><div>org.apache.spark.ml.feature.JavaStandardScalerSuite.standardScaler</div></li><li><div>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaStopWordsRemoverSuite.javaCompatibilityTest</div></li><li><div>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</div></li><li><div>org.apache.spark.ml.feature.JavaStringIndexerSuite.testStringIndexer</div></li><li><div>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</div></li><li><div>org.apache.spark.ml.feature.JavaTokenizerSuite.regexTokenizer</div></li><li><div>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</div></li><li><div>org.apache.spark.ml.feature.JavaVectorAssemblerSuite.testVectorAssembler</div></li><li><div>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</div></li><li><div>org.apache.spark.ml.feature.JavaVectorIndexerSuite.vectorIndexerAPI</div></li><li><div>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</div></li><li><div>org.apache.spark.ml.feature.JavaVectorSlicerSuite.vectorSlice</div></li><li><div>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</div></li><li><div>org.apache.spark.ml.feature.JavaWord2VecSuite.testJavaWord2Vec</div></li><li><div>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaGBTRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionDefaultParams</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</div></li><li><div>org.apache.spark.ml.regression.JavaLinearRegressionSuite.linearRegressionWithSetters</div></li><li><div>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.regression.JavaRandomForestRegressorSuite.runDT</div></li><li><div>org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite.verifyLibSVMDF</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestNamedDistribution</div></li><li><div>org.apache.spark.ml.stat.JavaKolmogorovSmirnovTestSuite.testKSTestCDF</div></li><li><div>org.apache.spark.ml.stat.JavaSummarizerSuite.testSummarizer</div></li><li><div>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</div></li><li><div>org.apache.spark.ml.tuning.JavaCrossValidatorSuite.crossValidationWithLogisticRegression</div></li><li><div>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</div></li><li><div>org.apache.spark.ml.util.JavaDefaultReadWriteSuite.testDefaultReadWrite</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaLogisticRegressionSuite.runLRUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.runUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</div></li><li><div>org.apache.spark.mllib.classification.JavaNaiveBayesSuite.testModelTypeSetters</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingConstructor</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaSVMSuite.runSVMUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.classification.JavaStreamingLogisticRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</div></li><li><div>org.apache.spark.mllib.clustering.JavaBisectingKMeansSuite.twoDimensionalData</div></li><li><div>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</div></li><li><div>org.apache.spark.mllib.clustering.JavaGaussianMixtureSuite.runGaussianMixture</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingConstructor</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaKMeansSuite.runKMeansUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.onlineOptimizerCompatibility</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.distributedLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLDAModel</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaLDASuite.localLdaMethods</div></li><li><div>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.clustering.JavaStreamingKMeansSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</div></li><li><div>org.apache.spark.mllib.evaluation.JavaRankingMetricsSuite.rankingMetrics</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdfMinimumDocumentFrequency</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</div></li><li><div>org.apache.spark.mllib.feature.JavaTfIdfSuite.tfIdf</div></li><li><div>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</div></li><li><div>org.apache.spark.mllib.feature.JavaWord2VecSuite.word2Vec</div></li><li><div>org.apache.spark.mllib.fpm.JavaAssociationRulesSuite.runAssociationRules</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowthSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</div></li><li><div>org.apache.spark.mllib.fpm.JavaFPGrowthSuite.runFPGrowth</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpan</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</div></li><li><div>org.apache.spark.mllib.fpm.JavaPrefixSpanSuite.runPrefixSpanSaveLoad</div></li><li><div>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</div></li><li><div>org.apache.spark.mllib.linalg.distributed.JavaRowMatrixSuite.rowMatrixQRDecomposition</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testArbitrary</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLogNormalVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testRandomVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testUniformVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testPoissonVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testGammaVectorRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testExponentialRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</div></li><li><div>org.apache.spark.mllib.random.JavaRandomRDDsSuite.testLNormalRDD</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runRecommend</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSWithNegativeWeight</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runImplicitALSUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.recommendation.JavaALSSuite.runALSUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite.testIsotonicRegressionPredictionsJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLassoSuite.runLassoUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.testPredictJavaRDD</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaLinearRegressionSuite.runLinearRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingConstructor</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaRidgeRegressionSuite.runRidgeRegressionUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.regression.JavaStreamingLinearRegressionSuite.javaAPI</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.testCorr</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.chiSqTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.streamingTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</div></li><li><div>org.apache.spark.mllib.stat.JavaStatisticsSuite.kolmogorovSmirnovTest</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingStaticMethods</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</div></li><li><div>org.apache.spark.mllib.tree.JavaDecisionTreeSuite.runDTUsingConstructor</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertMatrixColumnsToAndFromML</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</div></li><li><div>org.apache.spark.mllib.util.JavaMLUtilsSuite.testConvertVectorColumnsToAndFromML</div></li><li><div>org.apache.spark.repl.ReplSuite.SPARK-15236: use Hive catalog</div></li><li><div>org.apache.spark.repl.ReplSuite.SPARK-15236: use in-memory catalog</div></li><li><div>org.apache.spark.repl.ReplSuite.broadcast vars</div></li><li><div>org.apache.spark.repl.ReplSuite.line wrapper only initialized once when used as encoder outer scope</div></li><li><div>org.apache.spark.repl.ReplSuite.define case class and create Dataset together with paste mode</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.simple foreach with accumulator</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external classes</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external functions</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.external functions that access vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.broadcast vars</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.interacting with files</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.local-cluster mode</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.SPARK-2576 importing implicits</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.Datasets and encoders</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.SPARK-2632 importing a method from non serializable class and not using it.</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.collecting objects of class defined in repl - shuffling</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.replicating blocks of object with class defined in repl</div></li><li><div>org.apache.spark.repl.SingletonReplSuite.newProductSeqEncoder with REPL defined class</div></li><li><div>org.apache.spark.sql.catalyst.expressions.HiveHasherSuite.testKnownStringAndIntInputs</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.failureToAllocateFirstPage</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setAndRetrieve</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.randomizedTest</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.iteratorTest</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.setUpdateAndRetrieve</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingCapacity</div></li><li><div>org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite.appendRowUntilExceedingPageSize</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.Java8DatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchema</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.dataFrameRDDOperations</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</div></li><li><div>test.org.apache.spark.sql.JavaApplySchemaSuite.applySchemaToJSON</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testFormatAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testJsonAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testLoadAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testOptionsAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testSaveModeAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testCsvAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testParquetAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite.testTextFileAPI</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCollectAndTake</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testJsonRDDToDataFrame</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testVarargMethods</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBeanWithoutGetter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateStructTypeFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testSampleBy</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCrosstab</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testUDF</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFromFromList</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCircularReferenceBean</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testFrequentItems</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testExecution</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testTextLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.pivot</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testGenericLoad</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCountMinSketch</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCorrelation</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testBloomFilter</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCovariance</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDataFrameSuite.testCreateDataFrameFromLocalJavaBeans</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationCount</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumDouble</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationSumLong</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAnonClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaDatasetAggregatorSuite.testTypedAggregationAverage</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRuntimeNullabilityCheck</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean1</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCircularReferenceBean3</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSerializeNull</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testRandomSplit</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTypedFilterPreservingSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJoin</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTake</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTake</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testToLocalIterator</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSpecificLists</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testForeach</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testPrimitiveEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testEmptyBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCommonOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNullInTopLevelBean</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testGroupBy</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSetOperation</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testBeanWithEnum</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.test</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.test</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder2</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testCollect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testKryoEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaBeanEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testNestedTupleEncoder</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testTupleEncoderSchema</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testReduce</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testSelect</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaDatasetSuite.testJavaEncoderErrorMessageForPrivateClass</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoadWithSchema</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</div></li><li><div>test.org.apache.spark.sql.JavaSaveLoadSuite.saveAndLoad</div></li><li><div>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDAFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf1Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf2Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf3Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf4Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf5Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</div></li><li><div>test.org.apache.spark.sql.JavaUDFSuite.udf6Test</div></li><li><div>test.org.apache.spark.sql.execution.sort.RecordBinaryComparatorSuite.testBinaryComparatorForMixedColumns</div></li><li><div>org.apache.spark.sql.hive.HiveMetastoreLazyInitializationSuite.lazily initialize Hive client</div></li><li><div>org.apache.spark.sql.hive.JavaDataFrameSuite.testUDAF</div></li><li><div>org.apache.spark.sql.hive.JavaDataFrameSuite.saveTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveTableAndQueryIt</div></li><li><div>org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite.saveExternalTableWithSchemaAndQueryIt</div></li><li><div>org.apache.spark.streaming.JavaMapWithStateSuite.testBasicFunction</div></li><li><div>org.apache.spark.streaming.JavaReceiverAPISuite.testReceiver</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.Java8APISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testStreamingContextTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionFewerPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCombineByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextGetOrCreate</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindowWithSlideDuration</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testQueueStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValue</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToNormalRDDTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairReduceByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCount</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCount</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCheckpointMasterRecovery</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUnion</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUnion</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindowWithInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGlom</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGlom</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairFlatMap</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairToPairFlatMapWithChangingTypes</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMapPartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testRepartitionMorePartitions</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByWindowWithoutInverse</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testLeftOuterJoin</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testVariousTransformWith</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTextFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairGroupByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCoGroup</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testInitialization</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketString</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testGroupByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduceByKeyAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testForeachRDD</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFileStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testFilter</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testPairMap2</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testMapValues</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testReduce</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKey</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testTransform</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testCountByValueAndWindow</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testSocketTextStream</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testUpdateStateByKeyWithInitial</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextState</div></li><li><div>test.org.apache.spark.streaming.JavaAPISuite.testContextState</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.assign from earliest offsets (failOnDataLoss: false)</div></li><li><div>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.subscribing topic by name from latest offsets (failOnDataLoss: false)</div></li><li><div>org.apache.spark.sql.kafka010.KafkaContinuousSourceSuite.subscribing topic by pattern from earliest offsets (failOnDataLoss: false)</div></li><li><div>org.apache.spark.sql.kafka010.KafkaContinuousSourceTopicDeletionSuite.subscribing topic by pattern with topic deletions</div></li><li><div>org.apache.spark.sql.JoinSuite.test SortMergeJoin (with spill)</div></li><li><div>org.apache.spark.sql.streaming.StreamingQueryListenersConfSuite.test if the configured query lister is loaded</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="sqoop"><div style="font-weight:bold;" class="panel-heading">SQOOP<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Yussuf)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/trunk</div><div><b>Last Revision: </b>b790c606afd17067f563a107cde9faa733b242b6</div><div><b>Last Run: </b>29-06-2018 01:55 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td><td><div>Total Count : 816</div><div>Failed Count : 0</div><div>Skipped Count : 3</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="storm"><div style="font-weight:bold;" class="panel-heading">STORM<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>26d2f955251c0fa56520f6fe08cb35ef5171f321</div><div><b>Last Run: </b>05-07-2018 01:18 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1222</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 0</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td><td><div>Total Count : 1222</div><div>Failed Count : 1</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.storm.kafka.KafkaUtilsTest.fetchMessage</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.storm.utils.JCQueueTest.testFirstMessageFirst</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.storm.utils.JCQueueTest.testFirstMessageFirst</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 1000 ms.</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to send halt interrupt</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>Unable to send halt interrupt</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.storm.kafka.KafkaUtilsTest.fetchMessage</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="tez"><div style="font-weight:bold;" class="panel-heading">TEZ<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Valencia)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>06757e9d03c613ef5fd1dfcb1d86615ba2222818</div><div><b>Last Run: </b>05-07-2018 03:53 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1829</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 7</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 1</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 2</div><div>Skipped Count : 14</div></td><td><div>Total Count : 1829</div><div>Failed Count : 3</div><div>Skipped Count : 14</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.rm.TestTaskScheduler.testTaskSchedulerDetermineMinHeldContainers</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, ENABLED]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, NONE]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, MEMORY_OPTIMIZED]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, PRECISE]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[true, NONE]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[true, PRECISE]]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.app.TestSpeculation.testBasicSpeculationPerVertexConf</li></div><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.tests.TestExtServicesWithLocalMode.test1</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargevaluesWithoutFinalMerge[test[true, NONE]]</li></div><div><li>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testTextMixedRecords[test[true, PRECISE]]</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>
AppFinalStatus cannot be returned by getAMState()
getAMState() should return AMState
***
If you're unsure why you're getting above error read on.
Due to the nature of the syntax above problem might occur because:
1. This exception *might* occur in wrongly written multi-threaded tests.
   Please refer to Mockito FAQ on limitations of concurrency testing.
2. A spy is stubbed using when(spy.foo()).t</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;KILLED&gt; but was:&lt;FAILED&gt;</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>test timed out after 10000 milliseconds</li></div><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.tez.dag.api.TezUncheckedException: java.lang.reflect.InvocationTargetException</li></div><div><li>test timed out after 10000 milliseconds</li></div><div><li>test timed out after 10000 milliseconds</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.rm.TestTaskScheduler.testTaskSchedulerDetermineMinHeldContainers</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestMockDAGAppMaster.testInternalPreemption</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, ENABLED]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, NONE]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, MEMORY_OPTIMIZED]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[false, PRECISE]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[true, NONE]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargeKvPairs_WithPipelinedShuffle[test[true, PRECISE]]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.dag.app.TestSpeculation.testBasicSpeculationPerVertexConf</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testLargevaluesWithoutFinalMerge[test[true, NONE]]</div></li><li><div>org.apache.tez.runtime.library.common.writers.TestUnorderedPartitionedKVWriter.testTextMixedRecords[test[true, PRECISE]]</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zeppelin"><div style="font-weight:bold;" class="panel-heading">ZEPPELIN<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Alisha)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>93a9aefc9d7cfcfd01a7b308d27695460ec847f4</div><div><b>Last Run: </b>04-07-2018 06:35 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 839</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td><td><div>Total Count : 839</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td><td><div>Total Count : 839</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td><td><div>Total Count : 839</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td><td><div>Total Count : 828</div><div>Failed Count : 7</div><div>Skipped Count : 5</div></td><td><div>Total Count : 839</div><div>Failed Count : 6</div><div>Skipped Count : 5</div></td><td><div>Total Count : 829</div><div>Failed Count : 35</div><div>Skipped Count : 5</div></td><td><div>Total Count : 829</div><div>Failed Count : 13</div><div>Skipped Count : 5</div></td></tr><tr><td>Result</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.org.apache.zeppelin.interpreter.SparkIntegrationTest</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonAdvancedFeatures</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testGrpcFrameSize</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testCodeCompletion</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testRedefinitionZeppelinContext</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testPythonBasics</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonAdvancedFeatures</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testGrpcFrameSize</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testCodeCompletion</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testPythonBasics</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[0]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[1]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[2]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[3]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[3]</li></div><div><li>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[3]</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testIncludeJobStats</li></div><div><li>org.apache.zeppelin.pig.PigInterpreterTezTest.testBasics</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testMaxResult</li></div><div><li>org.apache.zeppelin.pig.PigQueryInterpreterTest.testBasics</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.python.IPythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.python.PythonInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonPlotting</li></div><div><li>org.apache.zeppelin.spark.IPySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.spark.PySparkInterpreterTest.testZeppelinContext</li></div><div><li>org.apache.zeppelin.security.SecurityUtilsTest.canGetPrincipalName</li></div></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>Could not fully delete /var/lib/jenkins/workspace/zeppelin/zeppelin-zengine/build/test/data/dfs/name1</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>Fail to open IPythonInterpreter</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>res16: String = 2.2.1
 doesn't contain 2.1.2</li></div><div><li>res18: String = 2.2.1
 doesn't contain 2.1.2</li></div><div><li>res20: String = 2.2.1
 doesn't contain 2.1.2</li></div><div><li>res22: String = 2.2.1
 doesn't contain 2.0.2</li></div><div><li>res24: String = 2.2.1
 doesn't contain 2.0.2</li></div><div><li>res26: String = 2.2.1
 doesn't contain 2.0.2</li></div><div><li>res28: String = 2.2.1
 doesn't contain 1.6.3</li></div><div><li>res30: String = 2.2.1
 doesn't contain 1.6.3</li></div><div><li>res32: String = 2.2.1
 doesn't contain 1.6.3</li></div></ol></td><td><ol style="padding-left: 1.0em"><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>org.apache.hadoop.yarn.api.records.LocalResource.setShouldBeUploadedToSharedCache(Z)V</li></div><div><li>expected:&lt;TABLE&gt; but was:&lt;TEXT&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;SUCCESS&gt; but was:&lt;ERROR&gt;</li></div><div><li>expected:&lt;java.security.[Principal.getN]ame()&gt; but was:&lt;java.security.[principal.getn]ame()&gt;</li></div></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.org.apache.zeppelin.interpreter.SparkIntegrationTest</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testIPythonAdvancedFeatures</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testGrpcFrameSize</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testCodeCompletion</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testRedefinitionZeppelinContext</div></li><li><div>org.apache.zeppelin.python.IPythonInterpreterTest.testPythonBasics</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPySpark</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testIPythonAdvancedFeatures</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testGrpcFrameSize</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testCodeCompletion</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testRedefinitionZeppelinContext</div></li><li><div>org.apache.zeppelin.spark.IPySparkInterpreterTest.testPythonBasics</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[0]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[1]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[2]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClusterMode[3]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testLocalMode[3]</div></li><li><div>org.apache.zeppelin.interpreter.SparkIntegrationTest.testYarnClientMode[3]</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zeppelin.security.SecurityUtilsTest.canGetPrincipalName</div></li></ol></td></tr></tbody></table></div></div><div style="font-weight:bold;display:none;" class="panel panel-info" name="data" id="zookeeper"><div style="font-weight:bold;" class="panel-heading">ZOOKEEPER<p align="right" role="presentation" style="padding-left:5px;color:grey;display:inline;font-weight:normal">(Pravin)</p></div><div class="panel-body"><div class="bs-callout bs-callout-info"><div><b>Branch Details:</b> refs/remotes/origin/master</div><div><b>Last Revision: </b>3465e0ced5edda2e1299662f6b75a1979b6bdc6e</div><div><b>Last Run: </b>29-06-2018 03:51 UTC</div></div><table width="100%" style="font-size:13" class="table table-striped"><thead><tr><th width="10%"></th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr></thead><tbody><tr><td>Summary</td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 3</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1664</div><div>Failed Count : 3</div><div>Skipped Count : 1</div></td><td><div>Total Count : 1675</div><div>Failed Count : 0</div><div>Skipped Count : 1</div></td></tr><tr><td>Result</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;"></img>UNSTABLE</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;"></img>SUCCESS</td></tr><tr><td>Failures</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.RaceConditionTest.testRaceConditionBetweenLeaderAndAckRequestProcessor</li></div><div><li>org.apache.zookeeper.server.quorum.StandaloneDisabledTest.startSingleServerTest</li></div><div><li>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>org.apache.zookeeper.server.quorum.RaceConditionTest.testRaceConditionBetweenLeaderAndAckRequestProcessor</li></div><div><li>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</li></div><div><li>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td>Description</td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Leader failed to transition to new state. Current state is leading</li></div><div><li>test timed out after 600000 milliseconds</li></div><div><li>expected:&lt;NodeDataChanged&gt; but was:&lt;NodeDeleted&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"></ol></td><td><ol style="padding-left: 1.0em"><div><li>Leader failed to transition to new state. Current state is leading</li></div><div><li>Timeout occurred. Please note the time in the report does not reflect the time until the timeout.</li></div><div><li>expected:&lt;NodeDataChanged&gt; but was:&lt;NodeDeleted&gt;</li></div></ol></td><td><ol style="padding-left: 1.0em"></ol></td></tr><tr><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;">Unique Failures</td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.RaceConditionTest.testRaceConditionBetweenLeaderAndAckRequestProcessor</div></li><li><div>org.apache.zookeeper.server.quorum.StandaloneDisabledTest.startSingleServerTest</div></li><li><div>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"><li><div>org.apache.zookeeper.server.quorum.RaceConditionTest.testRaceConditionBetweenLeaderAndAckRequestProcessor</div></li><li><div>org.apache.zookeeper.server.quorum.Zab1_0Test.testNormalObserverRun</div></li><li><div>org.apache.zookeeper.test.WatchEventWhenAutoResetTest.testNodeDataChanged</div></li></ol></td><td style="word-wrap: break-word;min-width: 160px;max-width: 220px;"><ol style="padding-left: 1.0em"></ol></td></tr></tbody></table></div></div><div id="ubuntu16" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU16 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 16.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>23 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>32 (12)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>863 (863)</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td></tr></tbody></table></div><div id="ubuntu18" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">UBUNTU18 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>UBUNTU 18.04</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>20 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>25 (8)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel72" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL72 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.2</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>29 (16)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>24 (11)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>871 (871)</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="rhel75" style="font-weight:bold;font-size:12;display:none" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">RHEL75 SUMMARY</div></div><div class="bs-callout bs-callout-info"><div><b>OS: </b>RHEL 7.5</div></div><table style="font-size:14" class="table table-striped"><tbody><tr><th>Package Name</th><th>PPC</th><th>X86</th><th></th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>48 (31)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>29 (12)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>35 (23)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13 (1)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div><div id="ppcx86" style="display:block;font-weight:bold" class="panel panel-info" name="summary"><div class="panel-heading"><div class="panel-title">FULL SUMMARY</div></div><table style="font-size:14" id="summarytable" class="table table-striped"><tbody><tr><th></th></tr><tr><th>Package Name</th><th>PPC UBUNTU16</th><th>X86 UBUNTU16</th><th>PPC UBUNTU18</th><th>X86 UBUNTU18</th><th>PPC RHEL72</th><th>X86 RHEL72</th><th>PPC RHEL75</th><th>X86 RHEL75</th></tr><tr><td><a href="#" id="anchor_accumulo" onclick="showme(this.id);">ACCUMULO</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ambari" onclick="showme(this.id);">AMBARI</a></td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/red.png" align="top" style="width: 16px; height: 16px;" title="FAILURE"></img>0</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_atlas" onclick="showme(this.id);">ATLAS</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_falcon" onclick="showme(this.id);">FALCON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_flume" onclick="showme(this.id);">FLUME</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_hadoop" onclick="showme(this.id);">HADOOP</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>23 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>32 (12)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>20 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>25 (8)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>29 (16)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>24 (11)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>48 (31)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>29 (12)</td></tr><tr><td><a href="#" id="anchor_hbase" onclick="showme(this.id);">HBASE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2</td></tr><tr><td><a href="#" id="anchor_hive" onclick="showme(this.id);">HIVE</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_kafka" onclick="showme(this.id);">KAFKA</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td></tr><tr><td><a href="#" id="anchor_knox" onclick="showme(this.id);">KNOX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td></tr><tr><td><a href="#" id="anchor_metron" onclick="showme(this.id);">METRON</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_oozie" onclick="showme(this.id);">OOZIE</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td></tr><tr><td><a href="#" id="anchor_phoenix" onclick="showme(this.id);">PHOENIX</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_pig" onclick="showme(this.id);">PIG</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6 (6)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_ranger" onclick="showme(this.id);">RANGER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_slider" onclick="showme(this.id);">SLIDER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_spark" onclick="showme(this.id);">SPARK</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>863 (863)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (2)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>871 (871)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_sqoop" onclick="showme(this.id);">SQOOP</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr><tr><td><a href="#" id="anchor_storm" onclick="showme(this.id);">STORM</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1 (1)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td></tr><tr><td><a href="#" id="anchor_tez" onclick="showme(this.id);">TEZ</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (6)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>1</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>2 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (2)</td></tr><tr><td><a href="#" id="anchor_zeppelin" onclick="showme(this.id);">ZEPPELIN</a></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>7 (1)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>6</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>35 (23)</td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>13 (1)</td></tr><tr><td><a href="#" id="anchor_zookeeper" onclick="showme(this.id);">ZOOKEEPER</a></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td><td><img src="resources/yellow.png" align="top" style="width: 16px; height: 16px;" title="UNSTABLE"></img>3 (3)</td><td><img src="resources/blue.png" align="top" style="width: 16px; height: 16px;" title="SUCCESS"></img></td></tr></tbody></table></div></div></body></html>